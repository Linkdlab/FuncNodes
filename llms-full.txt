# FuncNodes Documentation

> Comprehensive documentation for FuncNodes - a modular workflow automation system.

Comprehensive documentation for FuncNodes - a modular workflow automation system.

# Getting Started

# First Steps with FuncNodes

This guide walks you through launching FuncNodes, creating your first worker, and building a simple workflow.

______________________________________________________________________

## 1. Launch the UI

Start the FuncNodes web interface:

```bash
funcnodes runserver # (1)!
```

1. For more options see the [CLI reference](https://linkdlab.github.io/FuncNodes/api/cli/#runserver)

This opens a browser window with the FuncNodes interface:

______________________________________________________________________

## 2. Create a Worker

[Workers](https://linkdlab.github.io/FuncNodes/components/worker/index.md) are isolated execution environments that run your workflows. Each worker has:

- Its own **virtual environment** (isolated dependencies)
- Its own **nodespace** (graph state)
- Its own **installed modules**

### Steps

1. Click **Worker** ‚Üí **New** in the menu bar
1. Enter a name for your worker
1. Click **Create**

The worker is created in `~/.funcnodes/workers/` with its own virtualenv.

______________________________________________________________________

## 3. Start the Worker

1. Go to **Worker** ‚Üí **Select**
1. Click on your worker's name

The worker is active when you see:

- **Nodespace** menu enabled in the header
- **Manage Libraries** button available

______________________________________________________________________

## 4. Install Modules

FuncNodes functionality comes from **modules**‚ÄîPython packages containing nodes.

### Steps

1. Click **Manage Libraries**
1. Browse available modules:
1. **Installed** ‚Äî Modules in your worker's environment
1. **Available** ‚Äî Modules from the [official registry](https://github.com/Linkdlab/funcnodes_repositories)
1. **Active** ‚Äî Modules loaded in the current worker
1. Click **Add** to install a module

After installation, the module's [shelf](https://linkdlab.github.io/FuncNodes/components/shelf/index.md) appears in the **Lib** menu.

______________________________________________________________________

## 5. Add Nodes to Your Workflow

[Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) are the computational units‚Äîfunctions with [inputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) and outputs.

### Adding Nodes

1. Open the **Lib** menu
1. Browse shelves or use the **search bar**
1. **Double-click** a node name to add it to the [nodespace](https://linkdlab.github.io/FuncNodes/components/nodespace/index.md)

### Connecting Nodes

1. **Drag** from an output port to an input port to create a connection
1. **Click** on an input to edit its value manually (for compatible types)
1. **Hover** over any port to see its current value

### Execution Flow

- When an input changes, the node **triggers** automatically
- Outputs flow to connected inputs, potentially triggering downstream nodes
- Execution cascades through the graph based on data dependencies

______________________________________________________________________

## 6. What's Next?

Now that you have a running workflow:

| Topic                                                                                       | Description                                   |
| ------------------------------------------------------------------------------------------- | --------------------------------------------- |
| [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md)             | Build custom nodes with decorators or classes |
| [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) | Understand data flow and type rendering       |
| [Examples](https://linkdlab.github.io/FuncNodes/examples/index.md)                          | See complete workflow examples                |
| [Available Modules](https://linkdlab.github.io/FuncNodes/modules/index.md)                  | Browse the official module ecosystem          |

______________________________________________________________________

## Tips

Live Preview

Click on connections to see data flowing through your workflow in real-time.

Development Mode

For developing custom nodes, use `funcnodes --dir .funcnodes runserver` to keep data in your project folder.

# Getting started

FuncNodes is a powerful workflow automation system designed for modular and scalable execution. If you're familiar with Python, you can install FuncNodes with [`pip`](#with-pip), the Python package manager. We also aim an stand alone Docker installation and local executables, but they are not yet finished.

## With pip recommended

FuncNodes is published as a Python package and can be installed with `pip`, ideally using a virtual environment. Open a terminal and install FuncNodes with:

```bash
pip install funcnodes
```

```bash
pip install funcnodes=="0.5"
```

This will automatically install all required dependencies, including `funcnodes-core`, `funcnodes-basic`, and other essential packages. FuncNodes always strives to support the latest versions, so there's no need to install dependencies separately.

### Verifying Installation

To confirm that FuncNodes is installed correctly, run:

```bash
funcnodes --version
```

This should display the installed version of FuncNodes. If you encounter any issues, check the [troubleshooting guide](https://linkdlab.github.io/FuncNodes/faq/common-issues/index.md).

______________________________________________________________________

# Introduction to FuncNodes

FuncNodes is a **modular workflow automation framework** that uses node-based execution to handle complex computational tasks. Users construct workflows by connecting nodes‚Äîeach representing a function‚Äîinto a visual graph that processes data automatically.

______________________________________________________________________

## Architecture Overview

```
flowchart TB
    subgraph System["FuncNodes System"]
        UI["üñ•Ô∏è Web UI<br/>(React Flow)"]
        WM["‚öôÔ∏è Workermanager<br/>(orchestrates worker lifecycle)"]

        subgraph Workers["Worker Pool"]
            subgraph W1["Worker 1"]
                V1["venv"]
                NS1["Nodespace<br/>(graph)"]
            end
            subgraph W2["Worker 2"]
                V2["venv"]
                NS2["Nodespace<br/>(graph)"]
            end
            subgraph WN["Worker N"]
                VN["venv"]
                NSN["Nodespace<br/>(graph)"]
            end
        end
    end

    UI <-->|WebSocket| WM
    WM --> W1
    WM --> W2
    WM --> WN
```

______________________________________________________________________

## Core Concepts

### Nodes

Nodes are the fundamental building blocks of FuncNodes:

- Each node encapsulates a **function** with defined **inputs** and **outputs**
- Nodes execute automatically when all required inputs are available
- Creating nodes is **extremely** simple‚Äîjust add a decorator to an existing function:

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="add_numbers")
def add(a: int, b: int) -> int:
    return a + b
```

### Data Flow

- Nodes connect via inputs and outputs, forming a **directed acyclic graph (DAG)**
- Data flows from outputs to inputs, **triggering execution dynamically**
- The system automatically determines execution order based on dependencies

### Workers

Workers are **isolated execution environments** that run node graphs:

- Each worker has its own **virtual environment** for dependency isolation
- Workers are **sandboxed**, preventing conflicts between workflows
- Multiple workers can run simultaneously with different configurations

### Workermanager

The Workermanager is a **supervisory service** that:

- Orchestrates worker lifecycle (create, start, stop, delete)
- Provides a central discovery point for the UI
- Manages worker communication via WebSocket

______________________________________________________________________

## Execution Model

### Event-Driven Triggering

FuncNodes uses an **event-driven execution model**:

1. **Input Change** ‚Üí A node's input value is set or updated
1. **Trigger Check** ‚Üí System verifies all required inputs are available
1. **Execution** ‚Üí Node function runs asynchronously
1. **Propagation** ‚Üí Output values flow to connected downstream nodes
1. **Cascade** ‚Üí Connected nodes trigger if their inputs are satisfied

### Parallel Processing

- Nodes without data dependencies execute **in parallel**
- Heavy computations can run in **separate threads or processes**
- The async architecture ensures the UI stays responsive

______________________________________________________________________

## Key Features

| Feature                   | Description                                                          |
| ------------------------- | -------------------------------------------------------------------- |
| **Visual Editor**         | Drag-and-drop workflow creation with live previews                   |
| **Live Data Preview**     | Hover over connections to see current values                         |
| **Modular Ecosystem**     | Install domain-specific node packages as needed                      |
| **Type-Aware UI**         | Inputs render as sliders, dropdowns, or custom widgets based on type |
| **Isolated Environments** | Each worker manages its own dependencies                             |
| **Async by Default**      | Non-blocking execution for responsive workflows                      |

______________________________________________________________________

## Example: Image Processing Pipeline

This image processing workflow demonstrates FuncNodes' **live preview** capabilities:

- Each node shows a preview of its current output
- Numeric inputs with `min`/`max` render as **interactive sliders**
- The workflow converts an image to grayscale except where the cat has red fur

______________________________________________________________________

## Next Steps

1. **[Install FuncNodes](https://linkdlab.github.io/FuncNodes/getting-started/installation/index.md)** ‚Äî Set up your environment
1. **[First Steps](https://linkdlab.github.io/FuncNodes/getting-started/basic_usage/index.md)** ‚Äî Launch the UI and create your first workflow
1. **[Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md)** ‚Äî Learn the two ways to define nodes
1. **[Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md)** ‚Äî Understand data flow and type hints
# Core Concepts

# Configuration

FuncNodes stores its configuration in `config.json` under the base directory (default `~/.funcnodes`). Override the base with `funcnodes --dir <path>` or by setting `FUNCNODES_CONFIG_DIR`.

## Structure (key sections)

- **env_dir** ‚Äî base path for configs/logs/workers (usually the base dir itself).
- **worker_manager** ‚Äî `host`, `port`, `ssl` for the Workermanager service.
- **frontend** ‚Äî `host`, `port`, `ssl` for the UI server (`funcnodes runserver`).
- **nodes** ‚Äî runtime defaults such as `pretrigger_delay` or test-mode flags.
- **logging** ‚Äî handlers, log level, and format limits (see Logging section).
- **render_options** ‚Äî global `typemap` and `inputconverter` hints for special types.

Defaults come from `DEFAULT_CONFIG` in `funcnodes_core.config`. On load, FuncNodes:

1. Ensures the config directory exists.
1. Reads `config.json` (or the `.bu` backup).
1. Fills missing keys from defaults, then writes back.

## Editing config

- Use any editor to adjust `~/.funcnodes/config.json`; restart UI/manager/workers to apply.
- CLI overrides: `funcnodes runserver --host ... --port ...` take precedence for that run.
- Environment: a `.env` file is loaded if present; env vars can override individual settings.

## Test mode

`funcnodes_core.config.set_in_test()` switches to a temporary config dir, disables file logging, promotes warnings to errors (optional), and is automatically used by `pytest_funcnodes` nodetests.

## Render options registry

`render_options` can be extended at runtime (e.g., by modules) via `fn.update_render_options`, normalizing type strings so the UI knows how to preview custom classes.

# Inputs & Outputs

In FuncNodes, inputs and outputs (IOs) serve as the fundamental connection points between nodes. They are responsible for handling the flow of data and triggering execution throughout a workflow. Both inputs and outputs extend from a common foundation‚Äîthe NodeIO Base Class‚Äîwhich provides shared functionality for connection management, value handling, serialization, and event emission.

The main principle is that each IO can hold an arbitrary data object, referenceable via the `value` property. If the value is not set it is automatically set to the NoValue singleton object which is used to represent the absence of a value. This is important because None is a valid value for an IO.

If the value of an IO is changed this may trigger a range of events, including *e.g.* triggering the Node or passing its value to connected IOs.

## NodeIO Base Class

The inputs and outputs of a Node are both derived from the `NodeIO` base class. This class accepts the following parameters (for nromal use cases NodeIO is never intialized directly, but always via the child classes):

- **uuid**: Each IO has a unique ID that is generated when the IO is created. (1)
- **name**: Each IO has a name that is used as the referencing key and also for display purposes (defaults to the uuid).
- **description**: A description of the IO, mainly used for display purposes.
- **type**: The data type of the IO. This is treated as a hint for the UI and the backend, but is not enforced.
- **allow_multiple**: A boolean flag that indicates whether the IO have multiple connections to other IOs. By default this is False for inputs and True for outputs.
- **hidden**: A boolean flag that indicates whether the IO is hidden in the UI. This is useful for internal IOs or for very IO-rich nodes, to make them more usable.
- **render_options**: See [Render Options](#render-options).
- **value_options**: See [Value Options](#value-options).

1. Note: if the IO is derived of a function parameter, the id becomes the signature name of the parameter, so it is not individually unique. But IOs are always attasched to a node, with a unique id, so the combination of node id and IO id is always unique.

## Render Options

The IO-Render options are used to control and customize the appearance of the IO in the UI. In its base form these options are available:

- **type**: If the IO Type is different than what is should be rendered at (e.g. a number that should be rendered as a string or a custom frontend component, this can be set here).
- **set_default**: If the value of the IO is set manually, this flag indicates whether the new value should be set as the default value for the IO (meaning it will also be serialized, and has to be [serializable](https://linkdlab.github.io/FuncNodes/components/serialization/index.md)).

The render options are a dictionary, meaning it can be arbitrary extended with custom options. Which will be passed to the frontend and can there be used to customize the rendering of the IO.

## Value Options

The IO-Value options are used to control and customize the behavior of the IO-value. Currently these values are not directly enforced, but are used as hints for the UI and the backend and if required should be enforced in the respective node functions:

- **min**: The minimum value of the IO, currently used for number types.
- **max**: The maximum value of the IO, currently used for number types (1).
- **step**: The step size of the IO, currently used for number types.
- **options**: A list of options that the IO can take, rendered as a dropdown (2).

1. Note: If min and max are set the default frontend renders the IO as a slider.
1. For more control this can also be defined as a enum type in the form of a dictionary with keys and values (see example below).

```python
import funcnodes as fn

class IOModNode(fn.Node):
    node_id = "iomodnode"
    a = fn.NodeInput(
        value_options={"min": 0, "max": 1, "step": 0.1}, default=0.5, type=float
    )

    b = fn.NodeInput(
        render_options={"type": "color"}, type=str, default="#ff0000"
    )

    c = fn.NodeInput(
        value_options={"options": ["a", "b", "c"]}, default="a", type=str
    )
    d = fn.NodeInput(
        value_options={
            "options": {
                "type": "enum",
                "keys": ["full", "empty"],
                "values": [1, 0],
            }
        }
    )

    async def func(self, a: float, b: str, c: str, d: float):
        self.inputs["a"].set_value(float(d), does_trigger=False)
```

## Events & triggering

- Inputs fire `after_set_value` events when `emit_value_set=True`; outputs fire on `trigger`.
- Inputs can opt out of triggering the node with `does_trigger=False` (useful for control signals or staged values).
- Hidden maintenance ports (e.g., the auto-created `_triggerinput`/`_triggeroutput`) use `hidden=True` to stay out of the UI.

## Dynamic IO updates

Use decorator helpers to recompute options based on other inputs:

- `update_other_io_options("target", modifier=...)` ‚Äî recalc dropdown contents.
- `update_other_io_value_options("target", options_generator=...)` ‚Äî recalc numeric bounds (`min/max/step`).

Patterns in the shipped modules:

- Pandas column selectors rebuild `options` from `df.columns`.
- Basic list nodes adjust valid indices to the current list length.
- File/folder pickers repopulate from the worker `files_dir`.

## Enumerations & `DataEnum`

For stable choice lists, subclass `fn.DataEnum`; it registers a type string and exposes `.v()` to resolve stored values. Example:

```python
class BorderTypes(fn.DataEnum):
    CONSTANT = (0, "Constant")
    REFLECT = (2, "Reflect")
```

Attach the enum as the IO `type` or use `value_options={"options": BorderTypes}`; the UI renders friendly labels while storing the underlying values.

## `NoValue` and optional outputs

`NoValue` represents ‚Äúno data‚Äù and **suppresses downstream triggers**. Return it from optional outputs or routers to avoid firing branches unintentionally. Inputs default to `NoValue` until set; disconnecting an input resets it to its class default if provided.

## Render routing & previews

Node-level `default_render_options` can point the UI at a specific IO, e.g. `{"data": {"src": "figure"}}` for Plotly or images. Per-IO `render_options` can request widgets (`{"type": "color"}`, sliders via min/max) or mark values as preview-only.

### Custom renderers and type hints

- The global render-option registry lives in `funcnodes_core.config.FUNCNODES_RENDER_OPTIONS`. Modules can extend it at import time via an entry point (`render_options`) or by calling `funcnodes_core.config.update_render_options`.
- Serialization uses `funcnodes_core.utils.serialization.JSONEncoder/Decoder`; modules may register additional encoders so custom types can be stored in `nodespace.json` and previewed in the UI.
- Enums for dropdowns should subclass `fn.DataEnum` so both values and display labels are preserved.

## Connection rules & multiplicity

- Inputs default to **single connection**; set `allow_multiple=True` for fan-in semantics.
- Outputs allow multiple downstream connections.
- Connection validation prevents input‚Üíinput and output‚Üíoutput wiring and enforces `allow_multiple`; violations raise `NodeConnectionError` / `MultipleConnectionsError`.
- There is no automatic cycle detection across the graph; avoid feedback loops unless your node logic guards against it.

## Serialization hints

- All IO values must be JSON-serializable by the registered encoders to persist in `nodespace.json`.
- Set `render_options["set_default"]=True` when user-set values should become the new default and be serialized with the graph.

# Library (Shelf Registry)

The Library is the runtime registry that exposes shelves and node classes to a `NodeSpace`. It lives in `funcnodes_core.lib.Library` and is attached to every worker.

## Storage model

- Internally a flat dict keyed by tuple paths (`("Top", "Child", ...)`) pointing to `_ShelfRecord` entries that store **only node IDs**, not class objects.
- Weak references can be mounted (`add_external_shelf`, `add_subshelf_weak`) so externally owned shelves disappear automatically when GC‚Äôd.
- Materialized shelves are rebuilt on demand with `Shelf` objects; missing node classes are skipped if they are no longer registered.

## API highlights

- `add_shelf(shelf)` ‚Äî merge/insert a full shelf tree (deduplicates node IDs).
- `add_node(s)/add_nodes` ‚Äî append one or many node classes to a shelf path, creating intermediate shelves as needed.
- `remove_shelf`, `remove_shelf_path` ‚Äî drop shelves (and descendants) by object or path.
- `find_nodeid` / `find_nodeclass` ‚Äî return all shelf paths that reference a node.
- `get_node_by_id` ‚Äî resolves a node class only if it is both registered and referenced somewhere; otherwise raises `NodeClassNotFoundError`.
- `full_serialize()` ‚Äî JSON snapshot of all shelves, used by `NodeSpace.full_serialize()`.

## Population from installed modules

Module discovery runs via `funcnodes_core.libparser.module_to_shelf` and `_setup.py`:

1. Installed distributions are inspected for `funcnodes.module` entry points. If a `shelf` object is exported, it is validated (`check_shelf`) and mounted.
1. If no `shelf` entry point is provided, all non‚Äëabstract `Node` subclasses in the module are grouped into a shelf named after the module.
1. Render options or external workers exported via entry points are applied separately and do not affect the library tree.

## Why flat storage?

Keeping only node IDs in `_records` avoids strong references to node classes and keeps the GC happy, while still allowing quick materialization of nested shelves when the UI or serialization needs them.

Nodes are the most fundamental building blocks of FuncNodes. Each node encapsulates a function with defined inputs and outputs. Nodes execute when all required inputs are available, producing output data for downstream nodes. Nodes can be created with two different methods: [class based](#class-based-nodes) and [decorator based](#decorator-based-nodes). While class based nodes are more flexible and can be used to create complex nodes, decorator based nodes are simpler and faster to create.

## Class Based Nodes

Class based nodes are created by subclassing the `Node` class from the `funcnodes` package. This method is more flexible and allows for more complex nodes to be created. The `Node` class provides a number of methods and properties that can be overridden to customize the behavior of the node.

The basic layout of a class based node is as follows:

```python
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node"
    node_id = "my_node"

    async def func(self):
        """The function to be executed when the node is triggered."""
```

The `node_name` and `node_id` required properties define the name and ID of the node, respectively. It is important that the 'node_id' is unique across all nodes in the system since it is used for serialization and deserialization of the node. So it is recommended to make it as descriptive as possible, e.g. if the node CalculateOrbit is part of a public package named 'funcnodes_astronomy' and the node the node_id could be 'funcnodes_astronomy.calculate_orbit'. And while this is not enforced it is recommended to use a similar naming scheme for the ids, to prevent id clashes. The node name is the human readable name of the node and is used in the UI.

The async `func` method is the entry point for the node's execution. This method is called when the node is triggered and should contain the logic for the node's function.In the class based nodes the `func` method is the only method that is required to be implemented. The `func` method has to be an async method since the execution of the node is done asynchronously.

The node above has no inputs or outputs, which makes it relatively useless. inputs and outputs can be added on the class level as well:

```python
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node"
    node_id = "my_node"

    input1 = fn.NodeInput(id="input1", type=int)
    input2 = fn.NodeInput(id="input2", type=int)

    output1 = fn.NodeOutput(id="output1", type=int)


    async def func(self, input1, input2):

        result =  input1 + input2
        self.outputs["output1"].value = result
```

In the example above, the node has two inputs, `input1` and `input2`, and one output, `output`. The `func` method now takes two arguments, `input1` and `input2`, which are the values of the inputs. The `func` method then adds the two inputs together and sets the result as the value of the output. While the class attributes of the inputs and outputs can be arbitrary named, it is recommended to use the same name as the id of the input or output (IO), to make the code more readable. setting the type of the IO is optional, but it is recommended since this will be used to render the corresponding IO in the UI (defaults to Any).

Warning

The typing of the IO is not enforced, to stay as pythonic as possible. If the value is not of the expected type, the node will still trigger and raise an exception if it occurs.

This is important to keep the system flexible: e.g. numpy arrays can be passed to inputs that expect a list and it should still work.

If enforcing is required, it should be done in the `func` method.

During triggering all inputs are passed to the `func` method as keyword arguments, so the order of the inputs does not matter, but the ids should be valid python variable names. In the class based approach outputs have to be set **explicitly**, by setting the value of the output in the `func` method. For more details on the `IO` see the [Inputs and Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md).

## Decorator Based Nodes

A even simpler way to create nodes is by using the `@fn.NodeDecorator` decorator. This decorator can be used to create nodes from a simple function. The function should take the inputs as arguments and return the outputs as a dictionary. The decorator will automatically create the node and set the inputs and outputs based on the function signature.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(input1: int, input2: int) -> float:
    return input1 / input2
```

This will create a node with the id `my_node`, which has two inputs, `input1` and `input2` (of type `int`), and one output, `output1` (of type `float`).

The `@fn.NodeDecorator` decorator has the required argument `node_id`, which is the id of the node, similar to the `node_id` property in the class based nodes. The inputs are automatically created based on the function signature, as such the function should have only defined positional and keyword arguments and no expanding arguments like `*args` or `**kwargs`. Similar to the class based nodes, the type of the inputs is optional, but recommended.

The Decorator can also be used to create a Node from an arbitrary external function, by passing the function as an argument to the decorator. The corresponding inputs and outputs will be created based on the signature of the function and the type hints.

```python
import funcnodes as fn

def myfunction(a: int=1, b: int=2) -> int:
    return a + b

MyFuncNode = fn.NodeDecorator(
    node_id="my_node",
)(myfunction)
```

The outputs are defined by the return type of the function, the output type is also interpreted from the return type, if present. The default id if the output is `out` and the default type is `Any`.

How the Node input and Output can be further customized with decorators is described in the [Inputs and Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) section.

### Defining multiple outputs

Will the class based approach allows for multiple outputs simply by defining multiple outputs, the decorator requires a little modification.

To have multiple outputs, the function should return multiple values, which would make the return type a tuple.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(input1: int, input2: int) -> tuple:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

But this will result in a single output `out` of the type tuple. To actually have multiple outputs the return type has to be a typed tuple, to be able to interfere the number of outputs:

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
)
def my_node(input1: int, input2: int) -> Tuple[int, int]:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

By default the outputs are numbered, to give them a more descriptive name, the outputs can be customized with the `outputs` argument of the decorator:

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
    outputs=[
        {"name": "output1"},
        {"name": "output2"},
    ]
)
def my_node(input1: int, input2: int) -> Tuple[int, int]:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

The `outputs` argument of the decorator is a list of dictionaries, where each dictionary represents an output. The dictionary should have the key `name` which is the id of the output. To specify the type, the `type` argument can be used. Alternatively, the type can be specified in the return type of the function as in the example above.

### Further info in IO in decorator

In a similar manner the inputs can be customized with the `inputs` argument.

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
    inputs=[
        {"name": "a"},
        {"name": "b"},
    ],
)
def myfunction(var_name_i_dont_like_a: int=1, var_name_i_dont_like_b: int=2) -> int:
    return var_name_i_dont_like_a + var_name_i_dont_like_b
```

Defining the inputs and outputs in the decorator is especially useful when the function is an external function and the signature cannot be changed.

In the following example, the function `divmod` is an external function and the signature cannot be changed.

```python
from typing import Tuple
import funcnodes as fn

MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
)(divmod)
```

As you can see the function has the expected inputs, but it is not typed. As such the inputs are of type `Any`, which allows no manual input and the return type is not defined, meaning the function has no output.

To fix this, the inputs and outputs can be defined in the decorator.

```python
from typing import Tuple
import funcnodes as fn


MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
    inputs=[
        {"name": "a"},
        {"name": "b"},
    ],
    outputs=[
        {"name": "quotient", "type": int},
        {"name": "remainder", "type": int},
    ]
)(divmod)
```

While under normal circumstances this works as expected, it is recommended to use the `fn.NodeDecorator` as a decorator, and create a wrapper function that calls the external function, to make the node more readable and to allow for more customization.

```python
from typing import Tuple
import funcnodes as fn


@fn.NodeDecorator(
    node_id="divmod",
    outputs=[
        {"name": "quotient"},
        {"name": "remainder"},
    ]
)
def divmod_node(a: int=11, b: int=5) -> Tuple[int, int]:
    return divmod(a, b)
```

Furthermore by wrapping it in a function, it can be make sure, that the function accepts all arguments as keyword arguments. Since internally Funcnodes calls the function with all-keyword arguments, which is some functions don't accept:

```python
from typing import Tuple
import funcnodes as fn

MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
    inputs=[
        {"name": "a", "default":11}, # setting default to show the effect
        {"name": "b", "default":5},
    ],
    outputs=[
        {"name": "quotient", "type": int},
        {"name": "remainder", "type": int},
    ]
)(divmod) # this will not work since divmod does not accept keyword arguments
```

### Defining the node name

The node name is especially important for the UI, as it is the human readable name of the node. If not present, the node name will be the name of the function or the class. To set the node name, the `node_name` class attribute or the `name` argument of the decorator can be used.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node1", name="My Node Decorator")
def my_node(input1: int, input2: int) -> float:
    return input1 / input2

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node2"

    async def func(self):
        pass
```

### Defining the node description

In a similar manner the node description can be set with the `description` argument of the decorator or the `description` class attribute of the class based nodes.

Description is a human readable description of the node, which can be used to provide more information about the node to the user.

Additionaly if no description is provided, the docstring of the function or the class will be used as the description (if present).

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node1", description="This is a node created with the decorator")
def my_node(ip:int) -> float:
    return ip/2

@fn.NodeDecorator(node_id="my_node2")
def my_node(ip:int) -> float:
    """This is a node created with the decorator and a docstring"""
    return ip/2

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node3"
    description = """
This is a node created with the class

Multi line is supported
    """

    ip = fn.NodeInput(id="ip", type=int)

    async def func(self, ip):
        self.outputs["output1"].value = ip / 2
```

(Hover over the node header in the UI to see the description)

Future Plans

We plan to render the description as via Markdown/Sphinx in the UI, so it is recommended to use Markdown in the description.

### Node progress bar

Especially for long running nodes, it is recommended to provide a progress bar to the user. For this purpose the node has a custom property `progress` which wraps the `tqdm` progress bar and automatically streams the progress to the UI.

```python
import asyncio
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node3"
    description = "This is a node created with the class"

    ip = fn.NodeInput(id="ip", type=int,default=30)

    async def func(self, ip):
        for i in self.progress(range(ip)):
            await asyncio.sleep(10)
```

(All nodes on this page here run in parallel processes in [pyodide](https://pyodide.org/en/stable/), each with all the individual management overhead, which is why the progress bar is not 100% iterating with the sleep time. A normal use-case would be only little processes with multiple nodes per process)

To access the progress bar in a decorator based node, we need to access the underlying node object. For this purpose an input argument `node` can be added, which will not be considered as normal input, but as a reference to the node object.

```python
import asyncio
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
async def my_node(ip:int=30, node: fn.Node=None) -> float:
    for i in node.progress(range(ip)):
        await asyncio.sleep(10)

    return ip/2
```

### Heavy Tasks

Since Funcnodes uses the asyncio library, a blocking function will block the event loop and prevent other nodes from executing. To prevent this, heavy tasks should be executed in a separate thread or process. This can be done e.g. by using the `asyncio.to_thread` function, which will run the function in a separate thread and return the result.

```python
import asyncio
import time
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
async def my_node(input1: int, input2: int) -> int:
    def heavy_task(input1, input2):
        time.sleep(1)
        return input1 + input2

    return await asyncio.to_thread(heavy_task, input1, input2)
```

Pyodide Runtime

Funcnodes is also able to run in [pyodide](https://pyodide.org/en/stable/) ("Pyodide makes it possible to install and run Python packages in the browser"). We use this also in all the Nodes you see here running live. But pyodide does not yet support multithreading or multiprocessing.

This works for both class based and decorator based nodes. Alternatively, the NodeDecorator accepts a `separate_thread=True` argument, which will automatically run the function in a separate thread. (The decorator alternativly accepts a `separate_process=True` argument, which will run the function in a separate process, but this is still experimental and should only considered for heavy CPU bound tasks)

`separate_process` wraps the function with `funcnodes_core.utils.functions.make_run_in_new_process`, which uses a `ProcessPoolExecutor`. Resource limits or sandboxing are not applied by FuncNodes; if you need supervision, point the worker at a running `subprocess_monitor` (see Worker config).

### Nested Inheritance

While the class based approach allows for more complex inheritance patterns:

```python
import funcnodes as fn

class BaseNode(fn.Node):
    """
    `Abstract` base class does not need a `func` method or a `node_id`
    """

    my_id = fn.NodeOutput(id="my_id", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["my_id"].value = id(self)


class MyNode(BaseNode):
    node_name = "My Node"
    node_id = "my_node"

    input1 = fn.NodeInput(id="input1", type=int)
    input2 = fn.NodeInput(id="input2", type=int)

    output1 = fn.NodeOutput(id="output1", type=int)

    async def func(self, input1, input2):
        result =  input1 + input2
        self.outputs["output1"].value = result

class MyNodeTwo(BaseNode):
    node_name = "My Node Two"
    node_id = "my_node_two"

    input1 = fn.NodeInput(id="input1", type=int)
    output1 = fn.NodeOutput(id="output1", type=float)

    async def func(self, input1):
        self.outputs["output1"].value = input1/2
```

The decorator also allows to use different baseclasses than the default `Node` class, by using the `superclass` argument of the decorator.

```python
import funcnodes as fn

class BaseNode(fn.Node):
    """
    `Abstract` base class does not need a `func` method or a `node_id`
    """

    my_id = fn.NodeOutput(id="my_id", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["my_id"].value = id(self)


@fn.NodeDecorator(node_id="my_node", superclass=BaseNode)
def my_node(input1: int, input2: int) -> int:
    return input1 + input2

instance = my_node()
instance.outputs["my_id"].value == id(instance) # True
```

### Try it out yourself

# Node Inputs

`NodeInput` is the input connection point for nodes in FuncNodes. It extends `NodeIO` with input-specific behavior including triggering, default values, and required/optional semantics.

______________________________________________________________________

## Constructor Parameters

```python
fn.NodeInput(
    id: str,                           # Unique identifier (required)
    type: Type = Any,                  # Data type hint
    name: str = None,                  # Display name (defaults to id)
    description: str = None,           # Help text
    default: Any = NoValue,            # Default value
    required: bool = True,             # Must have value to execute?
    does_trigger: bool = True,         # Triggers node on value change?
    allow_multiple: bool = False,      # Allow multiple connections?
    hidden: bool = False,              # Hide in UI
    value_options: dict = None,        # Value constraints
    render_options: dict = None,       # UI rendering hints
    emit_value_set: bool = True,       # Emit events on value change?
    on: dict = None,                   # Event handlers
)
```

### Parameter Details

| Parameter        | Type   | Default   | Description                                                                                                                 |
| ---------------- | ------ | --------- | --------------------------------------------------------------------------------------------------------------------------- |
| `id`             | `str`  | Required  | Unique identifier within the node. Used for programmatic access via `node.inputs["id"]`. Must be a valid Python identifier. |
| `type`           | `Type` | `Any`     | Python type hint. Affects UI rendering (e.g., `int` shows number input, `bool` shows checkbox). Not enforced at runtime.    |
| `name`           | `str`  | `id`      | Human-readable display name shown in UI.                                                                                    |
| `description`    | `str`  | `None`    | Tooltip/help text shown on hover in UI.                                                                                     |
| `default`        | `Any`  | `NoValue` | Default value when input is not connected and not manually set.                                                             |
| `required`       | `bool` | `True`    | If `True`, node won't execute until this input has a value.                                                                 |
| `does_trigger`   | `bool` | `True`    | If `True`, setting this input triggers node execution.                                                                      |
| `allow_multiple` | `bool` | `False`   | If `True`, multiple outputs can connect to this input.                                                                      |
| `hidden`         | `bool` | `False`   | If `True`, input is hidden from UI (but still functional).                                                                  |
| `value_options`  | `dict` | `None`    | Constraints like `min`, `max`, `step`, `options`.                                                                           |
| `render_options` | `dict` | `None`    | UI hints like custom renderer type.                                                                                         |
| `emit_value_set` | `bool` | `True`    | If `True`, emits `after_set_value` event when value changes.                                                                |
| `on`             | `dict` | `None`    | Event handlers to register (e.g., `{"after_set_value": handler}`).                                                          |

______________________________________________________________________

## Basic Usage

### Class-Based Nodes

```python
import funcnodes_core as fn

class MyNode(fn.Node):
    node_id = "my_module.my_node"
    node_name = "My Node"

    # Basic input with type and default
    value = fn.NodeInput(id="value", type=float, default=0.0)

    # Required input (must be set before node executes)
    data = fn.NodeInput(id="data", type=list, required=True)

    # Optional input with description
    label = fn.NodeInput(
        id="label",
        type=str,
        default="",
        required=False,
        description="Optional label for the output"
    )

    async def func(self, value, data, label):
        result = process(data, value)
        return f"{label}: {result}" if label else str(result)
```

### Decorator-Based Nodes

With decorators, inputs are created automatically from function parameters:

```python
@fn.NodeDecorator(node_id="add_numbers")
def add(a: int = 0, b: int = 0) -> int:
    return a + b
```

This creates:

- Input `a` with type `int`, default `0`
- Input `b` with type `int`, default `0`

### Using Type Annotations with `InputMeta`

For more control in decorator-based nodes, use `typing.Annotated` with `fn.InputMeta` to define all input properties inline:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(
    a: Annotated[
        int,
        fn.InputMeta(
            name="Amount",           # Display name
            description="The amount to process",
            default=1,
            does_trigger=False,
            hidden=True,
        ),
    ],
) -> int:
    return a + 1
```

This approach:

- Uses the **parameter name** (`a`) as the input ID
- The **type** comes from the first argument to `Annotated`
- All input properties are specified in `InputMeta`

### `InputMeta` with Dynamic Options

You can also include event handlers directly in `InputMeta`:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="dict_selector")
def dict_selector(
    data: Annotated[
        dict[str, int],
        fn.InputMeta(
            name="Data",
            description="Dictionary to select from",
            on={
                "after_set_value": fn.decorator.update_other_io_options(
                    "key",
                    list,  # Updates key's options to list(data.keys())
                )
            },
        ),
    ],
    key: str,
) -> int:
    return data[key]
```

Each node instance maintains **separate state** ‚Äî setting `data` on one instance updates only that instance's `key` options:

```python
node1 = dict_selector()
node2 = dict_selector()

node1["data"] = {"k1": 1, "k2": 2}
node2["data"] = {"k3": 3, "k4": 4}

# node1's key options: ["k1", "k2"]
# node2's key options: ["k3", "k4"]
```

### `InputMeta` Parameters

| Parameter        | Type   | Description                               |
| ---------------- | ------ | ----------------------------------------- |
| `name`           | `str`  | Display name (defaults to parameter name) |
| `description`    | `str`  | Help text                                 |
| `default`        | `Any`  | Default value                             |
| `does_trigger`   | `bool` | Whether setting triggers execution        |
| `required`       | `bool` | Whether input must have value             |
| `hidden`         | `bool` | Whether to hide in UI                     |
| `value_options`  | `dict` | Constraints like `min`, `max`, `options`  |
| `render_options` | `dict` | UI rendering hints                        |
| `on`             | `dict` | Event handlers                            |

______________________________________________________________________

## Value Constraints (`value_options`)

### Numeric Constraints

```python
# Slider with min/max (renders as slider in UI)
amount = fn.NodeInput(
    id="amount",
    type=float,
    default=0.5,
    value_options={"min": 0.0, "max": 1.0, "step": 0.1}
)

# Integer with minimum only
count = fn.NodeInput(
    id="count",
    type=int,
    default=1,
    value_options={"min": 1}
)
```

### Dropdown Options

```python
# Simple string options
mode = fn.NodeInput(
    id="mode",
    type=str,
    default="fast",
    value_options={"options": ["fast", "balanced", "accurate"]}
)

# Enum-style options (display labels different from values)
border_type = fn.NodeInput(
    id="border",
    type=int,
    default=0,
    value_options={
        "options": {
            "type": "enum",
            "keys": ["Constant", "Reflect", "Replicate"],
            "values": [0, 2, 1]
        }
    }
)
```

### Using DataEnum for Type-Safe Options

```python
from funcnodes_core import DataEnum

class ColorMode(DataEnum):
    RGB = ("rgb", "RGB Color")
    HSV = ("hsv", "HSV Color")
    GRAY = ("gray", "Grayscale")

@fn.NodeDecorator(node_id="convert_color")
def convert_color(
    image: "np.ndarray",
    mode: ColorMode = ColorMode.RGB
) -> "np.ndarray":
    return convert(image, mode.v())  # .v() gets the actual value
```

______________________________________________________________________

## Dynamic Value Options

Update input constraints based on other inputs using decorators:

### Dynamic Dropdown (Column Selector)

```python
from funcnodes_core.decorator import update_other_io_options

@fn.NodeDecorator(
    node_id="select_column",
    default_io_options={
        "df": {
            "on": {
                "after_set_value": update_other_io_options(
                    "column",  # Target input to update
                    lambda df: list(df.columns)  # Generate options
                )
            }
        },
    },
)
def select_column(df: "pd.DataFrame", column: str) -> "pd.Series":
    return df[column]
```

### Dynamic Numeric Bounds (List Index)

```python
from funcnodes_core.decorator import update_other_io_value_options

@fn.NodeDecorator(
    node_id="list_get",
    default_io_options={
        "lst": {
            "on": {
                "after_set_value": update_other_io_value_options(
                    "index",  # Target input
                    lambda lst: {
                        "min": -len(lst),
                        "max": len(lst) - 1 if len(lst) > 0 else 0,
                    }
                )
            }
        },
    },
)
def list_get(lst: list, index: int = -1) -> Any:
    return lst[index]
```

______________________________________________________________________

## Triggering Behavior

### `does_trigger` Parameter

Controls whether setting this input triggers node execution:

```python
class WaitNode(fn.Node):
    node_id = "wait_node"

    # Setting delay does NOT trigger the node
    delay = fn.NodeInput(
        id="delay",
        type=float,
        default=1.0,
        does_trigger=False,  # Change this without re-executing
        value_options={"min": 0.0}
    )

    # Setting input DOES trigger the node
    input = fn.NodeInput(id="input", type=Any)

    output = fn.NodeOutput(id="output", type=Any)

    async def func(self, delay, input):
        await asyncio.sleep(delay)
        self.outputs["output"].value = input
```

**Use cases for `does_trigger=False`:**

- Configuration parameters that shouldn't cause re-execution
- Parameters that are read during execution but don't initiate it
- Collector inputs in loop constructs

### Programmatic Value Setting

```python
# Set value and trigger (default)
node.inputs["value"].set_value(42)

# Set value without triggering
node.inputs["value"].set_value(42, does_trigger=False)

# Using property (always triggers based on does_trigger setting)
node.inputs["value"].value = 42
```

______________________________________________________________________

## Required vs Optional Inputs

### Required Inputs (`required=True`)

Node will **not execute** until all required inputs have values:

```python
class ProcessNode(fn.Node):
    node_id = "process_node"

    # Must be set before node can run
    data = fn.NodeInput(id="data", type=list, required=True)

    async def func(self, data):
        return process(data)
```

### Optional Inputs (`required=False`)

Node can execute even if these inputs have no value:

```python
class FormatNode(fn.Node):
    node_id = "format_node"

    value = fn.NodeInput(id="value", type=float, required=True)

    # Optional: uses default if not provided
    precision = fn.NodeInput(
        id="precision",
        type=int,
        default=2,
        required=False
    )

    async def func(self, value, precision):
        return f"{value:.{precision}f}"
```

______________________________________________________________________

## Default Values

### Static Defaults

```python
threshold = fn.NodeInput(id="threshold", type=float, default=0.5)
enabled = fn.NodeInput(id="enabled", type=bool, default=True)
items = fn.NodeInput(id="items", type=list, default=[])
```

### Dynamic Defaults with DefaultFactory

For defaults that depend on input state:

```python
class MyNode(fn.Node):
    node_id = "my_node"

    @staticmethod
    @fn.NodeInput.DefaultFactory
    def _default_timestamp(input: fn.NodeInput):
        """Generate timestamp when accessed."""
        import time
        return time.time()

    timestamp = fn.NodeInput(
        id="timestamp",
        type=float,
        default=_default_timestamp
    )
```

______________________________________________________________________

## Connection Behavior

### Single Connection (Default)

```python
# Only one output can connect to this input
input = fn.NodeInput(id="input", type=int, allow_multiple=False)
```

### Multiple Connections

```python
# Multiple outputs can connect (fan-in)
inputs = fn.NodeInput(id="inputs", type=Any, allow_multiple=True)
```

Fan-in Semantics

When multiple outputs connect to a single input, only the **last value set** is used. The values don't accumulate automatically.

### Disconnection Behavior

When an input is disconnected, it resets to its default value:

```python
# If default is NoValue, input becomes "not set"
# If default is provided, input gets that value
```

______________________________________________________________________

## Input Forwarding

Inputs can forward their values to other inputs (useful for subgraphs):

```python
# Forward value from one input to another
input_a.forward(input_b)

# Remove forwarding
input_a.unforward(input_b)

# Check forwarding relationships
input_a.has_forward_to(input_b)
input_b.has_forwards_from(input_a)
```

______________________________________________________________________

## Events

### Available Events

| Event               | When Fired              | Payload                               |
| ------------------- | ----------------------- | ------------------------------------- |
| `after_set_value`   | After value changes     | `{"src": input, "result": new_value}` |
| `before_connect`    | Before connection made  | Connection info                       |
| `after_connect`     | After connection made   | Connection info                       |
| `before_disconnect` | Before disconnection    | Disconnection info                    |
| `after_disconnect`  | After disconnection     | Disconnection info                    |
| `before_forward`    | Before input forwarding | Forward info                          |
| `after_forward`     | After input forwarding  | Forward info                          |

### Subscribing to Events

```python
# In class-based node
class MyNode(fn.Node):
    node_id = "my_node"

    value = fn.NodeInput(id="value", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.inputs["value"].on("after_set_value", self._on_value_change)

    def _on_value_change(self, msg):
        print(f"Value changed to: {msg['result']}")

# Using on parameter
value = fn.NodeInput(
    id="value",
    type=int,
    on={"after_set_value": lambda msg: print(f"New: {msg['result']}")}
)
```

______________________________________________________________________

## Render Options

### Custom Renderer Type

```python
# Render as color picker
color = fn.NodeInput(
    id="color",
    type=str,
    default="#ff0000",
    render_options={"type": "color"}
)

# Render with custom step display
delay = fn.NodeInput(
    id="delay",
    type=float,
    default=1.0,
    render_options={"step": "0.1"}
)
```

### Set Default on Manual Edit

```python
# When user manually edits, save as new default
config = fn.NodeInput(
    id="config",
    type=dict,
    render_options={"set_default": True}
)
```

______________________________________________________________________

## Status and State

### Check Input State

```python
input = node.inputs["value"]

# Check if value is set
has_value = input.value is not fn.NoValue

# Check if connected
is_connected = input.is_connected()

# Check if ready (has value or not required)
is_ready = input.ready()

# Get full status
status = input.status()
# Returns: {"has_value": bool, "has_node": bool, "ready": bool,
#           "connected": bool, "required": bool}
```

______________________________________________________________________

## Serialization

### Serialize Input State

```python
# Get serialized representation
serialized = input.serialize()
# Returns: {"id": "value", "type": "int", "value": 42, ...}

# Full serialization with all details
full = input.full_serialize(with_value=True)
```

### Restore from Serialized

```python
input.deserialize({"value": 42, "required": False})
```

______________________________________________________________________

## Complete Example

```python
import funcnodes_core as fn
from funcnodes_core.decorator import update_other_io_value_options
from typing import List, Any

@fn.NodeDecorator(
    node_id="funcnodes_example.list_processor",
    name="List Processor",
    description="Process a list with configurable options",
    default_io_options={
        "items": {
            "on": {
                "after_set_value": update_other_io_value_options(
                    "start_index",
                    lambda lst: {"min": 0, "max": len(lst) - 1} if lst else {"min": 0, "max": 0}
                )
            }
        }
    }
)
def list_processor(
    items: List[Any],
    start_index: int = 0,
    reverse: bool = False,
    limit: int = 10
) -> List[Any]:
    """Process a list with various options."""
    result = items[start_index:]
    if reverse:
        result = list(reversed(result))
    return result[:limit]
```

______________________________________________________________________

## See Also

- [Node Outputs](https://linkdlab.github.io/FuncNodes/components/nodeoutput/index.md) ‚Äî Output connection points
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî Complete IO reference
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî Node creation patterns
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event handling

# Node Outputs

`NodeOutput` is the output connection point for nodes in FuncNodes. It extends `NodeIO` and is responsible for sending data to connected inputs, triggering downstream execution.

______________________________________________________________________

## Constructor Parameters

```python
fn.NodeOutput(
    id: str,                           # Unique identifier (required)
    type: Type = Any,                  # Data type hint
    name: str = None,                  # Display name (defaults to id)
    description: str = None,           # Help text
    allow_multiple: bool = True,       # Allow multiple connections?
    hidden: bool = False,              # Hide in UI?
    value_options: dict = None,        # Value constraints (for previews)
    render_options: dict = None,       # UI rendering hints
    emit_value_set: bool = True,       # Emit events on value change?
    on: dict = None,                   # Event handlers
)
```

### Parameter Details

| Parameter        | Type   | Default  | Description                                                                               |
| ---------------- | ------ | -------- | ----------------------------------------------------------------------------------------- |
| `id`             | `str`  | Required | Unique identifier within the node. Used for programmatic access via `node.outputs["id"]`. |
| `type`           | `Type` | `Any`    | Python type hint. Affects how value is previewed in UI and serialized.                    |
| `name`           | `str`  | `id`     | Human-readable display name shown in UI.                                                  |
| `description`    | `str`  | `None`   | Tooltip/help text shown on hover in UI.                                                   |
| `allow_multiple` | `bool` | `True`   | If `True`, can connect to multiple inputs (fan-out). Almost always `True`.                |
| `hidden`         | `bool` | `False`  | If `True`, output is hidden from UI (but still functional).                               |
| `value_options`  | `dict` | `None`   | Metadata for previews (rarely used for outputs).                                          |
| `render_options` | `dict` | `None`   | UI hints for rendering previews.                                                          |
| `emit_value_set` | `bool` | `True`   | If `True`, emits `after_set_value` event when value changes.                              |
| `on`             | `dict` | `None`   | Event handlers to register.                                                               |

______________________________________________________________________

## Basic Usage

### Class-Based Nodes

```python
import funcnodes_core as fn

class CalculatorNode(fn.Node):
    node_id = "calculator"
    node_name = "Calculator"

    a = fn.NodeInput(id="a", type=float, default=0.0)
    b = fn.NodeInput(id="b", type=float, default=0.0)

    # Single output
    result = fn.NodeOutput(id="result", type=float)

    async def func(self, a, b):
        # Explicitly set output value
        self.outputs["result"].value = a + b
```

### Decorator-Based Nodes

With decorators, outputs are created from return type annotations:

```python
# Single output (named "out" by default)
@fn.NodeDecorator(node_id="double")
def double(x: float) -> float:
    return x * 2
```

### Using Type Annotations with `OutputMeta`

For more control over output properties in decorator-based nodes, use `typing.Annotated` with `fn.OutputMeta`:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="process")
def process(
    value: int
) -> Annotated[int, fn.OutputMeta(name="result", description="Processed value")]:
    return value + 1
```

This approach:

- Uses `Annotated` on the **return type**
- The output **type** comes from the first argument to `Annotated`
- The output **name** and other properties come from `OutputMeta`

### `OutputMeta` Parameters

| Parameter        | Type   | Description                 |
| ---------------- | ------ | --------------------------- |
| `name`           | `str`  | Display name for the output |
| `description`    | `str`  | Help text shown in UI       |
| `hidden`         | `bool` | Whether to hide in UI       |
| `render_options` | `dict` | UI rendering hints          |

### Combining `InputMeta` and `OutputMeta`

You can use both in the same node for full control:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(
    a: Annotated[
        int,
        fn.InputMeta(
            name="Input Value",
            description="Value to increment",
            default=1,
            does_trigger=False,
        ),
    ],
) -> Annotated[int, fn.OutputMeta(name="Result", description="Incremented value")]:
    return a + 1
```

______________________________________________________________________

## Setting Output Values

### In Class-Based Nodes

Outputs must be set **explicitly** in the `func` method:

```python
class MyNode(fn.Node):
    node_id = "my_node"

    input = fn.NodeInput(id="input", type=int)
    output = fn.NodeOutput(id="output", type=int)
    debug = fn.NodeOutput(id="debug", type=str)

    async def func(self, input):
        # Set outputs explicitly
        self.outputs["output"].value = input * 2
        self.outputs["debug"].value = f"Processed: {input}"
```

### In Decorator-Based Nodes

Return values are automatically assigned to outputs:

```python
# Single return ‚Üí single output "out"
@fn.NodeDecorator(node_id="add")
def add(a: int, b: int) -> int:
    return a + b  # Assigned to output "out"
```

______________________________________________________________________

## Multiple Outputs

### Class-Based Approach

Simply define multiple `NodeOutput` attributes:

```python
class DivModNode(fn.Node):
    node_id = "divmod_node"

    a = fn.NodeInput(id="a", type=int)
    b = fn.NodeInput(id="b", type=int)

    quotient = fn.NodeOutput(id="quotient", type=int)
    remainder = fn.NodeOutput(id="remainder", type=int)

    async def func(self, a, b):
        q, r = divmod(a, b)
        self.outputs["quotient"].value = q
        self.outputs["remainder"].value = r
```

### Decorator with Typed Tuple

For multiple outputs in decorators, use `Tuple` with type hints:

```python
from typing import Tuple

@fn.NodeDecorator(node_id="divmod")
def divmod_node(a: int, b: int) -> Tuple[int, int]:
    return divmod(a, b)  # Creates outputs "out_0" and "out_1"
```

### Named Multiple Outputs

Use the `outputs` parameter to name them:

```python
from typing import Tuple

@fn.NodeDecorator(
    node_id="divmod",
    outputs=[
        {"name": "quotient"},
        {"name": "remainder"}
    ]
)
def divmod_node(a: int, b: int) -> Tuple[int, int]:
    q, r = divmod(a, b)
    return q, r  # quotient, remainder
```

### With Types in Output Spec

```python
@fn.NodeDecorator(
    node_id="stats",
    outputs=[
        {"name": "mean", "type": float},
        {"name": "std", "type": float},
        {"name": "count", "type": int}
    ]
)
def statistics(data: list) -> Tuple[float, float, int]:
    import statistics as st
    return st.mean(data), st.stdev(data), len(data)
```

______________________________________________________________________

## NoValue ‚Äî Conditional Outputs

`NoValue` is a special sentinel that indicates "no data". When an output is set to `NoValue`, it **does not trigger** connected inputs.

### Suppressing Downstream Triggers

```python
from funcnodes_core import NoValue

class ConditionalNode(fn.Node):
    node_id = "conditional"

    condition = fn.NodeInput(id="condition", type=bool)
    value = fn.NodeInput(id="value", type=Any)

    on_true = fn.NodeOutput(id="on_true", type=Any)
    on_false = fn.NodeOutput(id="on_false", type=Any)

    async def func(self, condition, value):
        if condition:
            self.outputs["on_true"].value = value
            self.outputs["on_false"].value = NoValue  # Won't trigger connected nodes
        else:
            self.outputs["on_true"].value = NoValue
            self.outputs["on_false"].value = value
```

### In Decorators

```python
from funcnodes_core import NoValue

@fn.NodeDecorator(
    node_id="filter_positive",
    outputs=[{"name": "positive"}, {"name": "negative"}]
)
def filter_positive(value: float) -> Tuple[float, float]:
    if value >= 0:
        return value, NoValue  # Only positive output triggers
    else:
        return NoValue, value  # Only negative output triggers
```

______________________________________________________________________

## Output Value Propagation

When an output value is set, it automatically propagates to all connected inputs:

```
flowchart TD
    SetOutput["Output.value = x"]
    ForEach["For each<br/>connected input"]
    SetInput["input.set_value(x)"]
    InputTrigger["input.trigger()"]
    NodeTrigger["node.trigger()<br/>(if ready)"]

    SetOutput --> ForEach
    ForEach --> SetInput
    SetInput --> InputTrigger
    InputTrigger --> NodeTrigger
```

### Propagation Timing

- Values propagate **immediately** when set
- All connected inputs receive the value
- Each input may trigger its node (if `does_trigger=True`)
- Execution cascades through the graph

______________________________________________________________________

## Connection Behavior

### Fan-Out (Default)

Outputs can connect to **multiple inputs** by default:

```python
# Single output connected to multiple nodes
output = fn.NodeOutput(id="result", type=float)

# Connect to multiple inputs
output.connect(node1.inputs["a"])
output.connect(node2.inputs["x"])
output.connect(node3.inputs["value"])
# All three inputs receive the same value
```

### Restricting Connections

Rarely needed, but you can limit to single connection:

```python
# Only one input can connect (unusual for outputs)
exclusive_output = fn.NodeOutput(
    id="exclusive",
    type=Any,
    allow_multiple=False
)
```

### Connection on Value Set

When a new connection is made, the current output value is **immediately sent** to the newly connected input:

```python
# If output.value is already 42
output.connect(new_input)
# new_input.value is now 42
```

______________________________________________________________________

## Hidden Outputs

Hide outputs that are for internal use or debugging:

```python
class DebugNode(fn.Node):
    node_id = "debug_node"

    input = fn.NodeInput(id="input", type=Any)

    # Visible in UI
    result = fn.NodeOutput(id="result", type=Any)

    # Hidden from UI (for debugging/internal use)
    trace = fn.NodeOutput(id="trace", type=str, hidden=True)

    async def func(self, input):
        self.outputs["result"].value = process(input)
        self.outputs["trace"].value = f"Processed at {time.time()}"
```

______________________________________________________________________

## Preview Rendering

### Default Render Options

Configure how the output preview is displayed:

```python
class ImageNode(fn.Node):
    node_id = "image_processor"

    # Tell UI which output to use for node preview
    default_render_options = {
        "data": {"src": "output_image"}
    }

    input_image = fn.NodeInput(id="input_image", type="np.ndarray")
    output_image = fn.NodeOutput(id="output_image", type="np.ndarray")
```

### Per-Output Render Options

```python
# Plotly figure output
figure = fn.NodeOutput(
    id="figure",
    type="plotly.graph_objs.Figure",
    render_options={"type": "plotly"}
)
```

______________________________________________________________________

## Events

### Available Events

| Event               | When Fired             | Payload                                |
| ------------------- | ---------------------- | -------------------------------------- |
| `after_set_value`   | After value changes    | `{"src": output, "result": new_value}` |
| `before_connect`    | Before connection made | Connection info                        |
| `after_connect`     | After connection made  | Connection info                        |
| `before_disconnect` | Before disconnection   | Disconnection info                     |
| `after_disconnect`  | After disconnection    | Disconnection info                     |

### Subscribing to Events

```python
class MyNode(fn.Node):
    node_id = "my_node"

    output = fn.NodeOutput(id="output", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["output"].on("after_set_value", self._on_output_change)

    def _on_output_change(self, msg):
        print(f"Output set to: {msg['result']}")
```

______________________________________________________________________

## Status and State

### Check Output State

```python
output = node.outputs["result"]

# Check if value is set
has_value = output.value is not fn.NoValue

# Check if connected
is_connected = output.is_connected()

# Get connections
connections = output.connections  # List of connected NodeInputs

# Get full status
status = output.status()
# Returns: {"has_value": bool, "has_node": bool, "ready": bool, "connected": bool}
```

______________________________________________________________________

## Manual Triggering

Force propagation to connected inputs:

```python
# Trigger all connected inputs with current value
output.trigger()

# This:
# 1. Sets value on all connected inputs (without triggering them)
# 2. Then triggers each connected input
```

______________________________________________________________________

## Serialization

### Serialize Output State

```python
# Get serialized representation
serialized = output.serialize()
# Returns: {"id": "result", "type": "float", ...}

# Full serialization with value
full = output.full_serialize(with_value=True)
```

______________________________________________________________________

## Complete Examples

### Router Node (Conditional Output)

```python
import funcnodes_core as fn
from funcnodes_core import NoValue
from typing import Any

class RouterNode(fn.Node):
    """Routes input to one of multiple outputs based on a selector."""

    node_id = "router"
    node_name = "Router"

    value = fn.NodeInput(id="value", type=Any)
    route = fn.NodeInput(
        id="route",
        type=int,
        default=0,
        value_options={"min": 0, "max": 2}
    )

    out_0 = fn.NodeOutput(id="out_0", type=Any)
    out_1 = fn.NodeOutput(id="out_1", type=Any)
    out_2 = fn.NodeOutput(id="out_2", type=Any)

    async def func(self, value, route):
        outputs = [self.outputs["out_0"],
                   self.outputs["out_1"],
                   self.outputs["out_2"]]

        for i, out in enumerate(outputs):
            if i == route:
                out.value = value
            else:
                out.value = NoValue  # Don't trigger other routes
```

### Statistics Node (Multiple Typed Outputs)

```python
from typing import Tuple, List
import statistics

@fn.NodeDecorator(
    node_id="statistics",
    name="Statistics",
    outputs=[
        {"name": "mean", "type": float},
        {"name": "median", "type": float},
        {"name": "stdev", "type": float},
        {"name": "min", "type": float},
        {"name": "max", "type": float},
    ]
)
def calc_statistics(
    data: List[float]
) -> Tuple[float, float, float, float, float]:
    """Calculate various statistics for a list of numbers."""
    return (
        statistics.mean(data),
        statistics.median(data),
        statistics.stdev(data) if len(data) > 1 else 0.0,
        min(data),
        max(data),
    )
```

### Image Processing with Preview

```python
import funcnodes_core as fn

class GrayscaleNode(fn.Node):
    """Convert image to grayscale."""

    node_id = "grayscale"
    node_name = "To Grayscale"

    # Configure preview to show output_image
    default_render_options = {
        "data": {"src": "output_image"}
    }

    input_image = fn.NodeInput(id="input_image", type="np.ndarray")
    output_image = fn.NodeOutput(id="output_image", type="np.ndarray")

    async def func(self, input_image):
        import cv2
        gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)
        self.outputs["output_image"].value = gray
```

______________________________________________________________________

## Comparison: Input vs Output

| Aspect                     | NodeInput             | NodeOutput          |
| -------------------------- | --------------------- | ------------------- |
| **Direction**              | Receives data         | Sends data          |
| **allow_multiple default** | `False`               | `True`              |
| **Triggers node**          | Yes (configurable)    | No                  |
| **Has default value**      | Yes                   | No                  |
| **required parameter**     | Yes                   | No                  |
| **does_trigger parameter** | Yes                   | No                  |
| **Value propagation**      | From connected output | To connected inputs |

______________________________________________________________________

## See Also

- [Node Inputs](https://linkdlab.github.io/FuncNodes/components/nodeinput/index.md) ‚Äî Input connection points
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî Complete IO reference
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî Node creation patterns
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event handling

# NodeSpace (Graph State)

`NodeSpace` is the in‚Äëmemory representation of a FuncNodes graph plus its library snapshot. Each worker owns exactly one `NodeSpace`.

## What a NodeSpace contains

- **Nodes:** Instances of node classes keyed by UUID.
- **Edges:** Connections between outputs and inputs (stored as tuples of source/target UUIDs and IO IDs).
- **Library:** A `funcnodes_core.lib.Library` with all shelves/nodes visible to this worker.
- **Properties:** Public `prop` (JSON‚Äëserializable) and non‚Äëserialized `secret` properties for runtime state.
- **Groups:** Optional node group metadata from `GroupingLogic`.

## Serialization

Two JSON shapes are used:

- `serialize()` ‚Üí minimal `NodeSpaceJSON` with `nodes`, `edges`, `prop`, `groups`. IO values are included only if set as defaults; secret properties are excluded.
- `full_serialize(with_io_values=False)` ‚Üí adds `lib` (full shelf tree) and can embed current IO values when requested.

Files on disk (`nodespace.json` inside each worker‚Äôs data directory) use `serialize()`. They are read back with `deserialize`, which re‚Äëhydrates nodes via the library; missing classes become `PlaceHolderNode` instances.

## Edge and connection rules

- Connections must be output‚Üíinput (or input forwarding) and honor each IO‚Äôs `allow_multiple` flag; violations raise `NodeConnectionError` / `MultipleConnectionsError`.
- There is no automatic cycle detection; avoid wiring graphs that feed back indefinitely unless your node logic guards against it.

## Lifecycle hooks

`NodeSpace` emits events on node add/remove, trigger errors (`node_error` / `node_trigger_error`), and cleanup. Workers subscribe to these to update clients.

Error handling is event-only: there is no built-in retry/backoff. When a node raises, the error event is emitted and the node stays in its current state until retriggered by another input change or a manual trigger.

## Persistence cadence

Workers run a `SaveLoop` that writes the serialized NodeSpace to disk when `request_save()` is set (e.g., after edits). Exporting a worker bundles this serialized graph together with config and optional files.

# Serialization

FuncNodes uses a custom JSON serialization system to persist workflows, transfer data between workers, and render previews in the UI. This page covers the complete serialization API.

______________________________________________________________________

## Overview

The serialization system consists of:

| Component      | Purpose                                          |
| -------------- | ------------------------------------------------ |
| `JSONEncoder`  | Converts Python objects to JSON-compatible types |
| `JSONDecoder`  | Restores Python objects from JSON                |
| `ByteEncoder`  | Converts objects to binary data with MIME types  |
| `Encdata`      | Return type for JSON encoders                    |
| `BytesEncdata` | Return type for byte encoders                    |

______________________________________________________________________

## JSONEncoder

`JSONEncoder` extends Python's `json.JSONEncoder` with a registry of custom handlers.

### Basic Usage

```python
import json
from funcnodes_core.utils.serialization import JSONEncoder

# Encode an object
data = {"array": my_numpy_array, "figure": my_plotly_figure}
json_string = json.dumps(data, cls=JSONEncoder)

# Apply encoding without full JSON serialization
encoded = JSONEncoder.apply_custom_encoding(my_object, preview=False)
```

### The `preview` Parameter

Encoders receive a `preview` flag that indicates lightweight encoding for UI display:

- **`preview=False`** ‚Äî Full serialization for persistence/transfer
- **`preview=True`** ‚Äî Truncated/simplified output for UI previews

Built-in preview behaviors:

- Strings longer than 1000 characters are truncated with `...`
- Lists are limited to the first 10 items
- Large arrays may use simplified representations

______________________________________________________________________

## Registering Custom Encoders

### Simple Encoder (Tuple Return)

```python
from funcnodes_core.utils.serialization import JSONEncoder

def my_encoder(obj, preview=False):
    """Simple encoder returning (data, handled) tuple."""
    if isinstance(obj, MyCustomType):
        return obj.to_dict(), True  # (encoded_data, was_handled)
    return obj, False  # Not handled, pass to next encoder

JSONEncoder.add_encoder(my_encoder)
```

### Advanced Encoder (Encdata Return)

For more control, return an `Encdata` object:

```python
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def my_encoder(obj, preview=False):
    """Advanced encoder with Encdata control."""
    if isinstance(obj, MyCustomType):
        return Encdata(
            data=obj.to_dict(),
            handeled=True,
            done=False,           # Continue encoding nested objects
            continue_preview=None # Inherit preview setting
        )
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(my_encoder)
```

### Encdata Parameters

| Parameter          | Type             | Description                                                                                                  |
| ------------------ | ---------------- | ------------------------------------------------------------------------------------------------------------ |
| `data`             | `Any`            | The encoded data                                                                                             |
| `handeled`         | `bool`           | Whether this encoder processed the object                                                                    |
| `done`             | `bool`           | If `True`, stop encoding (return data as-is). If `False`, continue encoding nested objects. Default: `False` |
| `continue_preview` | `Optional[bool]` | Override preview flag for nested encoding. `None` inherits current setting.                                  |

### Type-Specific Registration

Register encoders for specific types to improve performance:

```python
from pathlib import Path
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def path_encoder(obj, preview=False):
    if isinstance(obj, Path):
        return Encdata(data=obj.as_posix(), handeled=True)
    return Encdata(data=obj, handeled=False)

# Only called for Path objects (and subclasses)
JSONEncoder.add_encoder(path_encoder, enc_cls=[Path])
```

### Encoder Priority

Use `prepend_encoder` to add an encoder at the front of the queue (higher priority):

```python
# This encoder will be tried before others for the specified types
JSONEncoder.prepend_encoder(my_high_priority_encoder, enc_cls=[MyType])
```

______________________________________________________________________

## Real-World Encoder Examples

### NumPy Arrays

```python
import numpy as np
import funcnodes_core as fn

def numpy_encoder(obj, preview=False):
    if isinstance(obj, np.ndarray):
        if preview:
            # Simplified preview for UI
            return obj.tolist()[:10], True
        return obj.tolist(), True
    return obj, False

fn.JSONEncoder.add_encoder(numpy_encoder)
```

### Plotly Figures

```python
import plotly.graph_objects as go
import funcnodes_core as fn

def figure_encoder(figure: go.Figure, preview=False):
    if isinstance(figure, go.Figure):
        return fn.Encdata(
            data=figure.to_plotly_json(),
            handeled=True,
            done=False,              # Allow nested encoding
            continue_preview=False,  # Disable preview for nested data
        )
    return fn.Encdata(data=figure, handeled=False)

fn.JSONEncoder.add_encoder(figure_encoder, enc_cls=[go.Figure])
```

### Pydantic Models

```python
from pydantic import BaseModel
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def pydantic_encoder(obj, preview=False):
    if isinstance(obj, BaseModel):
        return Encdata(
            data=obj.model_dump(mode="json"),
            handeled=True,
            done=True,  # Already JSON-compatible
        )
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(pydantic_encoder, enc_cls=[BaseModel])
```

______________________________________________________________________

## JSONDecoder

`JSONDecoder` restores Python objects from JSON using registered decoders.

### Basic Usage

```python
import json
from funcnodes_core.utils.serialization import JSONDecoder

# Decode JSON string
data = json.loads(json_string, cls=JSONDecoder)
```

### Registering Decoders

Decoders are called for each dict/value during parsing:

```python
from funcnodes_core.utils.serialization import JSONDecoder

def my_decoder(obj):
    """Decoder returning (result, handled) tuple."""
    if isinstance(obj, dict) and obj.get("__type__") == "MyCustomType":
        return MyCustomType.from_dict(obj), True
    return obj, False

JSONDecoder.add_decoder(my_decoder)
```

### Decoder Signature

```python
def decoder(obj: Any) -> Tuple[Any, bool]:
    """
    Args:
        obj: The JSON value (dict, list, str, int, float, bool, None)

    Returns:
        Tuple of (decoded_object, was_handled)
    """
```

______________________________________________________________________

## ByteEncoder

`ByteEncoder` converts objects to binary data with MIME types for efficient transfer.

### Basic Usage

```python
from funcnodes_core.utils.serialization import ByteEncoder

result = ByteEncoder.encode(my_object, preview=False)
# result.data: bytes
# result.mime: str (e.g., "application/json", "image/png")
# result.handeled: bool
```

### Registering Byte Encoders

```python
from funcnodes_core.utils.serialization import ByteEncoder, BytesEncdata

def image_byte_encoder(obj, preview=False):
    if isinstance(obj, MyImageType):
        return BytesEncdata(
            data=obj.to_png_bytes(),
            handeled=True,
            mime="image/png"
        )
    return BytesEncdata(data=obj, handeled=False)

ByteEncoder.add_encoder(image_byte_encoder, enc_cls=[MyImageType])
```

### BytesEncdata Parameters

| Parameter  | Type            | Description                               |
| ---------- | --------------- | ----------------------------------------- |
| `data`     | `bytes \| Any`  | The encoded binary data                   |
| `handeled` | `bool`          | Whether this encoder processed the object |
| `mime`     | `Optional[str]` | MIME type of the encoded data             |

### Built-in MIME Types

| Type          | MIME                       |
| ------------- | -------------------------- |
| `str`         | `text/plain`               |
| `bytes`       | `application/octet-stream` |
| `int`         | `application/fn.struct.!q` |
| `float`       | `application/fn.struct.!d` |
| `bool`        | `application/fn.struct.?`  |
| `None`        | `application/fn.null`      |
| JSON fallback | `application/json`         |

______________________________________________________________________

## Built-in Type Handlers

### Bytes

Bytes are Base64 encoded for JSON:

```python
import base64

# Encoding: bytes ‚Üí base64 string
encoded = base64.b64encode(my_bytes).decode("utf-8")

# Built-in handler does this automatically
```

### Dataclasses

Dataclasses are automatically converted to dictionaries:

```python
from dataclasses import dataclass

@dataclass
class MyData:
    name: str
    value: int

# Automatically serializes to {"name": "...", "value": ...}
```

### Objects with `_repr_json_`

Objects implementing `_repr_json_()` method are automatically encoded:

```python
class MyType:
    def _repr_json_(self):
        """Return JSON-serializable representation."""
        return {"type": "MyType", "data": self._internal_data}
```

______________________________________________________________________

## Persistence Files

FuncNodes uses these files for persistence:

| File                 | Content                                       | Format  |
| -------------------- | --------------------------------------------- | ------- |
| `nodespace.json`     | Serialized graph state (nodes, edges, groups) | JSON    |
| `worker_<uuid>.json` | Worker configuration and metadata             | JSON    |
| `config.json`        | Global FuncNodes settings                     | JSON    |
| `io_values/`         | Large IO values stored separately             | Various |

### Nodespace Serialization

```python
# Save nodespace
nodespace.serialize()  # Returns dict
json.dumps(nodespace.serialize(), cls=JSONEncoder)

# Load nodespace
nodespace.deserialize(data)
```

### Node Serialization

```python
# Full serialization (for persistence)
node.full_serialize()

# Returns:
{
    "node_id": "my_node",
    "uuid": "abc123...",
    "io": [...],  # Serialized inputs/outputs
    "render_options": {...},
    "properties": {...}
}
```

______________________________________________________________________

## Performance Considerations

### Large Data

For large arrays or binary data:

1. **Use file references** instead of embedding data:

```python
# Instead of storing array in JSON
# Store path to file and load on demand
{"__file__": "data/large_array.npy"}
```

1. **Use ByteEncoder** for binary transfer (more efficient than Base64)
1. **Enable preview mode** for UI display to truncate large data

### Circular References

The encoder detects circular references and raises `ValueError`:

```python
# This will raise ValueError
a = {}
a["self"] = a
JSONEncoder.apply_custom_encoding(a)  # ValueError: Circular reference detected
```

### Encoder Ordering

- Register type-specific encoders with `enc_cls` for better performance
- Use `prepend_encoder` for high-priority handlers
- The encoder chain stops at the first handler that returns `handeled=True`

______________________________________________________________________

## Module Integration

### Registering Encoders in Modules

Add encoders in your module's `__init__.py`:

```python
# mymodule/__init__.py
import funcnodes_core as fn
from .types import MyCustomType

def my_encoder(obj, preview=False):
    if isinstance(obj, MyCustomType):
        return fn.Encdata(
            data={"__type__": "MyCustomType", **obj.to_dict()},
            handeled=True
        )
    return fn.Encdata(data=obj, handeled=False)

# Register when module is imported
fn.JSONEncoder.add_encoder(my_encoder, enc_cls=[MyCustomType])
```

### Render Options for Custom Types

Tell the UI how to display your type:

```python
FUNCNODES_RENDER_OPTIONS: fn.RenderOptions = {
    "typemap": {
        "mymodule.MyCustomType": "json",  # Render as JSON viewer
    },
    "inputconverter": {
        "mymodule.MyCustomType": "str_to_json",  # Parse JSON input
    },
}
```

______________________________________________________________________

## Complete Example

```python
import funcnodes_core as fn
from funcnodes_core.utils.serialization import (
    JSONEncoder, JSONDecoder, ByteEncoder,
    Encdata, BytesEncdata
)
from dataclasses import dataclass

@dataclass
class Measurement:
    timestamp: float
    values: list[float]
    unit: str

# JSON Encoder
def measurement_encoder(obj, preview=False):
    if isinstance(obj, Measurement):
        data = {
            "__type__": "Measurement",
            "timestamp": obj.timestamp,
            "values": obj.values[:10] if preview else obj.values,
            "unit": obj.unit,
        }
        return Encdata(data=data, handeled=True, done=True)
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(measurement_encoder, enc_cls=[Measurement])

# JSON Decoder
def measurement_decoder(obj):
    if isinstance(obj, dict) and obj.get("__type__") == "Measurement":
        return Measurement(
            timestamp=obj["timestamp"],
            values=obj["values"],
            unit=obj["unit"]
        ), True
    return obj, False

JSONDecoder.add_decoder(measurement_decoder)

# Byte Encoder (for efficient binary transfer)
def measurement_byte_encoder(obj, preview=False):
    if isinstance(obj, Measurement):
        import json
        data = json.dumps({
            "timestamp": obj.timestamp,
            "values": obj.values,
            "unit": obj.unit,
        }).encode("utf-8")
        return BytesEncdata(data=data, handeled=True, mime="application/json")
    return BytesEncdata(data=obj, handeled=False)

ByteEncoder.add_encoder(measurement_byte_encoder, enc_cls=[Measurement])
```

______________________________________________________________________

## Best Practices

1. **Keep IO values serializable** ‚Äî Use JSON-compatible types or register encoders
1. **Use `enc_cls` for type-specific encoders** ‚Äî Improves performance by skipping irrelevant handlers
1. **Support preview mode** ‚Äî Truncate large data for UI display
1. **Use `done=True` for terminal encodings** ‚Äî When data is already JSON-compatible
1. **Avoid embedding large binary data** ‚Äî Use file references or ByteEncoder
1. **Register decoders for round-trip support** ‚Äî Ensure deserialization works correctly
1. **Handle edge cases** ‚Äî `None`, empty collections, `NaN` values

______________________________________________________________________

## See Also

- [Nodespace](https://linkdlab.github.io/FuncNodes/components/nodespace/index.md) ‚Äî Graph state and persistence
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî IO serialization
- [Writing Modules](https://linkdlab.github.io/FuncNodes/extending/writing-modules/index.md) ‚Äî Module development

# Shelves (Node Library Groups)

Shelves are the catalog entries that tell FuncNodes which node classes are available and how they are grouped in the UI. A shelf is a small tree that contains node classes (`funcnodes_core.node.Node`) and optional subshelves.

## Structure

- **Data model:** `funcnodes_core.lib.Shelf` holds `name`, `description`, `nodes` (list of node classes), and `subshelves` (list of Shelves). Each shelf gets a generated `shelf_id` when validated.
- **Serialization:** Shelves serialize to JSON via `funcnodes_core.lib.serialize_shelf`, emitting `name`, `description`, `nodes` (serialized node classes), and nested `subshelves`.
- **Storage:** The runtime keeps a flat registry (`funcnodes_core.lib.Library`) keyed by tuple paths (`("Top", "Child", ...)`) for GC‚Äëfriendly storage. Complete shelf trees are materialized on demand.

## How shelves are discovered

FuncNodes loads shelves from installed Python packages via the `funcnodes.module` entry point group:

- If a distribution exposes `shelf = "<pkg>:<object>"` under `project.entry-points."funcnodes.module"`, that object is read and validated with `funcnodes_core.lib.check_shelf`. Dictionaries are accepted and converted to `Shelf` instances.
- If no `shelf` entry point is present, FuncNodes falls back to introspection: every non‚Äëabstract subclass of `Node` defined in the module is collected into a shelf named after the module (`funcnodes_core.lib.libparser.module_to_shelf`).
- Additional optional entry points (`render_options`, `external_worker`, `plugin_setup`) may also be exported; they are processed in `_setup.py` but do not affect shelf discovery itself.

Example (from `modules/funcnodes_files/pyproject.toml`):

```toml
[project.entry-points."funcnodes.module"]
module = "funcnodes_files"
shelf = "funcnodes_files:NODE_SHELF"
react_plugin = "funcnodes_files:REACT_PLUGIN"
```

Here `NODE_SHELF` is the authoritative shelf object; the React plugin entry point is consumed by the UI host but does not change the shelf tree.

## How shelves are mounted at runtime

- The Workermanager/Worker loads installed modules, parses their entry points, and registers shelves into a `Library` instance attached to each `NodeSpace`.
- `Library.add_shelf` merges shelves by path, keeping node IDs unique per shelf. External shelves can be mounted via weak references (`add_external_shelf`, `add_subshelf_weak`) so they disappear automatically when their owner is GC‚Äôd.
- Finding nodes is path‚Äëaware: `Library.find_nodeid` returns all shelf paths containing a node ID, and `get_node_by_id` only succeeds if the node is both registered and referenced by at least one shelf.

## Authoring guidance for module writers

- Export a `Shelf` (or dict convertible to one) through the `funcnodes.module` entry point to get precise grouping and descriptions.
- Ensure each node class has a globally unique `node_id`; shelves store only node IDs, so duplicates are skipped when the Library deduplicates.
- Organize subshelves for UI grouping‚Äîpaths are preserved (`["Vision", "Filters", ...]`) and rendered as nested menus in the editor host.

## What is a Worker?

Workers are long-lived processes that execute FuncNodes graphs. Each worker owns:

- A **NodeSpace** (graph state, groups, properties).
- An isolated **environment** (virtualenv by default) and dependency set.
- A **data directory** (`~/.funcnodes/workers/worker_<uuid>/`) containing `nodespace.json`, uploaded `files/`, optional `pyproject.toml`, and `worker.log`.
- A **WebSocket/HTTP server** that exposes RPC commands and large-payload endpoints.

Workers are started and supervised by the **Workermanager**, but you can also launch them directly via `funcnodes worker start`.

## Runtime loops & health

The worker event loop runs several recurring tasks:

- **NodeSpaceLoop** ‚Äî drains pending triggers (`NodeSpace.await_done`) on a short interval (default 5‚ÄØms).
- **SaveLoop** ‚Äî writes process/runstate files and persists the graph when `request_save()` is flagged.
- **LocalWorkerLookupLoop** ‚Äî discovers external worker classes in `data_path/local_scripts`.
- **HeartbeatLoop** ‚Äî optional; if `required_heartbeat` is set and no `heartbeat()` RPC arrives in time, the worker stops itself.

Defaults can be tuned via worker config (e.g., `nodespace_delay`, `save_delay`) for responsiveness vs. CPU/disk usage.

## RPC surface (WebSocket JSON)

Clients send `{"type":"cmd","cmd":<name>,"kwargs":{...}}`; worker replies with `result` or `error`. Common commands:

- **Identity/meta**: `uuid`, `name`, `get_meta`, `heartbeat`
- **State**: `full_state`, `get_nodes`, `get_edges`, `get_groups`, `view_state`, `get_save_state`
- **Mutations**: `update_node`, `update_group`, `group_nodes`, `remove_group`, `clear`, `save`, `load_data`, `export_worker`, `import_worker`
- **Library/modules**: `get_library`, `get_worker_dependencies`, `get_plugin_keys`, `get_plugin`, `add_package_dependency`, `remove_package_dependency`
- **External tooling**: `list_local_workers`, `start_local_worker`, `stop_local_worker`, `upload`

Ping/pong is built in (`{"type":"ping"}` ‚Üí `{"type":"pong"}`) and is how the UI detects liveness.

## Messaging & large payloads

- Standard messages travel over WebSockets as JSON.
- Messages larger than `MESSAGE_SIZE_BEFORE_REQUEST` (default 1‚ÄØMB) are staged in memory; the worker sends a `large_message` stub and exposes a temporary HTTP endpoint `/message/<msg_id>` for retrieval.
- Binary streams (e.g., image frames) are chunked with headers `chunk=<i>/<n>` to avoid blocking the socket.
- Uploads use `POST /upload/` and are forcibly rooted to `files/` inside the worker‚Äôs data dir; attempts to traverse elsewhere are rejected.

## Lifecycle & files on disk

When running, the worker writes:

- `worker_<uuid>.json` ‚Äî config (host/port, env paths, flags)
- `worker_<uuid>.p` ‚Äî PID file for liveness detection
- `worker_<uuid>.runstate` ‚Äî human-readable status (‚Äústarting‚Ä¶‚Äù, ‚Äúrunning‚Äù, etc.)

Shutting down clears PID/runstate and flushes a final save. Exports bundle `config`, `state`, optional `pyproject.toml`, and `files/` into a ZIP for backup/migration.

## Isolation & performance

- **Process/thread offload**: Nodes can set `separate_thread=True` or `separate_process=True` to avoid blocking the event loop.
- **Message size caps**: `MAX_DATA_SIZE` (default 10‚ÄØGB) protects memory; adjust via env if needed.
- **Logging**: Per-worker rotating file handler (~100‚ÄØKB √ó 5). Change location/level via config.

## Security considerations

- Workers do **not** implement authentication. In production, front them with an authenticated proxy (e.g., nginx/Traefik) and keep ports non-public. File writes are constrained to `files/`, but you should still sandbox network access and enforce upload size limits at the proxy.
- TLS termination is not provided by the worker itself; the `ssl` field in the config defaults to `False` and the WebSocket loop always starts plain HTTP. Terminate TLS in your proxy/load balancer instead.

## Environments & dependencies

- New workers create their own virtualenv unless started with `--not-in-venv`; sharing the interpreter is possible but increases the risk of version conflicts.
- The worker config carries `update_on_startup` flags (default `True` for `funcnodes`, `funcnodes-core`, `funcnodes-worker`) so core packages can be upgraded automatically when a worker starts.
- Additional packages installed via `funcnodes worker ... modules install ...` are tracked per worker in `package_dependencies`; isolated envs let different workers pin incompatible versions safely.

## Subprocess/offload options

- `@NodeDecorator(..., separate_thread=True)` runs the wrapped function in a thread; `separate_process=True` wraps it in a `ProcessPoolExecutor` (`funcnodes_core.utils.functions.make_run_in_new_process`).
- Workers expose an optional `subprocess_monitor` host/port in their config; if set, heavy external commands can be supervised by the `subprocess_monitor` service. FuncNodes itself does not enforce per-node resource limits‚Äîrely on the monitor/OS for that.

# Worker Configuration

Each worker keeps its own config file at `~/.funcnodes/workers/worker_<uuid>.json`. Key fields include:

- **uuid** / **name** ‚Äî worker identity.
- **data_path** ‚Äî worker data dir (nodespace.json, files/, logs).
- **env_path** ‚Äî virtualenv location (absent when created with `--not-in-venv`).
- **host/port/ssl** ‚Äî where the worker‚Äôs WS/HTTP server listens.
- **update_on_startup** ‚Äî flags to auto-upgrade `funcnodes`, `funcnodes-core`, and unpinned dependencies on activation.
- **nodespace_path** ‚Äî path to the current NodeSpace state file.
- **required_heartbeat** ‚Äî optional timeout for heartbeat enforcement.
- **workertype** ‚Äî worker class (defaults to WSWorker; extension point for external workers).
- **subprocess_monitor** ‚Äî optional host/port if using the subprocess monitor.

Creation and lifecycle:

- Generated when you run `funcnodes worker new ...`; updated when workers start/stop.
- The Workermanager reads this file to decide how to spawn and to report status.
- Edits can be made manually for advanced tuning (e.g., changing host/port) ‚Äî stop the worker first, edit, then restart.

Related liveness files:

- `worker_<uuid>.p` ‚Äî PID of the running process.
- `worker_<uuid>.runstate` ‚Äî human-readable startup/run status used by the UI.

## What is the Workermanager?

The Workermanager is a lightweight aiohttp service that supervises all workers on a host. It:

- Maintains worker metadata on disk (`~/.funcnodes/workers/worker_<uuid>.json/.p/.runstate`).
- Spawns, stops, restarts, deletes, and lists workers.
- Acts as a WebSocket hub so UIs can discover and control workers.
- Optionally provisions per-worker virtualenvs and upgrades packages on activation.

By default it listens on `localhost:9380` at `/` for WebSocket clients (no auth by default‚Äîsee Security).

## Message protocol (WebSocket)

Simple string commands:

- `ping` ‚Üí `pong`
- `identify` ‚Üí JSON `{ "class": "WorkerManager", "py": sys.executable }`
- `worker_status` ‚Üí lists active/inactive workers
- `stop` ‚Üí stop the manager

JSON commands (selected):

- `{ "type": "new_worker", "kwargs": {...} }` ‚Üí create worker (options: name, reference, copyLib, copyNS, in_venv toggle)
- `{ "type": "set_active", "workerid": uuid }` ‚Üí activate (start) worker
- `{ "type": "stop_worker", "workerid": uuid }`
- `{ "type": "restart_worker", "workerid": uuid }`
- `{ "type": "delete_worker", "workerid": uuid }`

Responses/broadcasts include:

- `worker_status` (active/inactive lists)
- `worker_created` / `worker_deleted`
- `set_worker` (full worker config once reachable)
- `progress` (text + progress float) to drive UI HUDs

## Files & liveness

Each worker has:

- `worker_<uuid>.json` ‚Äî config (host/port/env paths/nodespace path/flags)
- `worker_<uuid>.p` ‚Äî PID file written by the worker
- `worker_<uuid>.runstate` ‚Äî textual status during startup/running

Missing or stale files mark workers as inactive; status is refreshed every ~10‚ÄØs.

## Virtualenv & dependency management

- New workers default to their own venv unless `--not-in-venv` was set.
- On activation, optional `update_on_startup` flags can reinstall `funcnodes`, `funcnodes-core`, and unpinned dependencies.
- CLI helpers `funcnodes worker modules ‚Ä¶` run inside the worker env.

## Auto-start behavior

Clients (e.g., `funcnodes runserver`) call `assert_worker_manager_running`: it pings/identifies the manager and, if unreachable, spawns a fresh instance via `python -m funcnodes startworkermanager` (optionally through `subprocess_monitor`).

## Security

- No built-in authentication; expose only behind an authenticated reverse proxy.
- Keep the WS/HTTP ports private; block direct internet access.
- Size limits: large message/store defaults come from worker settings (`MAX_DATA_SIZE`, message expiry).
- TLS termination is not handled by the Workermanager itself; it serves plain HTTP/WebSocket. Terminate TLS at your proxy/load balancer if you need HTTPS/WSS.

## Operations cheat sheet

- Start manager: `funcnodes startworkermanager --host 0.0.0.0 --port 9380`
- List workers: `funcnodes worker list [--full]`
- New worker: `funcnodes worker new --name demo`
- Start worker: `funcnodes worker --name demo start`
- Delete worker: `funcnodes worker --name demo delete`
# Architecture

# Core Components (`funcnodes_core`)

The `funcnodes_core` package provides the fundamental building blocks for the FuncNodes runtime. This document explains its internal architecture and key classes.

______________________________________________________________________

## Package Structure

```text
funcnodes_core/
‚îú‚îÄ‚îÄ __init__.py           # Public API exports
‚îú‚îÄ‚îÄ node.py               # Node, NodeDecorator
‚îú‚îÄ‚îÄ nodeio.py             # NodeIO, NodeInput, NodeOutput
‚îú‚îÄ‚îÄ nodespace.py          # NodeSpace (graph container)
‚îú‚îÄ‚îÄ lib.py                # Library, Shelf
‚îú‚îÄ‚îÄ config.py             # Configuration management
‚îú‚îÄ‚îÄ io_hooks.py           # IO update decorators
‚îú‚îÄ‚îÄ eventmanager.py       # Event subscription system
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ serialization.py  # JSON encoder/decoder
    ‚îú‚îÄ‚îÄ functions.py      # Async helpers, process wrappers
    ‚îî‚îÄ‚îÄ data.py           # DataEnum, NoValue
```

______________________________________________________________________

## Node System

### Node Class Hierarchy

```
classDiagram
    class object {
    }

    class Node {
        +node_id: str
        +node_name: str
        +inputs: Dict
        +outputs: Dict
        +func()
    }

    class CustomNode {
        (user subclass)
    }

    class DecoratorNode {
        (generated from @NodeDecorator)
    }

    class PlaceHolderNode {
        (missing class fallback)
    }

    object <|-- Node : Base class for all nodes
    Node <|-- CustomNode
    Node <|-- DecoratorNode
    Node <|-- PlaceHolderNode
```

### Node Lifecycle

```python
# 1. Class Definition (at import time)
class MyNode(fn.Node):
    node_id = "my_module.my_node"
    node_name = "My Node"

    input1 = fn.NodeInput(id="input1", type=int)
    output1 = fn.NodeOutput(id="output1", type=int)

    async def func(self, input1):
        self.outputs["output1"].value = input1 * 2

# 2. Registration (module load)
# Node class is registered in Library via shelf

# 3. Instantiation (adding to graph)
node_instance = MyNode()  # Creates unique UUID
nodespace.add_node(node_instance)

# 4. Execution (triggered by input change)
await node_instance.trigger()  # Calls func() if inputs ready

# 5. Cleanup (removal)
nodespace.remove_node(node_instance.uuid)
```

### NodeDecorator Internals

The `@fn.NodeDecorator` creates a Node subclass dynamically:

```python
@fn.NodeDecorator(node_id="add_numbers", name="Add")
def add(a: int, b: int) -> int:
    return a + b

# Equivalent to:
class add(fn.Node):
    node_id = "add_numbers"
    node_name = "Add"

    a = fn.NodeInput(id="a", type=int)
    b = fn.NodeInput(id="b", type=int)
    out = fn.NodeOutput(id="out", type=int)

    async def func(self, a, b):
        result = add._original_func(a, b)
        self.outputs["out"].value = result
```

**Key transformations:**

1. Function parameters ‚Üí `NodeInput` instances
1. Return type annotation ‚Üí `NodeOutput` type
1. Return value ‚Üí Assigned to output
1. Sync functions wrapped in async

______________________________________________________________________

## IO System

### NodeIO Base Class

```python
class NodeIO:
    """Base class for inputs and outputs."""

    # Identity
    uuid: str              # Unique identifier
    id: str                # Name/key (from parameter name)

    # Type info
    type: Type             # Python type hint

    # Value
    _value: Any            # Current value (use .value property)
    default: Any           # Default value

    # Behavior
    allow_multiple: bool   # Multiple connections allowed?
    hidden: bool           # Hidden from UI?

    # Options
    render_options: dict   # UI rendering hints
    value_options: dict    # Constraints (min, max, options)

    # Connections
    connections: List[NodeIO]  # Connected IOs
```

### NodeInput Specifics

```python
class NodeInput(NodeIO):
    does_trigger: bool = True    # Setting value triggers node?
    required: bool = True        # Must have value to execute?

    def set_value(self, value, does_trigger=True, emit_value_set=True):
        """Set input value, optionally triggering the node."""
        self._value = value
        if emit_value_set:
            self.emit("after_set_value", value)
        if does_trigger and self.does_trigger:
            self.node.request_trigger()
```

### NodeOutput Specifics

```python
class NodeOutput(NodeIO):
    allow_multiple: bool = True  # Default: multiple connections

    @property
    def value(self):
        return self._value

    @value.setter
    def value(self, new_value):
        self._value = new_value
        # Propagate to all connected inputs
        for connected_input in self.connections:
            connected_input.set_value(new_value)
```

### NoValue Sentinel

```python
class NoValue:
    """Represents absence of a value (distinct from None)."""
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

# Usage
if input.value is NoValue:
    # Input has no value set
    pass
```

**NoValue semantics:**

- Default state for unset inputs
- Suppresses downstream triggering when set
- Distinct from `None` (which is a valid value)
- Reset state when disconnecting inputs

______________________________________________________________________

## NodeSpace

The `NodeSpace` is the in-memory graph container:

```python
class NodeSpace:
    """Container for a node graph."""

    # Storage
    _nodes: Dict[str, Node]           # UUID ‚Üí Node instance
    _edges: List[Tuple[str, str, str, str]]  # Connections
    _lib: Library                     # Available node classes

    # Properties
    prop: Dict[str, Any]              # Serializable properties
    secret: Dict[str, Any]            # Non-serialized runtime state

    # Methods
    def add_node(self, node: Node) -> None
    def remove_node(self, uuid: str) -> None
    def add_edge(self, src_uuid, src_io, dst_uuid, dst_io) -> None
    def remove_edge(self, src_uuid, src_io, dst_uuid, dst_io) -> None

    # Serialization
    def serialize(self) -> NodeSpaceJSON
    def full_serialize(self, with_io_values=False) -> FullNodeSpaceJSON

    @classmethod
    def deserialize(cls, data: dict, lib: Library) -> NodeSpace
```

### Serialization Format

```json
{
  "nodes": [
    {
      "node_id": "funcnodes_basic.math.add",
      "uuid": "abc-123",
      "frontend": { "pos": [100, 200] },
      "io": {
        "a": { "value": 5 },
        "b": { "value": 3 }
      }
    }
  ],
  "edges": [
    {
      "src": ["node-1", "out"],
      "dst": ["node-2", "a"]
    }
  ],
  "prop": {
    "name": "My Workflow"
  },
  "groups": []
}
```

______________________________________________________________________

## Library System

### Library Class

```python
class Library:
    """Registry of node classes organized by shelf paths."""

    _records: Dict[Tuple[str, ...], _ShelfRecord]

    def add_shelf(self, shelf: Shelf) -> None
        """Add a shelf (and all its nodes) to the library."""

    def add_node(self, path: Tuple[str, ...], node_class: Type[Node]) -> None
        """Add a single node class to a shelf path."""

    def get_node_by_id(self, node_id: str) -> Type[Node]
        """Look up a node class by its node_id."""

    def find_nodeid(self, node_id: str) -> List[Tuple[str, ...]]
        """Find all shelf paths containing a node_id."""

    def full_serialize(self) -> dict
        """Serialize all shelves for transmission to UI."""
```

### Shelf Structure

```python
@dataclass
class Shelf:
    name: str
    description: str = ""
    nodes: List[Type[Node]] = field(default_factory=list)
    subshelves: List[Shelf] = field(default_factory=list)

# Example shelf hierarchy:
root_shelf = Shelf(
    name="funcnodes_numpy",
    description="NumPy operations",
    subshelves=[
        Shelf(name="creation", nodes=[zeros, ones, eye, ...]),
        Shelf(name="manipulation", nodes=[reshape, transpose, ...]),
        Shelf(name="math", nodes=[add, multiply, ...]),
    ]
)
```

### Module Discovery

```python
# Entry point in pyproject.toml:
[project.entry-points."funcnodes.module"]
module = "funcnodes_numpy"
shelf = "funcnodes_numpy:NODE_SHELF"

# Discovery process:
def discover_modules():
    for dist in importlib.metadata.distributions():
        eps = dist.entry_points
        if "funcnodes.module" in eps.groups:
            for ep in eps["funcnodes.module"]:
                if ep.name == "shelf":
                    shelf = ep.load()
                    library.add_shelf(shelf)
```

______________________________________________________________________

## Configuration

### Config Structure

```python
@dataclass
class FuncNodesConfig:
    env_dir: Path                    # Base directory
    worker_manager: WorkerManagerConfig
    frontend: FrontendConfig
    nodes: NodesConfig
    logging: LoggingConfig
    render_options: RenderOptionsConfig

@dataclass
class WorkerManagerConfig:
    host: str = "localhost"
    port: int = 9380
    ssl: bool = False

@dataclass
class NodesConfig:
    pretrigger_delay: float = 0.0    # Delay before triggering
```

### Config File Location

```text
~/.funcnodes/config.json
# or
$FUNCNODES_CONFIG_DIR/config.json
# or
--dir .funcnodes ‚Üí .funcnodes/config.json
```

### Config Loading

```python
def get_config() -> FuncNodesConfig:
    """Load config, creating defaults if needed."""
    config_path = get_config_dir() / "config.json"

    if config_path.exists():
        config = load_config(config_path)
    else:
        config = FuncNodesConfig()
        save_config(config, config_path)

    return config
```

______________________________________________________________________

## Event System

The core uses an event emitter pattern:

```python
class EventEmitter:
    _listeners: Dict[str, List[Callable]]

    def on(self, event: str, callback: Callable) -> None
        """Subscribe to an event."""

    def off(self, event: str, callback: Callable) -> None
        """Unsubscribe from an event."""

    def emit(self, event: str, *args, **kwargs) -> None
        """Emit an event to all subscribers."""

# Node events
node.on("trigger", callback)
node.on("error", callback)

# IO events
input.on("after_set_value", callback)
output.on("value_changed", callback)

# NodeSpace events
nodespace.on("node_added", callback)
nodespace.on("node_removed", callback)
nodespace.on("edge_added", callback)
```

See [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) for the complete event reference.

______________________________________________________________________

## Utility Functions

### Async Helpers

```python
# Run sync function in thread pool
async def run_in_thread(func, *args, **kwargs):
    return await asyncio.to_thread(func, *args, **kwargs)

# Run function in separate process
def make_run_in_new_process(func):
    """Decorator to run function in ProcessPoolExecutor."""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            ProcessPoolExecutor(),
            partial(func, *args, **kwargs)
        )
    return wrapper
```

### Serialization

```python
class FuncNodesJSONEncoder(json.JSONEncoder):
    """Extended JSON encoder for FuncNodes types."""

    def default(self, obj):
        # NumPy arrays
        if isinstance(obj, np.ndarray):
            return {"__ndarray__": obj.tolist(), "dtype": str(obj.dtype)}

        # DataEnum
        if isinstance(obj, DataEnum):
            return {"__dataenum__": type(obj).__name__, "value": obj.value}

        # datetime
        if isinstance(obj, datetime):
            return {"__datetime__": obj.isoformat()}

        return super().default(obj)
```

______________________________________________________________________

## See Also

- [Architecture Overview](https://linkdlab.github.io/FuncNodes/architecture/overview/index.md) ‚Äî System-level view
- [Worker Components](https://linkdlab.github.io/FuncNodes/architecture/worker-components/index.md) ‚Äî Worker runtime
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event reference
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî User guide

# Event System

FuncNodes uses an event-driven architecture where components communicate through events. This document describes the event system and all available events.

______________________________________________________________________

## Overview

```
flowchart LR
    subgraph EventFlow["Event Flow"]
        Emitter["Emitter"]
        Queue["Event Queue"]

        subgraph Listeners["Listeners"]
            Internal["Internal Handler"]
            WS["WebSocket Relay"]
            Custom["Custom Handler"]
        end

        UI["üñ•Ô∏è UI"]
    end

    Emitter -->|"emit()"| Queue
    Queue -->|dispatch| Internal
    Queue -->|dispatch| WS
    Queue -->|dispatch| Custom
    WS --> UI
```

______________________________________________________________________

## EventEmitter Base

All event-emitting components inherit from `EventEmitter`:

```python
from funcnodes_core.eventmanager import EventEmitter

class MyComponent(EventEmitter):
    def do_something(self):
        # ... do work ...
        self.emit("something_done", result=42)

# Subscribe to events
component = MyComponent()
component.on("something_done", lambda result: print(f"Got {result}"))

# Unsubscribe
component.off("something_done", handler)

# One-time listener
component.once("something_done", handler)
```

### API

| Method                         | Description                 |
| ------------------------------ | --------------------------- |
| `on(event, callback)`          | Subscribe to event          |
| `off(event, callback)`         | Unsubscribe from event      |
| `once(event, callback)`        | Subscribe for single event  |
| `emit(event, *args, **kwargs)` | Emit event to listeners     |
| `listeners(event)`             | Get all listeners for event |
| `remove_all_listeners(event)`  | Remove all listeners        |

______________________________________________________________________

## Node Events

### Trigger Events

Events related to node execution:

#### `before_trigger`

Emitted before node execution begins:

```python
node.on("before_trigger", lambda: print("About to execute"))
```

**Use cases:**

- Validation before execution
- Logging/profiling start

#### `after_trigger`

Emitted after node execution completes:

```python
node.on("after_trigger", lambda: print("Execution complete"))
```

**Use cases:**

- Cleanup operations
- Logging/profiling end
- Cascading updates

#### `trigger_error`

Emitted when node execution fails:

```python
node.on("trigger_error", lambda error: print(f"Error: {error}"))
```

**Payload:**

- `error`: Exception that was raised
- `traceback`: Full traceback string

### Progress Events

#### `progress`

Emitted during long-running operations:

```python
node.on("progress", lambda p, msg: print(f"{p*100:.0f}%: {msg}"))
```

**Payload:**

- `progress`: Float 0.0 to 1.0
- `message`: Optional status message

**Emitting progress:**

```python
class MyNode(fn.Node):
    async def func(self, data):
        for i, item in enumerate(self.progress(data)):
            process(item)
            # Progress automatically emitted
```

______________________________________________________________________

## IO Events

### NodeInput Events

#### `after_set_value`

Emitted when an input value changes:

```python
input.on("after_set_value", lambda value: print(f"New value: {value}"))
```

**When emitted:**

- Manual value set via `input.set_value()`
- Value received from connected output
- UI sets value via RPC

**Options:**

- `emit_value_set=False` suppresses this event
- `does_trigger=False` prevents node triggering

#### `value_options_changed`

Emitted when value constraints change:

```python
input.on("value_options_changed", lambda opts: update_ui(opts))
```

**Payload:** New `value_options` dict

#### `render_options_changed`

Emitted when render hints change:

```python
input.on("render_options_changed", lambda opts: update_ui(opts))
```

**Payload:** New `render_options` dict

### NodeOutput Events

#### `value_changed`

Emitted when output value changes:

```python
output.on("value_changed", lambda value: print(f"Output: {value}"))
```

**Triggered by:**

- Setting `output.value = x`
- Return value from decorated function

______________________________________________________________________

## Connection Events

### `connected`

Emitted when an IO is connected:

```python
io.on("connected", lambda other_io: print(f"Connected to {other_io.id}"))
```

### `disconnected`

Emitted when an IO is disconnected:

```python
io.on("disconnected", lambda other_io: print(f"Disconnected from {other_io.id}"))
```

______________________________________________________________________

## NodeSpace Events

### Node Lifecycle

#### `node_added`

Emitted when a node is added to the graph:

```python
nodespace.on("node_added", lambda node: print(f"Added: {node.node_id}"))
```

**Payload:** Node instance

#### `node_removed`

Emitted when a node is removed:

```python
nodespace.on("node_removed", lambda uuid: print(f"Removed: {uuid}"))
```

**Payload:** Node UUID string

### Edge Lifecycle

#### `edge_added`

Emitted when a connection is created:

```python
nodespace.on("edge_added", lambda src, dst: print(f"Connected {src} ‚Üí {dst}"))
```

**Payload:**

- `src`: Tuple of (node_uuid, io_id)
- `dst`: Tuple of (node_uuid, io_id)

#### `edge_removed`

Emitted when a connection is removed:

```python
nodespace.on("edge_removed", lambda src, dst: print(f"Disconnected {src} ‚Üí {dst}"))
```

### Execution Events

#### `node_triggered`

Emitted when a node starts execution:

```python
nodespace.on("node_triggered", lambda uuid: print(f"Triggered: {uuid}"))
```

#### `node_done`

Emitted when a node completes execution:

```python
nodespace.on("node_done", lambda uuid: print(f"Done: {uuid}"))
```

#### `node_error`

Emitted when a node execution fails:

```python
nodespace.on("node_error", lambda uuid, error: print(f"Error in {uuid}: {error}"))
```

**Payload:**

- `uuid`: Node UUID
- `error`: Exception message
- `traceback`: Full traceback

### State Events

#### `cleared`

Emitted when nodespace is cleared:

```python
nodespace.on("cleared", lambda: print("Graph cleared"))
```

#### `loaded`

Emitted after loading state:

```python
nodespace.on("loaded", lambda: print("Graph loaded"))
```

______________________________________________________________________

## Worker Events

### Lifecycle

#### `starting`

Emitted when worker begins startup:

```python
worker.on("starting", lambda: print("Worker starting..."))
```

#### `ready`

Emitted when worker is fully initialized:

```python
worker.on("ready", lambda: print("Worker ready"))
```

#### `stopping`

Emitted when worker begins shutdown:

```python
worker.on("stopping", lambda: print("Worker stopping..."))
```

#### `stopped`

Emitted after worker cleanup:

```python
worker.on("stopped", lambda: print("Worker stopped"))
```

### Client Events

#### `client_connected`

Emitted when a WebSocket client connects:

```python
worker.on("client_connected", lambda ws: print("Client connected"))
```

#### `client_disconnected`

Emitted when a client disconnects:

```python
worker.on("client_disconnected", lambda ws: print("Client disconnected"))
```

______________________________________________________________________

## Event Propagation

### Trigger Cascade

When an input value changes, events cascade through the graph:

```
flowchart TD
    SetValue["Input.set_value()"]

    EmitAfterSet["emit('after_set_value')"]
    RequestTrigger["Node.request_trigger()"]

    EmitBefore["emit('before_trigger')"]
    AwaitFunc["await func()"]
    SetOutput["Output.value = result"]
    EmitValueChanged["emit('value_changed')"]
    ConnectedInputs["Connected inputs..."]
    Cascade["(cascade continues)"]
    EmitAfter["emit('after_trigger')"]

    SetValue --> EmitAfterSet
    SetValue --> RequestTrigger

    RequestTrigger --> EmitBefore
    RequestTrigger --> AwaitFunc
    RequestTrigger --> EmitAfter

    AwaitFunc --> SetOutput
    SetOutput --> EmitValueChanged
    EmitValueChanged --> ConnectedInputs
    ConnectedInputs -.-> Cascade
```

### Event Relay to UI

The worker relays nodespace events to connected WebSocket clients:

```python
# Internal setup (simplified)
def setup_event_relay(nodespace, worker):
    def relay_to_clients(event_name):
        def handler(*args, **kwargs):
            worker.broadcast({
                "type": "nodespaceevent",
                "event": event_name,
                "data": serialize_event_data(args, kwargs)
            })
        return handler

    for event in RELAYED_EVENTS:
        nodespace.on(event, relay_to_clients(event))
```

**Relayed events:**

- `node_added`, `node_removed`
- `edge_added`, `edge_removed`
- `node_triggered`, `node_done`, `node_error`
- `io_value_changed`
- `node_progress`

______________________________________________________________________

## Custom Event Handlers

### Subscribing in Nodes

Class-based nodes can subscribe to their own events:

```python
class MyNode(fn.Node):
    node_id = "my_node"

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.on("before_trigger", self._log_start)
        self.on("after_trigger", self._log_end)

    def _log_start(self):
        print(f"Node {self.uuid} starting")

    def _log_end(self):
        print(f"Node {self.uuid} finished")
```

### NodeSpace Event Hooks

Workers can add custom handlers:

```python
class MyWorker(WSWorker):
    async def setup(self):
        await super().setup()
        self.nodespace.on("node_error", self._handle_error)

    def _handle_error(self, uuid, error, traceback):
        # Custom error handling
        send_alert(f"Node {uuid} failed: {error}")
```

______________________________________________________________________

## Dynamic IO Updates

### `@update_other_io_options`

Decorator to rebuild dropdown options when an input changes:

```python
from funcnodes_core.io_hooks import update_other_io_options

@fn.NodeDecorator(node_id="column_selector")
@update_other_io_options("column", modifier=lambda df: df.columns.tolist())
def select_column(df: pd.DataFrame, column: str) -> pd.Series:
    return df[column]
```

**How it works:**

1. When `df` input changes, modifier is called
1. Result becomes `column.value_options["options"]`
1. `value_options_changed` event fires
1. UI updates dropdown

### `@update_other_io_value_options`

Decorator to update numeric constraints:

```python
from funcnodes_core.io_hooks import update_other_io_value_options

@fn.NodeDecorator(node_id="list_get")
@update_other_io_value_options("index", options_generator=lambda lst: {
    "min": 0,
    "max": len(lst) - 1 if lst else 0
})
def list_get(lst: list, index: int) -> Any:
    return lst[index]
```

______________________________________________________________________

## Event Best Practices

### Do

‚úÖ Use events for loose coupling between components ‚úÖ Keep event handlers fast (offload heavy work) ‚úÖ Clean up listeners when components are destroyed ‚úÖ Use `once()` for one-time setup handlers ‚úÖ Document custom events in node docstrings

### Don't

‚ùå Create circular event chains (A‚ÜíB‚ÜíA) ‚ùå Rely on event ordering between different emitters ‚ùå Block in event handlers (use async if needed) ‚ùå Emit events during `__init__` (object not ready) ‚ùå Store sensitive data in event payloads

______________________________________________________________________

## See Also

- [Architecture Overview](https://linkdlab.github.io/FuncNodes/architecture/overview/index.md) ‚Äî System diagram
- [Core Components](https://linkdlab.github.io/FuncNodes/architecture/core-components/index.md) ‚Äî Event emitter implementation
- [Message Protocol](https://linkdlab.github.io/FuncNodes/architecture/message-protocol/index.md) ‚Äî WebSocket event relay
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî IO events

# Message Protocol

This document describes the WebSocket and HTTP communication protocols used between FuncNodes components.

______________________________________________________________________

## Protocol Overview

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          WebSocket (JSON)           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ             ‚îÇ
‚îÇ   Frontend  ‚îÇ                                     ‚îÇ   Worker    ‚îÇ
‚îÇ    (UI)     ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ             ‚îÇ
‚îÇ             ‚îÇ          WebSocket (JSON)           ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                                                   ‚îÇ
       ‚îÇ  HTTP (large payloads, uploads)                   ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          WebSocket (JSON)           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ                 ‚îÇ
‚îÇ   Frontend  ‚îÇ                                     ‚îÇ  Workermanager  ‚îÇ
‚îÇ    (UI)     ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ                 ‚îÇ
‚îÇ             ‚îÇ          WebSocket (JSON)           ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

______________________________________________________________________

## Message Structure

### Base Message Format

All WebSocket messages are JSON objects with a `type` field:

```json
{
  "type": "<message_type>",
  ...additional fields...
}
```

### Message Types

| Type             | Direction       | Description             |
| ---------------- | --------------- | ----------------------- |
| `ping`           | Client ‚Üí Server | Heartbeat request       |
| `pong`           | Server ‚Üí Client | Heartbeat response      |
| `cmd`            | Client ‚Üí Server | RPC command             |
| `result`         | Server ‚Üí Client | Command response        |
| `error`          | Server ‚Üí Client | Command error           |
| `nodespaceevent` | Server ‚Üí Client | Graph state change      |
| `large_message`  | Server ‚Üí Client | Large payload indicator |
| `progress`       | Server ‚Üí Client | Operation progress      |

______________________________________________________________________

## Workermanager Protocol

### Connection

```text
ws://localhost:9380/
```

### Commands (String)

Simple string commands for basic operations:

| Command         | Response    | Description            |
| --------------- | ----------- | ---------------------- |
| `ping`          | `pong`      | Connectivity check     |
| `identify`      | JSON object | Get manager identity   |
| `worker_status` | JSON object | Get all workers status |
| `stop`          | -           | Stop the manager       |

**identify response:**

```json
{
  "class": "WorkerManager",
  "py": "/usr/bin/python3"
}
```

**worker_status response:**

```json
{
  "active": [
    {
      "uuid": "abc123",
      "name": "my-workflow",
      "host": "localhost",
      "port": 9382
    }
  ],
  "inactive": [
    {
      "uuid": "def456",
      "name": "other-workflow"
    }
  ]
}
```

### Commands (JSON)

Complex operations use JSON format:

#### new_worker

Create a new worker:

```json
// Request
{
  "type": "new_worker",
  "kwargs": {
    "name": "my-workflow",
    "copyLib": false,
    "copyNS": false,
    "in_venv": true,
    "reference": null
  }
}

// Response (broadcast)
{
  "type": "worker_created",
  "worker": {
    "uuid": "abc123",
    "name": "my-workflow",
    "data_path": "~/.funcnodes/workers/worker_my-workflow"
  }
}
```

#### set_active

Start a worker:

```json
// Request
{
  "type": "set_active",
  "workerid": "abc123"
}

// Response (broadcast)
{
  "type": "set_worker",
  "worker": {
    "uuid": "abc123",
    "host": "localhost",
    "port": 9382,
    "status": "running"
  }
}
```

#### stop_worker

Stop a running worker:

```json
{
  "type": "stop_worker",
  "workerid": "abc123"
}
```

#### restart_worker

Restart a worker:

```json
{
  "type": "restart_worker",
  "workerid": "abc123"
}
```

#### delete_worker

Delete a worker and its data:

```json
// Request
{
  "type": "delete_worker",
  "workerid": "abc123"
}

// Response (broadcast)
{
  "type": "worker_deleted",
  "workerid": "abc123"
}
```

### Progress Events

Long operations broadcast progress:

```json
{
  "type": "progress",
  "workerid": "abc123",
  "text": "Installing dependencies...",
  "progress": 0.45
}
```

______________________________________________________________________

## Worker Protocol

### Connection

```text
ws://localhost:{worker_port}/
```

Default ports start at 9382 and increment for each worker.

### Basic Commands

#### ping/pong

```json
// Request
{"type": "ping"}

// Response
{"type": "pong"}
```

#### uuid

Get worker UUID:

```json
// Request
{"type": "cmd", "cmd": "uuid"}

// Response
{"type": "result", "cmd": "uuid", "result": "abc123"}
```

#### name

Get worker name:

```json
// Request
{"type": "cmd", "cmd": "name"}

// Response
{"type": "result", "cmd": "name", "result": "my-workflow"}
```

#### heartbeat

Keep worker alive (when `required_heartbeat` is set):

```json
{"type": "cmd", "cmd": "heartbeat"}
```

### State Commands

#### full_state

Get complete worker state:

```json
// Request
{"type": "cmd", "cmd": "full_state"}

// Response
{
  "type": "result",
  "cmd": "full_state",
  "result": {
    "nodespace": {
      "nodes": [...],
      "edges": [...],
      "prop": {...}
    },
    "lib": {
      "shelves": [...]
    },
    "worker": {
      "uuid": "abc123",
      "name": "my-workflow"
    }
  }
}
```

#### get_nodes

Get all nodes in the graph:

```json
// Request
{"type": "cmd", "cmd": "get_nodes"}

// Response
{
  "type": "result",
  "cmd": "get_nodes",
  "result": [
    {
      "node_id": "funcnodes_basic.math.add",
      "uuid": "node-1",
      "name": "Add",
      "inputs": {...},
      "outputs": {...}
    }
  ]
}
```

#### get_edges

Get all connections:

```json
// Request
{"type": "cmd", "cmd": "get_edges"}

// Response
{
  "type": "result",
  "cmd": "get_edges",
  "result": [
    {
      "src": ["node-1", "out"],
      "dst": ["node-2", "a"]
    }
  ]
}
```

#### get_library

Get available node shelves:

```json
// Request
{"type": "cmd", "cmd": "get_library"}

// Response
{
  "type": "result",
  "cmd": "get_library",
  "result": {
    "shelves": [
      {
        "name": "funcnodes_basic",
        "subshelves": [
          {
            "name": "math",
            "nodes": [
              {"node_id": "funcnodes_basic.math.add", "name": "Add"}
            ]
          }
        ]
      }
    ]
  }
}
```

### Mutation Commands

#### add_node

Add a node to the graph:

```json
// Request
{
  "type": "cmd",
  "cmd": "add_node",
  "kwargs": {
    "node_id": "funcnodes_basic.math.add",
    "uuid": "node-new-1",  // optional, auto-generated if omitted
    "frontend": {
      "pos": [100, 200]
    }
  }
}

// Response
{
  "type": "result",
  "cmd": "add_node",
  "result": {
    "uuid": "node-new-1",
    "node_id": "funcnodes_basic.math.add"
  }
}
```

#### remove_node

Remove a node:

```json
{
  "type": "cmd",
  "cmd": "remove_node",
  "kwargs": {
    "uuid": "node-1"
  }
}
```

#### update_node

Update a node's input or properties:

```json
// Set input value
{
  "type": "cmd",
  "cmd": "update_node",
  "kwargs": {
    "uuid": "node-1",
    "io_id": "a",
    "io_type": "input",
    "value": 42
  }
}

// Update frontend position
{
  "type": "cmd",
  "cmd": "update_node",
  "kwargs": {
    "uuid": "node-1",
    "frontend": {
      "pos": [150, 250]
    }
  }
}
```

#### add_edge

Create a connection:

```json
{
  "type": "cmd",
  "cmd": "add_edge",
  "kwargs": {
    "src_uuid": "node-1",
    "src_io": "out",
    "dst_uuid": "node-2",
    "dst_io": "a"
  }
}
```

#### remove_edge

Remove a connection:

```json
{
  "type": "cmd",
  "cmd": "remove_edge",
  "kwargs": {
    "src_uuid": "node-1",
    "src_io": "out",
    "dst_uuid": "node-2",
    "dst_io": "a"
  }
}
```

#### clear

Clear all nodes and edges:

```json
{
  "type": "cmd",
  "cmd": "clear"
}
```

### Module Commands

#### get_worker_dependencies

Get installed package dependencies:

```json
// Request
{"type": "cmd", "cmd": "get_worker_dependencies"}

// Response
{
  "type": "result",
  "cmd": "get_worker_dependencies",
  "result": {
    "funcnodes-basic": {"package": "funcnodes-basic", "version": "0.2.1"},
    "funcnodes-numpy": {"package": "funcnodes-numpy", "version": "0.2.5"}
  }
}
```

#### add_package_dependency

Install a module:

```json
{
  "type": "cmd",
  "cmd": "add_package_dependency",
  "kwargs": {
    "package": "funcnodes-plotly",
    "version": null  // or specific version
  }
}
```

#### remove_package_dependency

Uninstall a module:

```json
{
  "type": "cmd",
  "cmd": "remove_package_dependency",
  "kwargs": {
    "package": "funcnodes-plotly"
  }
}
```

### Import/Export Commands

#### export_worker

Export worker as ZIP:

```json
// Request
{
  "type": "cmd",
  "cmd": "export_worker",
  "kwargs": {
    "include_files": true
  }
}

// Response contains base64-encoded ZIP or large_message reference
```

#### import_worker

Import from ZIP:

```json
{
  "type": "cmd",
  "cmd": "import_worker",
  "kwargs": {
    "data": "<base64-encoded-zip>"
  }
}
```

#### load_data

Load nodespace from JSON:

```json
{
  "type": "cmd",
  "cmd": "load_data",
  "kwargs": {
    "data": {
      "nodes": [...],
      "edges": [...]
    }
  }
}
```

### Group Commands

#### get_groups

Get node groups:

```json
// Request
{"type": "cmd", "cmd": "get_groups"}

// Response
{
  "type": "result",
  "cmd": "get_groups",
  "result": [
    {
      "id": "group-1",
      "name": "Data Processing",
      "nodes": ["node-1", "node-2"]
    }
  ]
}
```

#### group_nodes

Create a group:

```json
{
  "type": "cmd",
  "cmd": "group_nodes",
  "kwargs": {
    "nodes": ["node-1", "node-2"],
    "name": "Data Processing"
  }
}
```

______________________________________________________________________

## NodeSpace Events

Workers broadcast state changes to all connected clients:

### node_added

```json
{
  "type": "nodespaceevent",
  "event": "node_added",
  "data": {
    "uuid": "node-1",
    "node_id": "funcnodes_basic.math.add",
    "serialized": {...}
  }
}
```

### node_removed

```json
{
  "type": "nodespaceevent",
  "event": "node_removed",
  "data": {
    "uuid": "node-1"
  }
}
```

### edge_added

```json
{
  "type": "nodespaceevent",
  "event": "edge_added",
  "data": {
    "src": ["node-1", "out"],
    "dst": ["node-2", "a"]
  }
}
```

### edge_removed

```json
{
  "type": "nodespaceevent",
  "event": "edge_removed",
  "data": {
    "src": ["node-1", "out"],
    "dst": ["node-2", "a"]
  }
}
```

### node_triggered

```json
{
  "type": "nodespaceevent",
  "event": "node_triggered",
  "data": {
    "uuid": "node-1"
  }
}
```

### node_done

```json
{
  "type": "nodespaceevent",
  "event": "node_done",
  "data": {
    "uuid": "node-1"
  }
}
```

### node_error

```json
{
  "type": "nodespaceevent",
  "event": "node_error",
  "data": {
    "uuid": "node-1",
    "error": "ValueError: invalid input",
    "traceback": "..."
  }
}
```

### io_value_changed

```json
{
  "type": "nodespaceevent",
  "event": "io_value_changed",
  "data": {
    "node_uuid": "node-1",
    "io_id": "out",
    "io_type": "output",
    "value": 42,
    "preview": "42"  // String representation for UI
  }
}
```

### node_progress

```json
{
  "type": "nodespaceevent",
  "event": "node_progress",
  "data": {
    "uuid": "node-1",
    "progress": 0.65,
    "message": "Processing item 65/100"
  }
}
```

______________________________________________________________________

## HTTP Endpoints

### Large Message Retrieval

When a message exceeds `MESSAGE_SIZE_BEFORE_REQUEST`:

```text
GET /message/{msg_id}

Response: JSON payload
```

### File Upload

```text
POST /upload/

Content-Type: multipart/form-data
Body: file data

Response:
{
  "success": true,
  "filename": "uploaded_file.csv",
  "path": "files/uploaded_file.csv"
}
```

### React Plugin Assets

```text
GET /plugin/{module_name}/...

Response: Static files from module's react_plugin
```

______________________________________________________________________

## Error Handling

### Command Errors

```json
{
  "type": "error",
  "cmd": "add_node",
  "error": "NodeClassNotFoundError: unknown_node_id",
  "traceback": "..."  // Optional, depends on debug mode
}
```

### Common Error Types

| Error                      | Description                          |
| -------------------------- | ------------------------------------ |
| `NodeClassNotFoundError`   | Unknown node_id                      |
| `NodeConnectionError`      | Invalid connection attempt           |
| `MultipleConnectionsError` | Multiple connections to single-input |
| `SerializationError`       | Value cannot be serialized           |
| `ValidationError`          | Invalid command parameters           |

______________________________________________________________________

## Connection Lifecycle

```text
Client                                    Server
  ‚îÇ                                         ‚îÇ
  ‚îÇ  1. WebSocket connect                   ‚îÇ
  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ  2. {"type": "ping"}                    ‚îÇ
  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ  3. {"type": "pong"}                    ‚îÇ
  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ  4. {"type": "cmd", "cmd": "full_state"}‚îÇ
  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ  5. {"type": "result", ...}             ‚îÇ
  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ  6. (ongoing) Events broadcast          ‚îÇ
  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ  7. WebSocket close                     ‚îÇ
  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
  ‚îÇ                                         ‚îÇ
```

______________________________________________________________________

## See Also

- [Architecture Overview](https://linkdlab.github.io/FuncNodes/architecture/overview/index.md) ‚Äî System diagram
- [Worker Components](https://linkdlab.github.io/FuncNodes/architecture/worker-components/index.md) ‚Äî Worker internals
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event reference

# Architecture Overview

This document provides a comprehensive view of the FuncNodes system architecture, explaining how components interact and data flows through the system.

______________________________________________________________________

## System Architecture

```
flowchart TB
    subgraph USER["üë§ USER LAYER"]
        Browser["üåê Web Browser"]
        subgraph Frontend["React Flow UI"]
            Editor["Visual workflow editor"]
            LibBrowser["Node library browser"]
            Preview["Live data previews"]
        end
    end

    subgraph SERVICE["‚öôÔ∏è SERVICE LAYER"]
        Static["Static File Server<br/>localhost:8000"]
        subgraph WM["Workermanager"]
            WMLife["Worker lifecycle mgmt"]
            WMHub["WebSocket hub :9380"]
            WMDisc["Worker discovery"]
            WMVenv["Venv provisioning"]
        end
    end

    subgraph WORKER["üîß WORKER LAYER"]
        subgraph Pool["Worker Pool"]
            subgraph W1["Worker 1 :9382"]
                NS1["Nodespace"]
                Lib1["Library"]
                Venv1[".venv"]
            end
            subgraph W2["Worker 2 :9383"]
                NS2["Nodespace"]
                Lib2["Library"]
                Venv2[".venv"]
            end
            subgraph WN["Worker N :938X"]
                NSN["Nodespace"]
                LibN["Library"]
                VenvN[".venv"]
            end
        end
    end

    subgraph STORAGE["üíæ STORAGE LAYER"]
        Config["~/.funcnodes/config.json"]
        subgraph Workers["workers/"]
            WConf["worker_uuid.json"]
            WPid["worker_uuid.p"]
            subgraph WDir["worker_name/"]
                WVenv[".venv/"]
                WNS["nodespace.json"]
                WFiles["files/"]
                WLog["worker.log"]
            end
        end
    end

    Browser -->|WebSocket| WM
    WM -->|spawn/manage| Pool
    W1 --> Workers
    W2 --> Workers
    WN --> Workers
```

______________________________________________________________________

## Component Overview

### Frontend (`funcnodes_react_flow`)

The browser-based visual editor built with React and React Flow:

| Component             | Purpose                                       |
| --------------------- | --------------------------------------------- |
| **Graph Editor**      | Drag-and-drop node canvas                     |
| **Library Browser**   | Browse and search available nodes             |
| **Property Panel**    | Edit node inputs and view outputs             |
| **Worker Selector**   | Manage and switch between workers             |
| **Preview Renderers** | Display data previews (images, plots, tables) |

The frontend connects to both the Workermanager (for worker discovery) and individual workers (for graph manipulation).

### Workermanager

A lightweight `aiohttp` service that supervises workers:

- **Discovery**: Lists available workers and their status
- **Lifecycle**: Creates, starts, stops, and deletes workers
- **Provisioning**: Sets up virtualenvs for new workers
- **Hub**: Routes UI connections to the correct worker

Default endpoint: `ws://localhost:9380/`

### Workers

Independent processes that execute node graphs:

- **Nodespace**: In-memory graph state with nodes and edges
- **Library**: Registry of available node classes (shelves)
- **Event Loop**: Async execution engine for node triggering
- **RPC Server**: WebSocket API for graph manipulation
- **Virtualenv**: Isolated Python environment per worker

Each worker runs on its own port (9382+) and can have different installed modules.

### Storage

File-based persistence in `~/.funcnodes/`:

| File                 | Content                                             |
| -------------------- | --------------------------------------------------- |
| `config.json`        | Global settings (ports, logging, render options)    |
| `worker_<uuid>.json` | Worker configuration (port, env path, dependencies) |
| `nodespace.json`     | Serialized graph (nodes, edges, groups, properties) |

______________________________________________________________________

## Data Flow

### 1. Startup Sequence

```
flowchart TD
    Start["User runs: funcnodes runserver"]

    subgraph Init["Initialization"]
        S1["1. Load global config"]
        S2["2. Start static file server"]
        S3["3. Check for Workermanager"]
        S4["Start if not running"]
        S5["4. Open browser to UI"]
    end

    subgraph Connect["UI Connection"]
        C1["UI connects to Workermanager<br/>via WebSocket"]
        C2["‚Ä¢ Request worker list<br/>‚Ä¢ Subscribe to status"]
    end

    subgraph Worker["Worker Setup"]
        W1["User selects/creates worker"]
        W2["Workermanager spawns<br/>worker process"]
        W3["Worker initializes<br/>nodespace + library"]
        W4["UI connects to worker"]
    end

    Start --> S1 --> S2 --> S3 --> S4 --> S5
    S5 --> C1 --> C2
    C2 --> W1 --> W2 --> W3 --> W4
```

### 2. Node Execution Flow

```
flowchart TD
    UserInput["User sets input value"]

    RPC["UI sends RPC:<br/>update_node_input"]
    Worker["Worker receives<br/>Sets input.value"]
    Emit["Input emits<br/>after_set_value"]
    Trigger["Node.trigger() called"]
    Check{"All required<br/>inputs have values?"}

    Execute["await node.func()<br/>(async execution)"]
    Wait["Wait for<br/>more inputs"]

    Output["Output values set<br/>Emit to connected<br/>downstream inputs"]
    Cascade["Connected nodes<br/>trigger (cascade)"]

    UserInput -->|WebSocket| RPC
    RPC --> Worker
    Worker --> Emit
    Emit --> Trigger
    Trigger --> Check

    Check -->|Yes| Execute
    Check -->|No| Wait

    Execute --> Output
    Output --> Cascade
    Cascade -.->|"repeat for each<br/>downstream node"| Trigger
```

### 3. Module Loading Flow

```
flowchart TD
    subgraph Discovery["Module Discovery"]
        Venv["Python Environment<br/>(worker's venv)"]
        Scan["Scan installed packages for<br/>funcnodes.module entry point"]

        subgraph Load["For each module"]
            Import["Import module"]
            Shelf["Load shelf entry point"]
            Register["Register nodes in Library"]
            Render["Load render_options"]
            Plugin["Load react_plugin info"]
        end

        Library["Library populated with<br/>shelves and node classes"]
    end

    Venv --> Scan
    Scan --> Import
    Import --> Shelf
    Shelf --> Register
    Register --> Render
    Render --> Plugin
    Plugin --> Library
```

______________________________________________________________________

## Package Structure

FuncNodes is split into several packages:

```text
funcnodes (meta-package)
‚îú‚îÄ‚îÄ funcnodes_core          # Core runtime
‚îÇ   ‚îú‚îÄ‚îÄ node.py             # Node, NodeInput, NodeOutput
‚îÇ   ‚îú‚îÄ‚îÄ nodeio.py           # IO base class
‚îÇ   ‚îú‚îÄ‚îÄ nodespace.py        # Graph container
‚îÇ   ‚îú‚îÄ‚îÄ lib.py              # Library, Shelf
‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Configuration management
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Serialization, functions
‚îÇ
‚îú‚îÄ‚îÄ funcnodes_worker        # Worker runtime
‚îÇ   ‚îú‚îÄ‚îÄ worker.py           # WSWorker class
‚îÇ   ‚îú‚îÄ‚îÄ websocket.py        # RPC server
‚îÇ   ‚îî‚îÄ‚îÄ loop.py             # Event loops
‚îÇ
‚îî‚îÄ‚îÄ funcnodes (package)     # High-level API
    ‚îú‚îÄ‚îÄ __init__.py         # Public exports
    ‚îî‚îÄ‚îÄ _setup.py           # Module discovery
```

______________________________________________________________________

## Communication Protocols

### WebSocket Messages

All communication uses JSON over WebSocket:

```json
// Client ‚Üí Server (Command)
{
  "type": "cmd",
  "cmd": "update_node",
  "kwargs": {
    "uuid": "node-123",
    "input_id": "value",
    "value": 42
  }
}

// Server ‚Üí Client (Response)
{
  "type": "result",
  "cmd": "update_node",
  "result": { "success": true }
}

// Server ‚Üí Client (Event)
{
  "type": "nodespaceevent",
  "event": "node_triggered",
  "data": { "uuid": "node-123" }
}
```

See [Message Protocol](https://linkdlab.github.io/FuncNodes/architecture/message-protocol/index.md) for the complete reference.

______________________________________________________________________

## Key Design Decisions

### Why Isolated Workers?

1. **Dependency Isolation**: Different workflows can use different library versions
1. **Crash Isolation**: A buggy node won't take down other workflows
1. **Resource Management**: Workers can be stopped independently
1. **State Isolation**: Each workflow has its own persistent state

### Why Event-Driven?

1. **Reactive**: Data changes automatically propagate
1. **Efficient**: Only affected nodes re-execute
1. **Intuitive**: Matches mental model of data flowing through pipes
1. **Debuggable**: Each step is observable

### Why WebSocket?

1. **Bidirectional**: Server can push updates to clients
1. **Real-time**: Low latency for live previews
1. **Persistent**: No reconnection overhead per message
1. **Standard**: Wide library support

______________________________________________________________________

## See Also

- [Core Components](https://linkdlab.github.io/FuncNodes/architecture/core-components/index.md) ‚Äî `funcnodes_core` internals
- [Worker Components](https://linkdlab.github.io/FuncNodes/architecture/worker-components/index.md) ‚Äî `funcnodes_worker` internals
- [Message Protocol](https://linkdlab.github.io/FuncNodes/architecture/message-protocol/index.md) ‚Äî RPC command reference
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event types and handling

# Worker Components (`funcnodes_worker`)

The `funcnodes_worker` package provides the runtime environment for executing FuncNodes graphs. This document explains the worker architecture and its components.

______________________________________________________________________

## Package Structure

```text
funcnodes_worker/
‚îú‚îÄ‚îÄ __init__.py           # Public exports
‚îú‚îÄ‚îÄ worker.py             # WSWorker class
‚îú‚îÄ‚îÄ websocket.py          # WebSocket server and RPC handling
‚îú‚îÄ‚îÄ loop.py               # Runtime loops (save, trigger, heartbeat)
‚îú‚îÄ‚îÄ external_worker.py    # External worker base class
‚îî‚îÄ‚îÄ config.py             # Worker configuration
```

______________________________________________________________________

## Worker Architecture

```
flowchart TB
    subgraph WSWorker["WSWorker"]
        subgraph EventLoop["Event Loop (asyncio)"]
            NSLoop["NodeSpaceLoop<br/>(5ms tick)"]
            SaveLoop["SaveLoop<br/>(1s tick)"]
            HeartLoop["HeartbeatLoop<br/>(optional)"]

            subgraph WS["WebSocket Server"]
                RPC["RPC command handling"]
                Broadcast["Event broadcasting"]
                HTTP["Large message HTTP fallback"]
            end
        end

        subgraph NS["NodeSpace"]
            Nodes["Nodes<br/>(graph)"]
            Edges["Edges<br/>(connections)"]
            Library["Library<br/>(shelves)"]
        end

        subgraph FS["File System (data_path/)"]
            NSJson["nodespace.json"]
            Files["files/"]
            Scripts["local_scripts/"]
            Log["worker.log"]
        end
    end
```

______________________________________________________________________

## WSWorker Class

The main worker class that orchestrates everything:

```python
class WSWorker:
    """WebSocket-based FuncNodes worker."""

    # Identity
    uuid: str                    # Unique identifier
    name: str                    # Human-readable name

    # Paths
    data_path: Path              # Worker data directory
    env_path: Optional[Path]     # Virtualenv path

    # Components
    nodespace: NodeSpace         # Graph container
    lib: Library                 # Node registry

    # Server
    host: str                    # WebSocket host
    port: int                    # WebSocket port

    # State
    _running: bool               # Is worker active?
    _clients: Set[WebSocket]     # Connected clients

    # Loops
    _nodespace_loop: NodeSpaceLoop
    _save_loop: SaveLoop
    _heartbeat_loop: Optional[HeartbeatLoop]
```

### Worker Lifecycle

```
stateDiagram-v2
    [*] --> Created: config.json written

    Created --> Starting: start()

    state Starting {
        [*] --> LoadLibs: Load libs
        LoadLibs --> LoadState: Load state
        LoadState --> StartWS: Start WS
    }

    Starting --> Running

    state Running {
        [*] --> Active
        Active: ‚Ä¢ Accepting WebSocket connections
        Active: ‚Ä¢ Processing RPC commands
        Active: ‚Ä¢ Executing node triggers
        Active: ‚Ä¢ Saving state periodically
    }

    Running --> Stopping: stop()

    state Stopping {
        [*] --> SaveState: Save state
        SaveState --> CloseWS: Close WS
        CloseWS --> Cleanup: Cleanup
    }

    Stopping --> Stopped

    Stopped --> [*]: PID file removed
```

______________________________________________________________________

## Runtime Loops

### NodeSpaceLoop

Processes pending node triggers:

```python
class NodeSpaceLoop:
    """Drains the node trigger queue."""

    interval: float = 0.005  # 5ms default

    async def run(self):
        while self._running:
            # Wait for any pending triggers to complete
            await self.nodespace.await_done()
            await asyncio.sleep(self.interval)
```

**Purpose:**

- Ensures async node execution completes
- Prevents event loop starvation
- Configurable tick rate for responsiveness vs CPU

### SaveLoop

Persists state to disk:

```python
class SaveLoop:
    """Periodically saves worker state."""

    interval: float = 1.0  # 1 second default

    async def run(self):
        while self._running:
            if self._save_requested:
                await self._save_state()
                self._save_requested = False
            await asyncio.sleep(self.interval)

    def request_save(self):
        """Mark that a save is needed."""
        self._save_requested = True
```

**Saved files:**

- `nodespace.json` ‚Äî Graph state
- `worker_<uuid>.p` ‚Äî PID file (liveness indicator)
- `worker_<uuid>.runstate` ‚Äî Human-readable status

### HeartbeatLoop (Optional)

Enforces client connectivity:

```python
class HeartbeatLoop:
    """Stops worker if no heartbeat received."""

    timeout: float  # From worker config

    async def run(self):
        while self._running:
            if time.time() - self._last_heartbeat > self.timeout:
                logger.warning("Heartbeat timeout, stopping worker")
                await self.worker.stop()
            await asyncio.sleep(1.0)

    def heartbeat(self):
        """Called when client sends heartbeat."""
        self._last_heartbeat = time.time()
```

**Use case:** Auto-stop workers when UI disconnects (optional feature).

______________________________________________________________________

## WebSocket Server

### Connection Handling

```python
async def websocket_handler(request):
    ws = web.WebSocketResponse()
    await ws.prepare(request)

    worker._clients.add(ws)

    try:
        async for msg in ws:
            if msg.type == WSMsgType.TEXT:
                await handle_message(ws, msg.data)
            elif msg.type == WSMsgType.BINARY:
                await handle_binary(ws, msg.data)
    finally:
        worker._clients.discard(ws)

    return ws
```

### RPC Dispatch

```python
async def handle_message(ws, data):
    msg = json.loads(data)

    if msg["type"] == "ping":
        await ws.send_json({"type": "pong"})

    elif msg["type"] == "cmd":
        cmd = msg["cmd"]
        kwargs = msg.get("kwargs", {})

        handler = COMMAND_HANDLERS.get(cmd)
        if handler:
            try:
                result = await handler(worker, **kwargs)
                await ws.send_json({
                    "type": "result",
                    "cmd": cmd,
                    "result": result
                })
            except Exception as e:
                await ws.send_json({
                    "type": "error",
                    "cmd": cmd,
                    "error": str(e)
                })
```

### Event Broadcasting

```python
def broadcast_event(event_type: str, data: dict):
    """Send event to all connected clients."""
    message = {
        "type": "nodespaceevent",
        "event": event_type,
        "data": data
    }
    for client in worker._clients:
        asyncio.create_task(client.send_json(message))
```

______________________________________________________________________

## Large Message Handling

Messages exceeding `MESSAGE_SIZE_BEFORE_REQUEST` (default 1MB) use HTTP fallback:

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Client  ‚îÇ                          ‚îÇ  Worker  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                                     ‚îÇ
     ‚îÇ  1. WS: request full_state          ‚îÇ
     ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
     ‚îÇ                                     ‚îÇ
     ‚îÇ  2. Worker serializes (>1MB)        ‚îÇ
     ‚îÇ                                     ‚îÇ
     ‚îÇ  3. WS: {"type": "large_message",   ‚îÇ
     ‚îÇ         "msg_id": "abc123"}         ‚îÇ
     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
     ‚îÇ                                     ‚îÇ
     ‚îÇ  4. HTTP GET /message/abc123        ‚îÇ
     ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
     ‚îÇ                                     ‚îÇ
     ‚îÇ  5. HTTP Response (full JSON)       ‚îÇ
     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
     ‚îÇ                                     ‚îÇ
```

```python
# Server side
async def send_large_message(ws, data):
    msg_id = str(uuid4())
    _pending_messages[msg_id] = data

    await ws.send_json({
        "type": "large_message",
        "msg_id": msg_id
    })

# HTTP endpoint
async def get_message(request):
    msg_id = request.match_info["msg_id"]
    data = _pending_messages.pop(msg_id)
    return web.json_response(data)
```

______________________________________________________________________

## File Upload Handling

Uploads are received via HTTP POST and stored in `files/`:

```python
async def upload_handler(request):
    reader = await request.multipart()

    async for part in reader:
        filename = part.filename
        # Security: sanitize filename, prevent path traversal
        safe_name = secure_filename(filename)

        target_path = worker.files_dir / safe_name

        with open(target_path, 'wb') as f:
            while chunk := await part.read_chunk():
                f.write(chunk)

    return web.json_response({"success": True})
```

**Security measures:**

- Filename sanitization
- Path traversal prevention (no `..`)
- Files constrained to `files/` directory
- Size limits at proxy layer (recommended)

______________________________________________________________________

## Worker Configuration

### WorkerConfig

```python
@dataclass
class WorkerConfig:
    uuid: str
    name: str

    # Paths
    data_path: Path
    env_path: Optional[Path]
    python_path: Optional[Path]

    # Network
    host: str = "localhost"
    port: int = 9382
    ssl: bool = False

    # Behavior
    update_on_startup: Dict[str, bool] = field(default_factory=dict)
    required_heartbeat: Optional[float] = None

    # Dependencies
    package_dependencies: Dict[str, PackageDependency] = field(default_factory=dict)
    worker_dependencies: Dict[str, Any] = field(default_factory=dict)

    # Type
    workertype: str = "WSWorker"
```

### Config File Location

```text
~/.funcnodes/workers/worker_<uuid>.json
```

### Example Config

```json
{
  "uuid": "abc123",
  "name": "my-workflow",
  "data_path": "~/.funcnodes/workers/worker_my-workflow",
  "env_path": "~/.funcnodes/workers/worker_my-workflow/.venv",
  "host": "localhost",
  "port": 9382,
  "ssl": false,
  "update_on_startup": {
    "funcnodes": true,
    "funcnodes-core": true
  },
  "package_dependencies": {
    "funcnodes-numpy": {
      "package": "funcnodes-numpy",
      "version": ">=0.2.0"
    }
  },
  "workertype": "WSWorker"
}
```

______________________________________________________________________

## External Workers

Custom worker types can be created by subclassing:

```python
from funcnodes_worker import ExternalWorker

class MyCustomWorker(ExternalWorker):
    """Custom worker with additional capabilities."""

    worker_type = "my_custom_worker"

    async def setup(self):
        """Called during worker initialization."""
        await super().setup()
        # Custom setup logic

    async def handle_custom_command(self, **kwargs):
        """Custom RPC command."""
        return {"custom": "result"}
```

Register via entry point:

```toml
[project.entry-points."funcnodes.module"]
external_worker = "my_module:MyCustomWorker"
```

______________________________________________________________________

## Process Isolation

### Separate Thread

For I/O-bound or blocking operations:

```python
@fn.NodeDecorator(
    node_id="heavy_io",
    separate_thread=True  # Run in ThreadPoolExecutor
)
def heavy_io_operation(data: bytes) -> bytes:
    # This won't block the event loop
    return process_data(data)
```

### Separate Process

For CPU-bound operations:

```python
@fn.NodeDecorator(
    node_id="cpu_intensive",
    separate_process=True  # Run in ProcessPoolExecutor
)
def cpu_intensive_task(data: list) -> list:
    # This runs in a separate process
    return [heavy_computation(x) for x in data]
```

**Note:** `separate_process` has limitations:

- Arguments must be picklable
- No access to node state during execution
- Higher overhead than threads

### Subprocess Monitor Integration

For long-running external processes:

```python
# Worker config
{
  "subprocess_monitor": {
    "host": "localhost",
    "port": 8765
  }
}

# Usage in node
async def run_external_tool(cmd: str):
    async with subprocess_monitor.spawn(cmd) as proc:
        async for line in proc.stdout:
            yield line  # Stream output
```

______________________________________________________________________

## Logging

### Per-Worker Logs

Each worker has its own rotating log file:

```text
~/.funcnodes/workers/worker_<name>/worker.log
```

### Log Configuration

```python
# Rotating file handler
handler = RotatingFileHandler(
    log_path,
    maxBytes=100_000,    # 100KB per file
    backupCount=5        # Keep 5 backups
)

# Format
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

### Log Levels

| Level   | Usage                           |
| ------- | ------------------------------- |
| DEBUG   | Detailed execution flow         |
| INFO    | Startup, shutdown, major events |
| WARNING | Recoverable issues              |
| ERROR   | Failures, exceptions            |

______________________________________________________________________

## See Also

- [Architecture Overview](https://linkdlab.github.io/FuncNodes/architecture/overview/index.md) ‚Äî System-level view
- [Core Components](https://linkdlab.github.io/FuncNodes/architecture/core-components/index.md) ‚Äî `funcnodes_core` internals
- [Message Protocol](https://linkdlab.github.io/FuncNodes/architecture/message-protocol/index.md) ‚Äî RPC reference
- [Worker Configuration](https://linkdlab.github.io/FuncNodes/components/worker_config/index.md) ‚Äî User guide
# Runtime

# Configuration

FuncNodes stores its configuration in `config.json` under the base directory (default `~/.funcnodes`). Override the base with `funcnodes --dir <path>` or by setting `FUNCNODES_CONFIG_DIR`.

## Structure (key sections)

- **env_dir** ‚Äî base path for configs/logs/workers (usually the base dir itself).
- **worker_manager** ‚Äî `host`, `port`, `ssl` for the Workermanager service.
- **frontend** ‚Äî `host`, `port`, `ssl` for the UI server (`funcnodes runserver`).
- **nodes** ‚Äî runtime defaults such as `pretrigger_delay` or test-mode flags.
- **logging** ‚Äî handlers, log level, and format limits (see Logging section).
- **render_options** ‚Äî global `typemap` and `inputconverter` hints for special types.

Defaults come from `DEFAULT_CONFIG` in `funcnodes_core.config`. On load, FuncNodes:

1. Ensures the config directory exists.
1. Reads `config.json` (or the `.bu` backup).
1. Fills missing keys from defaults, then writes back.

## Editing config

- Use any editor to adjust `~/.funcnodes/config.json`; restart UI/manager/workers to apply.
- CLI overrides: `funcnodes runserver --host ... --port ...` take precedence for that run.
- Environment: a `.env` file is loaded if present; env vars can override individual settings.

## Test mode

`funcnodes_core.config.set_in_test()` switches to a temporary config dir, disables file logging, promotes warnings to errors (optional), and is automatically used by `pytest_funcnodes` nodetests.

## Render options registry

`render_options` can be extended at runtime (e.g., by modules) via `fn.update_render_options`, normalizing type strings so the UI knows how to preview custom classes.

# Inputs & Outputs

In FuncNodes, inputs and outputs (IOs) serve as the fundamental connection points between nodes. They are responsible for handling the flow of data and triggering execution throughout a workflow. Both inputs and outputs extend from a common foundation‚Äîthe NodeIO Base Class‚Äîwhich provides shared functionality for connection management, value handling, serialization, and event emission.

The main principle is that each IO can hold an arbitrary data object, referenceable via the `value` property. If the value is not set it is automatically set to the NoValue singleton object which is used to represent the absence of a value. This is important because None is a valid value for an IO.

If the value of an IO is changed this may trigger a range of events, including *e.g.* triggering the Node or passing its value to connected IOs.

## NodeIO Base Class

The inputs and outputs of a Node are both derived from the `NodeIO` base class. This class accepts the following parameters (for nromal use cases NodeIO is never intialized directly, but always via the child classes):

- **uuid**: Each IO has a unique ID that is generated when the IO is created. (1)
- **name**: Each IO has a name that is used as the referencing key and also for display purposes (defaults to the uuid).
- **description**: A description of the IO, mainly used for display purposes.
- **type**: The data type of the IO. This is treated as a hint for the UI and the backend, but is not enforced.
- **allow_multiple**: A boolean flag that indicates whether the IO have multiple connections to other IOs. By default this is False for inputs and True for outputs.
- **hidden**: A boolean flag that indicates whether the IO is hidden in the UI. This is useful for internal IOs or for very IO-rich nodes, to make them more usable.
- **render_options**: See [Render Options](#render-options).
- **value_options**: See [Value Options](#value-options).

1. Note: if the IO is derived of a function parameter, the id becomes the signature name of the parameter, so it is not individually unique. But IOs are always attasched to a node, with a unique id, so the combination of node id and IO id is always unique.

## Render Options

The IO-Render options are used to control and customize the appearance of the IO in the UI. In its base form these options are available:

- **type**: If the IO Type is different than what is should be rendered at (e.g. a number that should be rendered as a string or a custom frontend component, this can be set here).
- **set_default**: If the value of the IO is set manually, this flag indicates whether the new value should be set as the default value for the IO (meaning it will also be serialized, and has to be [serializable](https://linkdlab.github.io/FuncNodes/components/serialization/index.md)).

The render options are a dictionary, meaning it can be arbitrary extended with custom options. Which will be passed to the frontend and can there be used to customize the rendering of the IO.

## Value Options

The IO-Value options are used to control and customize the behavior of the IO-value. Currently these values are not directly enforced, but are used as hints for the UI and the backend and if required should be enforced in the respective node functions:

- **min**: The minimum value of the IO, currently used for number types.
- **max**: The maximum value of the IO, currently used for number types (1).
- **step**: The step size of the IO, currently used for number types.
- **options**: A list of options that the IO can take, rendered as a dropdown (2).

1. Note: If min and max are set the default frontend renders the IO as a slider.
1. For more control this can also be defined as a enum type in the form of a dictionary with keys and values (see example below).

```python
import funcnodes as fn

class IOModNode(fn.Node):
    node_id = "iomodnode"
    a = fn.NodeInput(
        value_options={"min": 0, "max": 1, "step": 0.1}, default=0.5, type=float
    )

    b = fn.NodeInput(
        render_options={"type": "color"}, type=str, default="#ff0000"
    )

    c = fn.NodeInput(
        value_options={"options": ["a", "b", "c"]}, default="a", type=str
    )
    d = fn.NodeInput(
        value_options={
            "options": {
                "type": "enum",
                "keys": ["full", "empty"],
                "values": [1, 0],
            }
        }
    )

    async def func(self, a: float, b: str, c: str, d: float):
        self.inputs["a"].set_value(float(d), does_trigger=False)
```

## Events & triggering

- Inputs fire `after_set_value` events when `emit_value_set=True`; outputs fire on `trigger`.
- Inputs can opt out of triggering the node with `does_trigger=False` (useful for control signals or staged values).
- Hidden maintenance ports (e.g., the auto-created `_triggerinput`/`_triggeroutput`) use `hidden=True` to stay out of the UI.

## Dynamic IO updates

Use decorator helpers to recompute options based on other inputs:

- `update_other_io_options("target", modifier=...)` ‚Äî recalc dropdown contents.
- `update_other_io_value_options("target", options_generator=...)` ‚Äî recalc numeric bounds (`min/max/step`).

Patterns in the shipped modules:

- Pandas column selectors rebuild `options` from `df.columns`.
- Basic list nodes adjust valid indices to the current list length.
- File/folder pickers repopulate from the worker `files_dir`.

## Enumerations & `DataEnum`

For stable choice lists, subclass `fn.DataEnum`; it registers a type string and exposes `.v()` to resolve stored values. Example:

```python
class BorderTypes(fn.DataEnum):
    CONSTANT = (0, "Constant")
    REFLECT = (2, "Reflect")
```

Attach the enum as the IO `type` or use `value_options={"options": BorderTypes}`; the UI renders friendly labels while storing the underlying values.

## `NoValue` and optional outputs

`NoValue` represents ‚Äúno data‚Äù and **suppresses downstream triggers**. Return it from optional outputs or routers to avoid firing branches unintentionally. Inputs default to `NoValue` until set; disconnecting an input resets it to its class default if provided.

## Render routing & previews

Node-level `default_render_options` can point the UI at a specific IO, e.g. `{"data": {"src": "figure"}}` for Plotly or images. Per-IO `render_options` can request widgets (`{"type": "color"}`, sliders via min/max) or mark values as preview-only.

### Custom renderers and type hints

- The global render-option registry lives in `funcnodes_core.config.FUNCNODES_RENDER_OPTIONS`. Modules can extend it at import time via an entry point (`render_options`) or by calling `funcnodes_core.config.update_render_options`.
- Serialization uses `funcnodes_core.utils.serialization.JSONEncoder/Decoder`; modules may register additional encoders so custom types can be stored in `nodespace.json` and previewed in the UI.
- Enums for dropdowns should subclass `fn.DataEnum` so both values and display labels are preserved.

## Connection rules & multiplicity

- Inputs default to **single connection**; set `allow_multiple=True` for fan-in semantics.
- Outputs allow multiple downstream connections.
- Connection validation prevents input‚Üíinput and output‚Üíoutput wiring and enforces `allow_multiple`; violations raise `NodeConnectionError` / `MultipleConnectionsError`.
- There is no automatic cycle detection across the graph; avoid feedback loops unless your node logic guards against it.

## Serialization hints

- All IO values must be JSON-serializable by the registered encoders to persist in `nodespace.json`.
- Set `render_options["set_default"]=True` when user-set values should become the new default and be serialized with the graph.

# Library (Shelf Registry)

The Library is the runtime registry that exposes shelves and node classes to a `NodeSpace`. It lives in `funcnodes_core.lib.Library` and is attached to every worker.

## Storage model

- Internally a flat dict keyed by tuple paths (`("Top", "Child", ...)`) pointing to `_ShelfRecord` entries that store **only node IDs**, not class objects.
- Weak references can be mounted (`add_external_shelf`, `add_subshelf_weak`) so externally owned shelves disappear automatically when GC‚Äôd.
- Materialized shelves are rebuilt on demand with `Shelf` objects; missing node classes are skipped if they are no longer registered.

## API highlights

- `add_shelf(shelf)` ‚Äî merge/insert a full shelf tree (deduplicates node IDs).
- `add_node(s)/add_nodes` ‚Äî append one or many node classes to a shelf path, creating intermediate shelves as needed.
- `remove_shelf`, `remove_shelf_path` ‚Äî drop shelves (and descendants) by object or path.
- `find_nodeid` / `find_nodeclass` ‚Äî return all shelf paths that reference a node.
- `get_node_by_id` ‚Äî resolves a node class only if it is both registered and referenced somewhere; otherwise raises `NodeClassNotFoundError`.
- `full_serialize()` ‚Äî JSON snapshot of all shelves, used by `NodeSpace.full_serialize()`.

## Population from installed modules

Module discovery runs via `funcnodes_core.libparser.module_to_shelf` and `_setup.py`:

1. Installed distributions are inspected for `funcnodes.module` entry points. If a `shelf` object is exported, it is validated (`check_shelf`) and mounted.
1. If no `shelf` entry point is provided, all non‚Äëabstract `Node` subclasses in the module are grouped into a shelf named after the module.
1. Render options or external workers exported via entry points are applied separately and do not affect the library tree.

## Why flat storage?

Keeping only node IDs in `_records` avoids strong references to node classes and keeps the GC happy, while still allowing quick materialization of nested shelves when the UI or serialization needs them.

Nodes are the most fundamental building blocks of FuncNodes. Each node encapsulates a function with defined inputs and outputs. Nodes execute when all required inputs are available, producing output data for downstream nodes. Nodes can be created with two different methods: [class based](#class-based-nodes) and [decorator based](#decorator-based-nodes). While class based nodes are more flexible and can be used to create complex nodes, decorator based nodes are simpler and faster to create.

## Class Based Nodes

Class based nodes are created by subclassing the `Node` class from the `funcnodes` package. This method is more flexible and allows for more complex nodes to be created. The `Node` class provides a number of methods and properties that can be overridden to customize the behavior of the node.

The basic layout of a class based node is as follows:

```python
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node"
    node_id = "my_node"

    async def func(self):
        """The function to be executed when the node is triggered."""
```

The `node_name` and `node_id` required properties define the name and ID of the node, respectively. It is important that the 'node_id' is unique across all nodes in the system since it is used for serialization and deserialization of the node. So it is recommended to make it as descriptive as possible, e.g. if the node CalculateOrbit is part of a public package named 'funcnodes_astronomy' and the node the node_id could be 'funcnodes_astronomy.calculate_orbit'. And while this is not enforced it is recommended to use a similar naming scheme for the ids, to prevent id clashes. The node name is the human readable name of the node and is used in the UI.

The async `func` method is the entry point for the node's execution. This method is called when the node is triggered and should contain the logic for the node's function.In the class based nodes the `func` method is the only method that is required to be implemented. The `func` method has to be an async method since the execution of the node is done asynchronously.

The node above has no inputs or outputs, which makes it relatively useless. inputs and outputs can be added on the class level as well:

```python
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node"
    node_id = "my_node"

    input1 = fn.NodeInput(id="input1", type=int)
    input2 = fn.NodeInput(id="input2", type=int)

    output1 = fn.NodeOutput(id="output1", type=int)


    async def func(self, input1, input2):

        result =  input1 + input2
        self.outputs["output1"].value = result
```

In the example above, the node has two inputs, `input1` and `input2`, and one output, `output`. The `func` method now takes two arguments, `input1` and `input2`, which are the values of the inputs. The `func` method then adds the two inputs together and sets the result as the value of the output. While the class attributes of the inputs and outputs can be arbitrary named, it is recommended to use the same name as the id of the input or output (IO), to make the code more readable. setting the type of the IO is optional, but it is recommended since this will be used to render the corresponding IO in the UI (defaults to Any).

Warning

The typing of the IO is not enforced, to stay as pythonic as possible. If the value is not of the expected type, the node will still trigger and raise an exception if it occurs.

This is important to keep the system flexible: e.g. numpy arrays can be passed to inputs that expect a list and it should still work.

If enforcing is required, it should be done in the `func` method.

During triggering all inputs are passed to the `func` method as keyword arguments, so the order of the inputs does not matter, but the ids should be valid python variable names. In the class based approach outputs have to be set **explicitly**, by setting the value of the output in the `func` method. For more details on the `IO` see the [Inputs and Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md).

## Decorator Based Nodes

A even simpler way to create nodes is by using the `@fn.NodeDecorator` decorator. This decorator can be used to create nodes from a simple function. The function should take the inputs as arguments and return the outputs as a dictionary. The decorator will automatically create the node and set the inputs and outputs based on the function signature.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(input1: int, input2: int) -> float:
    return input1 / input2
```

This will create a node with the id `my_node`, which has two inputs, `input1` and `input2` (of type `int`), and one output, `output1` (of type `float`).

The `@fn.NodeDecorator` decorator has the required argument `node_id`, which is the id of the node, similar to the `node_id` property in the class based nodes. The inputs are automatically created based on the function signature, as such the function should have only defined positional and keyword arguments and no expanding arguments like `*args` or `**kwargs`. Similar to the class based nodes, the type of the inputs is optional, but recommended.

The Decorator can also be used to create a Node from an arbitrary external function, by passing the function as an argument to the decorator. The corresponding inputs and outputs will be created based on the signature of the function and the type hints.

```python
import funcnodes as fn

def myfunction(a: int=1, b: int=2) -> int:
    return a + b

MyFuncNode = fn.NodeDecorator(
    node_id="my_node",
)(myfunction)
```

The outputs are defined by the return type of the function, the output type is also interpreted from the return type, if present. The default id if the output is `out` and the default type is `Any`.

How the Node input and Output can be further customized with decorators is described in the [Inputs and Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) section.

### Defining multiple outputs

Will the class based approach allows for multiple outputs simply by defining multiple outputs, the decorator requires a little modification.

To have multiple outputs, the function should return multiple values, which would make the return type a tuple.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(input1: int, input2: int) -> tuple:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

But this will result in a single output `out` of the type tuple. To actually have multiple outputs the return type has to be a typed tuple, to be able to interfere the number of outputs:

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
)
def my_node(input1: int, input2: int) -> Tuple[int, int]:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

By default the outputs are numbered, to give them a more descriptive name, the outputs can be customized with the `outputs` argument of the decorator:

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
    outputs=[
        {"name": "output1"},
        {"name": "output2"},
    ]
)
def my_node(input1: int, input2: int) -> Tuple[int, int]:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

The `outputs` argument of the decorator is a list of dictionaries, where each dictionary represents an output. The dictionary should have the key `name` which is the id of the output. To specify the type, the `type` argument can be used. Alternatively, the type can be specified in the return type of the function as in the example above.

### Further info in IO in decorator

In a similar manner the inputs can be customized with the `inputs` argument.

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
    inputs=[
        {"name": "a"},
        {"name": "b"},
    ],
)
def myfunction(var_name_i_dont_like_a: int=1, var_name_i_dont_like_b: int=2) -> int:
    return var_name_i_dont_like_a + var_name_i_dont_like_b
```

Defining the inputs and outputs in the decorator is especially useful when the function is an external function and the signature cannot be changed.

In the following example, the function `divmod` is an external function and the signature cannot be changed.

```python
from typing import Tuple
import funcnodes as fn

MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
)(divmod)
```

As you can see the function has the expected inputs, but it is not typed. As such the inputs are of type `Any`, which allows no manual input and the return type is not defined, meaning the function has no output.

To fix this, the inputs and outputs can be defined in the decorator.

```python
from typing import Tuple
import funcnodes as fn


MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
    inputs=[
        {"name": "a"},
        {"name": "b"},
    ],
    outputs=[
        {"name": "quotient", "type": int},
        {"name": "remainder", "type": int},
    ]
)(divmod)
```

While under normal circumstances this works as expected, it is recommended to use the `fn.NodeDecorator` as a decorator, and create a wrapper function that calls the external function, to make the node more readable and to allow for more customization.

```python
from typing import Tuple
import funcnodes as fn


@fn.NodeDecorator(
    node_id="divmod",
    outputs=[
        {"name": "quotient"},
        {"name": "remainder"},
    ]
)
def divmod_node(a: int=11, b: int=5) -> Tuple[int, int]:
    return divmod(a, b)
```

Furthermore by wrapping it in a function, it can be make sure, that the function accepts all arguments as keyword arguments. Since internally Funcnodes calls the function with all-keyword arguments, which is some functions don't accept:

```python
from typing import Tuple
import funcnodes as fn

MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
    inputs=[
        {"name": "a", "default":11}, # setting default to show the effect
        {"name": "b", "default":5},
    ],
    outputs=[
        {"name": "quotient", "type": int},
        {"name": "remainder", "type": int},
    ]
)(divmod) # this will not work since divmod does not accept keyword arguments
```

### Defining the node name

The node name is especially important for the UI, as it is the human readable name of the node. If not present, the node name will be the name of the function or the class. To set the node name, the `node_name` class attribute or the `name` argument of the decorator can be used.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node1", name="My Node Decorator")
def my_node(input1: int, input2: int) -> float:
    return input1 / input2

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node2"

    async def func(self):
        pass
```

### Defining the node description

In a similar manner the node description can be set with the `description` argument of the decorator or the `description` class attribute of the class based nodes.

Description is a human readable description of the node, which can be used to provide more information about the node to the user.

Additionaly if no description is provided, the docstring of the function or the class will be used as the description (if present).

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node1", description="This is a node created with the decorator")
def my_node(ip:int) -> float:
    return ip/2

@fn.NodeDecorator(node_id="my_node2")
def my_node(ip:int) -> float:
    """This is a node created with the decorator and a docstring"""
    return ip/2

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node3"
    description = """
This is a node created with the class

Multi line is supported
    """

    ip = fn.NodeInput(id="ip", type=int)

    async def func(self, ip):
        self.outputs["output1"].value = ip / 2
```

(Hover over the node header in the UI to see the description)

Future Plans

We plan to render the description as via Markdown/Sphinx in the UI, so it is recommended to use Markdown in the description.

### Node progress bar

Especially for long running nodes, it is recommended to provide a progress bar to the user. For this purpose the node has a custom property `progress` which wraps the `tqdm` progress bar and automatically streams the progress to the UI.

```python
import asyncio
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node3"
    description = "This is a node created with the class"

    ip = fn.NodeInput(id="ip", type=int,default=30)

    async def func(self, ip):
        for i in self.progress(range(ip)):
            await asyncio.sleep(10)
```

(All nodes on this page here run in parallel processes in [pyodide](https://pyodide.org/en/stable/), each with all the individual management overhead, which is why the progress bar is not 100% iterating with the sleep time. A normal use-case would be only little processes with multiple nodes per process)

To access the progress bar in a decorator based node, we need to access the underlying node object. For this purpose an input argument `node` can be added, which will not be considered as normal input, but as a reference to the node object.

```python
import asyncio
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
async def my_node(ip:int=30, node: fn.Node=None) -> float:
    for i in node.progress(range(ip)):
        await asyncio.sleep(10)

    return ip/2
```

### Heavy Tasks

Since Funcnodes uses the asyncio library, a blocking function will block the event loop and prevent other nodes from executing. To prevent this, heavy tasks should be executed in a separate thread or process. This can be done e.g. by using the `asyncio.to_thread` function, which will run the function in a separate thread and return the result.

```python
import asyncio
import time
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
async def my_node(input1: int, input2: int) -> int:
    def heavy_task(input1, input2):
        time.sleep(1)
        return input1 + input2

    return await asyncio.to_thread(heavy_task, input1, input2)
```

Pyodide Runtime

Funcnodes is also able to run in [pyodide](https://pyodide.org/en/stable/) ("Pyodide makes it possible to install and run Python packages in the browser"). We use this also in all the Nodes you see here running live. But pyodide does not yet support multithreading or multiprocessing.

This works for both class based and decorator based nodes. Alternatively, the NodeDecorator accepts a `separate_thread=True` argument, which will automatically run the function in a separate thread. (The decorator alternativly accepts a `separate_process=True` argument, which will run the function in a separate process, but this is still experimental and should only considered for heavy CPU bound tasks)

`separate_process` wraps the function with `funcnodes_core.utils.functions.make_run_in_new_process`, which uses a `ProcessPoolExecutor`. Resource limits or sandboxing are not applied by FuncNodes; if you need supervision, point the worker at a running `subprocess_monitor` (see Worker config).

### Nested Inheritance

While the class based approach allows for more complex inheritance patterns:

```python
import funcnodes as fn

class BaseNode(fn.Node):
    """
    `Abstract` base class does not need a `func` method or a `node_id`
    """

    my_id = fn.NodeOutput(id="my_id", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["my_id"].value = id(self)


class MyNode(BaseNode):
    node_name = "My Node"
    node_id = "my_node"

    input1 = fn.NodeInput(id="input1", type=int)
    input2 = fn.NodeInput(id="input2", type=int)

    output1 = fn.NodeOutput(id="output1", type=int)

    async def func(self, input1, input2):
        result =  input1 + input2
        self.outputs["output1"].value = result

class MyNodeTwo(BaseNode):
    node_name = "My Node Two"
    node_id = "my_node_two"

    input1 = fn.NodeInput(id="input1", type=int)
    output1 = fn.NodeOutput(id="output1", type=float)

    async def func(self, input1):
        self.outputs["output1"].value = input1/2
```

The decorator also allows to use different baseclasses than the default `Node` class, by using the `superclass` argument of the decorator.

```python
import funcnodes as fn

class BaseNode(fn.Node):
    """
    `Abstract` base class does not need a `func` method or a `node_id`
    """

    my_id = fn.NodeOutput(id="my_id", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["my_id"].value = id(self)


@fn.NodeDecorator(node_id="my_node", superclass=BaseNode)
def my_node(input1: int, input2: int) -> int:
    return input1 + input2

instance = my_node()
instance.outputs["my_id"].value == id(instance) # True
```

### Try it out yourself

# Node Inputs

`NodeInput` is the input connection point for nodes in FuncNodes. It extends `NodeIO` with input-specific behavior including triggering, default values, and required/optional semantics.

______________________________________________________________________

## Constructor Parameters

```python
fn.NodeInput(
    id: str,                           # Unique identifier (required)
    type: Type = Any,                  # Data type hint
    name: str = None,                  # Display name (defaults to id)
    description: str = None,           # Help text
    default: Any = NoValue,            # Default value
    required: bool = True,             # Must have value to execute?
    does_trigger: bool = True,         # Triggers node on value change?
    allow_multiple: bool = False,      # Allow multiple connections?
    hidden: bool = False,              # Hide in UI
    value_options: dict = None,        # Value constraints
    render_options: dict = None,       # UI rendering hints
    emit_value_set: bool = True,       # Emit events on value change?
    on: dict = None,                   # Event handlers
)
```

### Parameter Details

| Parameter        | Type   | Default   | Description                                                                                                                 |
| ---------------- | ------ | --------- | --------------------------------------------------------------------------------------------------------------------------- |
| `id`             | `str`  | Required  | Unique identifier within the node. Used for programmatic access via `node.inputs["id"]`. Must be a valid Python identifier. |
| `type`           | `Type` | `Any`     | Python type hint. Affects UI rendering (e.g., `int` shows number input, `bool` shows checkbox). Not enforced at runtime.    |
| `name`           | `str`  | `id`      | Human-readable display name shown in UI.                                                                                    |
| `description`    | `str`  | `None`    | Tooltip/help text shown on hover in UI.                                                                                     |
| `default`        | `Any`  | `NoValue` | Default value when input is not connected and not manually set.                                                             |
| `required`       | `bool` | `True`    | If `True`, node won't execute until this input has a value.                                                                 |
| `does_trigger`   | `bool` | `True`    | If `True`, setting this input triggers node execution.                                                                      |
| `allow_multiple` | `bool` | `False`   | If `True`, multiple outputs can connect to this input.                                                                      |
| `hidden`         | `bool` | `False`   | If `True`, input is hidden from UI (but still functional).                                                                  |
| `value_options`  | `dict` | `None`    | Constraints like `min`, `max`, `step`, `options`.                                                                           |
| `render_options` | `dict` | `None`    | UI hints like custom renderer type.                                                                                         |
| `emit_value_set` | `bool` | `True`    | If `True`, emits `after_set_value` event when value changes.                                                                |
| `on`             | `dict` | `None`    | Event handlers to register (e.g., `{"after_set_value": handler}`).                                                          |

______________________________________________________________________

## Basic Usage

### Class-Based Nodes

```python
import funcnodes_core as fn

class MyNode(fn.Node):
    node_id = "my_module.my_node"
    node_name = "My Node"

    # Basic input with type and default
    value = fn.NodeInput(id="value", type=float, default=0.0)

    # Required input (must be set before node executes)
    data = fn.NodeInput(id="data", type=list, required=True)

    # Optional input with description
    label = fn.NodeInput(
        id="label",
        type=str,
        default="",
        required=False,
        description="Optional label for the output"
    )

    async def func(self, value, data, label):
        result = process(data, value)
        return f"{label}: {result}" if label else str(result)
```

### Decorator-Based Nodes

With decorators, inputs are created automatically from function parameters:

```python
@fn.NodeDecorator(node_id="add_numbers")
def add(a: int = 0, b: int = 0) -> int:
    return a + b
```

This creates:

- Input `a` with type `int`, default `0`
- Input `b` with type `int`, default `0`

### Using Type Annotations with `InputMeta`

For more control in decorator-based nodes, use `typing.Annotated` with `fn.InputMeta` to define all input properties inline:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(
    a: Annotated[
        int,
        fn.InputMeta(
            name="Amount",           # Display name
            description="The amount to process",
            default=1,
            does_trigger=False,
            hidden=True,
        ),
    ],
) -> int:
    return a + 1
```

This approach:

- Uses the **parameter name** (`a`) as the input ID
- The **type** comes from the first argument to `Annotated`
- All input properties are specified in `InputMeta`

### `InputMeta` with Dynamic Options

You can also include event handlers directly in `InputMeta`:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="dict_selector")
def dict_selector(
    data: Annotated[
        dict[str, int],
        fn.InputMeta(
            name="Data",
            description="Dictionary to select from",
            on={
                "after_set_value": fn.decorator.update_other_io_options(
                    "key",
                    list,  # Updates key's options to list(data.keys())
                )
            },
        ),
    ],
    key: str,
) -> int:
    return data[key]
```

Each node instance maintains **separate state** ‚Äî setting `data` on one instance updates only that instance's `key` options:

```python
node1 = dict_selector()
node2 = dict_selector()

node1["data"] = {"k1": 1, "k2": 2}
node2["data"] = {"k3": 3, "k4": 4}

# node1's key options: ["k1", "k2"]
# node2's key options: ["k3", "k4"]
```

### `InputMeta` Parameters

| Parameter        | Type   | Description                               |
| ---------------- | ------ | ----------------------------------------- |
| `name`           | `str`  | Display name (defaults to parameter name) |
| `description`    | `str`  | Help text                                 |
| `default`        | `Any`  | Default value                             |
| `does_trigger`   | `bool` | Whether setting triggers execution        |
| `required`       | `bool` | Whether input must have value             |
| `hidden`         | `bool` | Whether to hide in UI                     |
| `value_options`  | `dict` | Constraints like `min`, `max`, `options`  |
| `render_options` | `dict` | UI rendering hints                        |
| `on`             | `dict` | Event handlers                            |

______________________________________________________________________

## Value Constraints (`value_options`)

### Numeric Constraints

```python
# Slider with min/max (renders as slider in UI)
amount = fn.NodeInput(
    id="amount",
    type=float,
    default=0.5,
    value_options={"min": 0.0, "max": 1.0, "step": 0.1}
)

# Integer with minimum only
count = fn.NodeInput(
    id="count",
    type=int,
    default=1,
    value_options={"min": 1}
)
```

### Dropdown Options

```python
# Simple string options
mode = fn.NodeInput(
    id="mode",
    type=str,
    default="fast",
    value_options={"options": ["fast", "balanced", "accurate"]}
)

# Enum-style options (display labels different from values)
border_type = fn.NodeInput(
    id="border",
    type=int,
    default=0,
    value_options={
        "options": {
            "type": "enum",
            "keys": ["Constant", "Reflect", "Replicate"],
            "values": [0, 2, 1]
        }
    }
)
```

### Using DataEnum for Type-Safe Options

```python
from funcnodes_core import DataEnum

class ColorMode(DataEnum):
    RGB = ("rgb", "RGB Color")
    HSV = ("hsv", "HSV Color")
    GRAY = ("gray", "Grayscale")

@fn.NodeDecorator(node_id="convert_color")
def convert_color(
    image: "np.ndarray",
    mode: ColorMode = ColorMode.RGB
) -> "np.ndarray":
    return convert(image, mode.v())  # .v() gets the actual value
```

______________________________________________________________________

## Dynamic Value Options

Update input constraints based on other inputs using decorators:

### Dynamic Dropdown (Column Selector)

```python
from funcnodes_core.decorator import update_other_io_options

@fn.NodeDecorator(
    node_id="select_column",
    default_io_options={
        "df": {
            "on": {
                "after_set_value": update_other_io_options(
                    "column",  # Target input to update
                    lambda df: list(df.columns)  # Generate options
                )
            }
        },
    },
)
def select_column(df: "pd.DataFrame", column: str) -> "pd.Series":
    return df[column]
```

### Dynamic Numeric Bounds (List Index)

```python
from funcnodes_core.decorator import update_other_io_value_options

@fn.NodeDecorator(
    node_id="list_get",
    default_io_options={
        "lst": {
            "on": {
                "after_set_value": update_other_io_value_options(
                    "index",  # Target input
                    lambda lst: {
                        "min": -len(lst),
                        "max": len(lst) - 1 if len(lst) > 0 else 0,
                    }
                )
            }
        },
    },
)
def list_get(lst: list, index: int = -1) -> Any:
    return lst[index]
```

______________________________________________________________________

## Triggering Behavior

### `does_trigger` Parameter

Controls whether setting this input triggers node execution:

```python
class WaitNode(fn.Node):
    node_id = "wait_node"

    # Setting delay does NOT trigger the node
    delay = fn.NodeInput(
        id="delay",
        type=float,
        default=1.0,
        does_trigger=False,  # Change this without re-executing
        value_options={"min": 0.0}
    )

    # Setting input DOES trigger the node
    input = fn.NodeInput(id="input", type=Any)

    output = fn.NodeOutput(id="output", type=Any)

    async def func(self, delay, input):
        await asyncio.sleep(delay)
        self.outputs["output"].value = input
```

**Use cases for `does_trigger=False`:**

- Configuration parameters that shouldn't cause re-execution
- Parameters that are read during execution but don't initiate it
- Collector inputs in loop constructs

### Programmatic Value Setting

```python
# Set value and trigger (default)
node.inputs["value"].set_value(42)

# Set value without triggering
node.inputs["value"].set_value(42, does_trigger=False)

# Using property (always triggers based on does_trigger setting)
node.inputs["value"].value = 42
```

______________________________________________________________________

## Required vs Optional Inputs

### Required Inputs (`required=True`)

Node will **not execute** until all required inputs have values:

```python
class ProcessNode(fn.Node):
    node_id = "process_node"

    # Must be set before node can run
    data = fn.NodeInput(id="data", type=list, required=True)

    async def func(self, data):
        return process(data)
```

### Optional Inputs (`required=False`)

Node can execute even if these inputs have no value:

```python
class FormatNode(fn.Node):
    node_id = "format_node"

    value = fn.NodeInput(id="value", type=float, required=True)

    # Optional: uses default if not provided
    precision = fn.NodeInput(
        id="precision",
        type=int,
        default=2,
        required=False
    )

    async def func(self, value, precision):
        return f"{value:.{precision}f}"
```

______________________________________________________________________

## Default Values

### Static Defaults

```python
threshold = fn.NodeInput(id="threshold", type=float, default=0.5)
enabled = fn.NodeInput(id="enabled", type=bool, default=True)
items = fn.NodeInput(id="items", type=list, default=[])
```

### Dynamic Defaults with DefaultFactory

For defaults that depend on input state:

```python
class MyNode(fn.Node):
    node_id = "my_node"

    @staticmethod
    @fn.NodeInput.DefaultFactory
    def _default_timestamp(input: fn.NodeInput):
        """Generate timestamp when accessed."""
        import time
        return time.time()

    timestamp = fn.NodeInput(
        id="timestamp",
        type=float,
        default=_default_timestamp
    )
```

______________________________________________________________________

## Connection Behavior

### Single Connection (Default)

```python
# Only one output can connect to this input
input = fn.NodeInput(id="input", type=int, allow_multiple=False)
```

### Multiple Connections

```python
# Multiple outputs can connect (fan-in)
inputs = fn.NodeInput(id="inputs", type=Any, allow_multiple=True)
```

Fan-in Semantics

When multiple outputs connect to a single input, only the **last value set** is used. The values don't accumulate automatically.

### Disconnection Behavior

When an input is disconnected, it resets to its default value:

```python
# If default is NoValue, input becomes "not set"
# If default is provided, input gets that value
```

______________________________________________________________________

## Input Forwarding

Inputs can forward their values to other inputs (useful for subgraphs):

```python
# Forward value from one input to another
input_a.forward(input_b)

# Remove forwarding
input_a.unforward(input_b)

# Check forwarding relationships
input_a.has_forward_to(input_b)
input_b.has_forwards_from(input_a)
```

______________________________________________________________________

## Events

### Available Events

| Event               | When Fired              | Payload                               |
| ------------------- | ----------------------- | ------------------------------------- |
| `after_set_value`   | After value changes     | `{"src": input, "result": new_value}` |
| `before_connect`    | Before connection made  | Connection info                       |
| `after_connect`     | After connection made   | Connection info                       |
| `before_disconnect` | Before disconnection    | Disconnection info                    |
| `after_disconnect`  | After disconnection     | Disconnection info                    |
| `before_forward`    | Before input forwarding | Forward info                          |
| `after_forward`     | After input forwarding  | Forward info                          |

### Subscribing to Events

```python
# In class-based node
class MyNode(fn.Node):
    node_id = "my_node"

    value = fn.NodeInput(id="value", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.inputs["value"].on("after_set_value", self._on_value_change)

    def _on_value_change(self, msg):
        print(f"Value changed to: {msg['result']}")

# Using on parameter
value = fn.NodeInput(
    id="value",
    type=int,
    on={"after_set_value": lambda msg: print(f"New: {msg['result']}")}
)
```

______________________________________________________________________

## Render Options

### Custom Renderer Type

```python
# Render as color picker
color = fn.NodeInput(
    id="color",
    type=str,
    default="#ff0000",
    render_options={"type": "color"}
)

# Render with custom step display
delay = fn.NodeInput(
    id="delay",
    type=float,
    default=1.0,
    render_options={"step": "0.1"}
)
```

### Set Default on Manual Edit

```python
# When user manually edits, save as new default
config = fn.NodeInput(
    id="config",
    type=dict,
    render_options={"set_default": True}
)
```

______________________________________________________________________

## Status and State

### Check Input State

```python
input = node.inputs["value"]

# Check if value is set
has_value = input.value is not fn.NoValue

# Check if connected
is_connected = input.is_connected()

# Check if ready (has value or not required)
is_ready = input.ready()

# Get full status
status = input.status()
# Returns: {"has_value": bool, "has_node": bool, "ready": bool,
#           "connected": bool, "required": bool}
```

______________________________________________________________________

## Serialization

### Serialize Input State

```python
# Get serialized representation
serialized = input.serialize()
# Returns: {"id": "value", "type": "int", "value": 42, ...}

# Full serialization with all details
full = input.full_serialize(with_value=True)
```

### Restore from Serialized

```python
input.deserialize({"value": 42, "required": False})
```

______________________________________________________________________

## Complete Example

```python
import funcnodes_core as fn
from funcnodes_core.decorator import update_other_io_value_options
from typing import List, Any

@fn.NodeDecorator(
    node_id="funcnodes_example.list_processor",
    name="List Processor",
    description="Process a list with configurable options",
    default_io_options={
        "items": {
            "on": {
                "after_set_value": update_other_io_value_options(
                    "start_index",
                    lambda lst: {"min": 0, "max": len(lst) - 1} if lst else {"min": 0, "max": 0}
                )
            }
        }
    }
)
def list_processor(
    items: List[Any],
    start_index: int = 0,
    reverse: bool = False,
    limit: int = 10
) -> List[Any]:
    """Process a list with various options."""
    result = items[start_index:]
    if reverse:
        result = list(reversed(result))
    return result[:limit]
```

______________________________________________________________________

## See Also

- [Node Outputs](https://linkdlab.github.io/FuncNodes/components/nodeoutput/index.md) ‚Äî Output connection points
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî Complete IO reference
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî Node creation patterns
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event handling

# Node Outputs

`NodeOutput` is the output connection point for nodes in FuncNodes. It extends `NodeIO` and is responsible for sending data to connected inputs, triggering downstream execution.

______________________________________________________________________

## Constructor Parameters

```python
fn.NodeOutput(
    id: str,                           # Unique identifier (required)
    type: Type = Any,                  # Data type hint
    name: str = None,                  # Display name (defaults to id)
    description: str = None,           # Help text
    allow_multiple: bool = True,       # Allow multiple connections?
    hidden: bool = False,              # Hide in UI?
    value_options: dict = None,        # Value constraints (for previews)
    render_options: dict = None,       # UI rendering hints
    emit_value_set: bool = True,       # Emit events on value change?
    on: dict = None,                   # Event handlers
)
```

### Parameter Details

| Parameter        | Type   | Default  | Description                                                                               |
| ---------------- | ------ | -------- | ----------------------------------------------------------------------------------------- |
| `id`             | `str`  | Required | Unique identifier within the node. Used for programmatic access via `node.outputs["id"]`. |
| `type`           | `Type` | `Any`    | Python type hint. Affects how value is previewed in UI and serialized.                    |
| `name`           | `str`  | `id`     | Human-readable display name shown in UI.                                                  |
| `description`    | `str`  | `None`   | Tooltip/help text shown on hover in UI.                                                   |
| `allow_multiple` | `bool` | `True`   | If `True`, can connect to multiple inputs (fan-out). Almost always `True`.                |
| `hidden`         | `bool` | `False`  | If `True`, output is hidden from UI (but still functional).                               |
| `value_options`  | `dict` | `None`   | Metadata for previews (rarely used for outputs).                                          |
| `render_options` | `dict` | `None`   | UI hints for rendering previews.                                                          |
| `emit_value_set` | `bool` | `True`   | If `True`, emits `after_set_value` event when value changes.                              |
| `on`             | `dict` | `None`   | Event handlers to register.                                                               |

______________________________________________________________________

## Basic Usage

### Class-Based Nodes

```python
import funcnodes_core as fn

class CalculatorNode(fn.Node):
    node_id = "calculator"
    node_name = "Calculator"

    a = fn.NodeInput(id="a", type=float, default=0.0)
    b = fn.NodeInput(id="b", type=float, default=0.0)

    # Single output
    result = fn.NodeOutput(id="result", type=float)

    async def func(self, a, b):
        # Explicitly set output value
        self.outputs["result"].value = a + b
```

### Decorator-Based Nodes

With decorators, outputs are created from return type annotations:

```python
# Single output (named "out" by default)
@fn.NodeDecorator(node_id="double")
def double(x: float) -> float:
    return x * 2
```

### Using Type Annotations with `OutputMeta`

For more control over output properties in decorator-based nodes, use `typing.Annotated` with `fn.OutputMeta`:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="process")
def process(
    value: int
) -> Annotated[int, fn.OutputMeta(name="result", description="Processed value")]:
    return value + 1
```

This approach:

- Uses `Annotated` on the **return type**
- The output **type** comes from the first argument to `Annotated`
- The output **name** and other properties come from `OutputMeta`

### `OutputMeta` Parameters

| Parameter        | Type   | Description                 |
| ---------------- | ------ | --------------------------- |
| `name`           | `str`  | Display name for the output |
| `description`    | `str`  | Help text shown in UI       |
| `hidden`         | `bool` | Whether to hide in UI       |
| `render_options` | `dict` | UI rendering hints          |

### Combining `InputMeta` and `OutputMeta`

You can use both in the same node for full control:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(
    a: Annotated[
        int,
        fn.InputMeta(
            name="Input Value",
            description="Value to increment",
            default=1,
            does_trigger=False,
        ),
    ],
) -> Annotated[int, fn.OutputMeta(name="Result", description="Incremented value")]:
    return a + 1
```

______________________________________________________________________

## Setting Output Values

### In Class-Based Nodes

Outputs must be set **explicitly** in the `func` method:

```python
class MyNode(fn.Node):
    node_id = "my_node"

    input = fn.NodeInput(id="input", type=int)
    output = fn.NodeOutput(id="output", type=int)
    debug = fn.NodeOutput(id="debug", type=str)

    async def func(self, input):
        # Set outputs explicitly
        self.outputs["output"].value = input * 2
        self.outputs["debug"].value = f"Processed: {input}"
```

### In Decorator-Based Nodes

Return values are automatically assigned to outputs:

```python
# Single return ‚Üí single output "out"
@fn.NodeDecorator(node_id="add")
def add(a: int, b: int) -> int:
    return a + b  # Assigned to output "out"
```

______________________________________________________________________

## Multiple Outputs

### Class-Based Approach

Simply define multiple `NodeOutput` attributes:

```python
class DivModNode(fn.Node):
    node_id = "divmod_node"

    a = fn.NodeInput(id="a", type=int)
    b = fn.NodeInput(id="b", type=int)

    quotient = fn.NodeOutput(id="quotient", type=int)
    remainder = fn.NodeOutput(id="remainder", type=int)

    async def func(self, a, b):
        q, r = divmod(a, b)
        self.outputs["quotient"].value = q
        self.outputs["remainder"].value = r
```

### Decorator with Typed Tuple

For multiple outputs in decorators, use `Tuple` with type hints:

```python
from typing import Tuple

@fn.NodeDecorator(node_id="divmod")
def divmod_node(a: int, b: int) -> Tuple[int, int]:
    return divmod(a, b)  # Creates outputs "out_0" and "out_1"
```

### Named Multiple Outputs

Use the `outputs` parameter to name them:

```python
from typing import Tuple

@fn.NodeDecorator(
    node_id="divmod",
    outputs=[
        {"name": "quotient"},
        {"name": "remainder"}
    ]
)
def divmod_node(a: int, b: int) -> Tuple[int, int]:
    q, r = divmod(a, b)
    return q, r  # quotient, remainder
```

### With Types in Output Spec

```python
@fn.NodeDecorator(
    node_id="stats",
    outputs=[
        {"name": "mean", "type": float},
        {"name": "std", "type": float},
        {"name": "count", "type": int}
    ]
)
def statistics(data: list) -> Tuple[float, float, int]:
    import statistics as st
    return st.mean(data), st.stdev(data), len(data)
```

______________________________________________________________________

## NoValue ‚Äî Conditional Outputs

`NoValue` is a special sentinel that indicates "no data". When an output is set to `NoValue`, it **does not trigger** connected inputs.

### Suppressing Downstream Triggers

```python
from funcnodes_core import NoValue

class ConditionalNode(fn.Node):
    node_id = "conditional"

    condition = fn.NodeInput(id="condition", type=bool)
    value = fn.NodeInput(id="value", type=Any)

    on_true = fn.NodeOutput(id="on_true", type=Any)
    on_false = fn.NodeOutput(id="on_false", type=Any)

    async def func(self, condition, value):
        if condition:
            self.outputs["on_true"].value = value
            self.outputs["on_false"].value = NoValue  # Won't trigger connected nodes
        else:
            self.outputs["on_true"].value = NoValue
            self.outputs["on_false"].value = value
```

### In Decorators

```python
from funcnodes_core import NoValue

@fn.NodeDecorator(
    node_id="filter_positive",
    outputs=[{"name": "positive"}, {"name": "negative"}]
)
def filter_positive(value: float) -> Tuple[float, float]:
    if value >= 0:
        return value, NoValue  # Only positive output triggers
    else:
        return NoValue, value  # Only negative output triggers
```

______________________________________________________________________

## Output Value Propagation

When an output value is set, it automatically propagates to all connected inputs:

```
flowchart TD
    SetOutput["Output.value = x"]
    ForEach["For each<br/>connected input"]
    SetInput["input.set_value(x)"]
    InputTrigger["input.trigger()"]
    NodeTrigger["node.trigger()<br/>(if ready)"]

    SetOutput --> ForEach
    ForEach --> SetInput
    SetInput --> InputTrigger
    InputTrigger --> NodeTrigger
```

### Propagation Timing

- Values propagate **immediately** when set
- All connected inputs receive the value
- Each input may trigger its node (if `does_trigger=True`)
- Execution cascades through the graph

______________________________________________________________________

## Connection Behavior

### Fan-Out (Default)

Outputs can connect to **multiple inputs** by default:

```python
# Single output connected to multiple nodes
output = fn.NodeOutput(id="result", type=float)

# Connect to multiple inputs
output.connect(node1.inputs["a"])
output.connect(node2.inputs["x"])
output.connect(node3.inputs["value"])
# All three inputs receive the same value
```

### Restricting Connections

Rarely needed, but you can limit to single connection:

```python
# Only one input can connect (unusual for outputs)
exclusive_output = fn.NodeOutput(
    id="exclusive",
    type=Any,
    allow_multiple=False
)
```

### Connection on Value Set

When a new connection is made, the current output value is **immediately sent** to the newly connected input:

```python
# If output.value is already 42
output.connect(new_input)
# new_input.value is now 42
```

______________________________________________________________________

## Hidden Outputs

Hide outputs that are for internal use or debugging:

```python
class DebugNode(fn.Node):
    node_id = "debug_node"

    input = fn.NodeInput(id="input", type=Any)

    # Visible in UI
    result = fn.NodeOutput(id="result", type=Any)

    # Hidden from UI (for debugging/internal use)
    trace = fn.NodeOutput(id="trace", type=str, hidden=True)

    async def func(self, input):
        self.outputs["result"].value = process(input)
        self.outputs["trace"].value = f"Processed at {time.time()}"
```

______________________________________________________________________

## Preview Rendering

### Default Render Options

Configure how the output preview is displayed:

```python
class ImageNode(fn.Node):
    node_id = "image_processor"

    # Tell UI which output to use for node preview
    default_render_options = {
        "data": {"src": "output_image"}
    }

    input_image = fn.NodeInput(id="input_image", type="np.ndarray")
    output_image = fn.NodeOutput(id="output_image", type="np.ndarray")
```

### Per-Output Render Options

```python
# Plotly figure output
figure = fn.NodeOutput(
    id="figure",
    type="plotly.graph_objs.Figure",
    render_options={"type": "plotly"}
)
```

______________________________________________________________________

## Events

### Available Events

| Event               | When Fired             | Payload                                |
| ------------------- | ---------------------- | -------------------------------------- |
| `after_set_value`   | After value changes    | `{"src": output, "result": new_value}` |
| `before_connect`    | Before connection made | Connection info                        |
| `after_connect`     | After connection made  | Connection info                        |
| `before_disconnect` | Before disconnection   | Disconnection info                     |
| `after_disconnect`  | After disconnection    | Disconnection info                     |

### Subscribing to Events

```python
class MyNode(fn.Node):
    node_id = "my_node"

    output = fn.NodeOutput(id="output", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["output"].on("after_set_value", self._on_output_change)

    def _on_output_change(self, msg):
        print(f"Output set to: {msg['result']}")
```

______________________________________________________________________

## Status and State

### Check Output State

```python
output = node.outputs["result"]

# Check if value is set
has_value = output.value is not fn.NoValue

# Check if connected
is_connected = output.is_connected()

# Get connections
connections = output.connections  # List of connected NodeInputs

# Get full status
status = output.status()
# Returns: {"has_value": bool, "has_node": bool, "ready": bool, "connected": bool}
```

______________________________________________________________________

## Manual Triggering

Force propagation to connected inputs:

```python
# Trigger all connected inputs with current value
output.trigger()

# This:
# 1. Sets value on all connected inputs (without triggering them)
# 2. Then triggers each connected input
```

______________________________________________________________________

## Serialization

### Serialize Output State

```python
# Get serialized representation
serialized = output.serialize()
# Returns: {"id": "result", "type": "float", ...}

# Full serialization with value
full = output.full_serialize(with_value=True)
```

______________________________________________________________________

## Complete Examples

### Router Node (Conditional Output)

```python
import funcnodes_core as fn
from funcnodes_core import NoValue
from typing import Any

class RouterNode(fn.Node):
    """Routes input to one of multiple outputs based on a selector."""

    node_id = "router"
    node_name = "Router"

    value = fn.NodeInput(id="value", type=Any)
    route = fn.NodeInput(
        id="route",
        type=int,
        default=0,
        value_options={"min": 0, "max": 2}
    )

    out_0 = fn.NodeOutput(id="out_0", type=Any)
    out_1 = fn.NodeOutput(id="out_1", type=Any)
    out_2 = fn.NodeOutput(id="out_2", type=Any)

    async def func(self, value, route):
        outputs = [self.outputs["out_0"],
                   self.outputs["out_1"],
                   self.outputs["out_2"]]

        for i, out in enumerate(outputs):
            if i == route:
                out.value = value
            else:
                out.value = NoValue  # Don't trigger other routes
```

### Statistics Node (Multiple Typed Outputs)

```python
from typing import Tuple, List
import statistics

@fn.NodeDecorator(
    node_id="statistics",
    name="Statistics",
    outputs=[
        {"name": "mean", "type": float},
        {"name": "median", "type": float},
        {"name": "stdev", "type": float},
        {"name": "min", "type": float},
        {"name": "max", "type": float},
    ]
)
def calc_statistics(
    data: List[float]
) -> Tuple[float, float, float, float, float]:
    """Calculate various statistics for a list of numbers."""
    return (
        statistics.mean(data),
        statistics.median(data),
        statistics.stdev(data) if len(data) > 1 else 0.0,
        min(data),
        max(data),
    )
```

### Image Processing with Preview

```python
import funcnodes_core as fn

class GrayscaleNode(fn.Node):
    """Convert image to grayscale."""

    node_id = "grayscale"
    node_name = "To Grayscale"

    # Configure preview to show output_image
    default_render_options = {
        "data": {"src": "output_image"}
    }

    input_image = fn.NodeInput(id="input_image", type="np.ndarray")
    output_image = fn.NodeOutput(id="output_image", type="np.ndarray")

    async def func(self, input_image):
        import cv2
        gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)
        self.outputs["output_image"].value = gray
```

______________________________________________________________________

## Comparison: Input vs Output

| Aspect                     | NodeInput             | NodeOutput          |
| -------------------------- | --------------------- | ------------------- |
| **Direction**              | Receives data         | Sends data          |
| **allow_multiple default** | `False`               | `True`              |
| **Triggers node**          | Yes (configurable)    | No                  |
| **Has default value**      | Yes                   | No                  |
| **required parameter**     | Yes                   | No                  |
| **does_trigger parameter** | Yes                   | No                  |
| **Value propagation**      | From connected output | To connected inputs |

______________________________________________________________________

## See Also

- [Node Inputs](https://linkdlab.github.io/FuncNodes/components/nodeinput/index.md) ‚Äî Input connection points
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî Complete IO reference
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî Node creation patterns
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event handling

# NodeSpace (Graph State)

`NodeSpace` is the in‚Äëmemory representation of a FuncNodes graph plus its library snapshot. Each worker owns exactly one `NodeSpace`.

## What a NodeSpace contains

- **Nodes:** Instances of node classes keyed by UUID.
- **Edges:** Connections between outputs and inputs (stored as tuples of source/target UUIDs and IO IDs).
- **Library:** A `funcnodes_core.lib.Library` with all shelves/nodes visible to this worker.
- **Properties:** Public `prop` (JSON‚Äëserializable) and non‚Äëserialized `secret` properties for runtime state.
- **Groups:** Optional node group metadata from `GroupingLogic`.

## Serialization

Two JSON shapes are used:

- `serialize()` ‚Üí minimal `NodeSpaceJSON` with `nodes`, `edges`, `prop`, `groups`. IO values are included only if set as defaults; secret properties are excluded.
- `full_serialize(with_io_values=False)` ‚Üí adds `lib` (full shelf tree) and can embed current IO values when requested.

Files on disk (`nodespace.json` inside each worker‚Äôs data directory) use `serialize()`. They are read back with `deserialize`, which re‚Äëhydrates nodes via the library; missing classes become `PlaceHolderNode` instances.

## Edge and connection rules

- Connections must be output‚Üíinput (or input forwarding) and honor each IO‚Äôs `allow_multiple` flag; violations raise `NodeConnectionError` / `MultipleConnectionsError`.
- There is no automatic cycle detection; avoid wiring graphs that feed back indefinitely unless your node logic guards against it.

## Lifecycle hooks

`NodeSpace` emits events on node add/remove, trigger errors (`node_error` / `node_trigger_error`), and cleanup. Workers subscribe to these to update clients.

Error handling is event-only: there is no built-in retry/backoff. When a node raises, the error event is emitted and the node stays in its current state until retriggered by another input change or a manual trigger.

## Persistence cadence

Workers run a `SaveLoop` that writes the serialized NodeSpace to disk when `request_save()` is set (e.g., after edits). Exporting a worker bundles this serialized graph together with config and optional files.

# Serialization

FuncNodes uses a custom JSON serialization system to persist workflows, transfer data between workers, and render previews in the UI. This page covers the complete serialization API.

______________________________________________________________________

## Overview

The serialization system consists of:

| Component      | Purpose                                          |
| -------------- | ------------------------------------------------ |
| `JSONEncoder`  | Converts Python objects to JSON-compatible types |
| `JSONDecoder`  | Restores Python objects from JSON                |
| `ByteEncoder`  | Converts objects to binary data with MIME types  |
| `Encdata`      | Return type for JSON encoders                    |
| `BytesEncdata` | Return type for byte encoders                    |

______________________________________________________________________

## JSONEncoder

`JSONEncoder` extends Python's `json.JSONEncoder` with a registry of custom handlers.

### Basic Usage

```python
import json
from funcnodes_core.utils.serialization import JSONEncoder

# Encode an object
data = {"array": my_numpy_array, "figure": my_plotly_figure}
json_string = json.dumps(data, cls=JSONEncoder)

# Apply encoding without full JSON serialization
encoded = JSONEncoder.apply_custom_encoding(my_object, preview=False)
```

### The `preview` Parameter

Encoders receive a `preview` flag that indicates lightweight encoding for UI display:

- **`preview=False`** ‚Äî Full serialization for persistence/transfer
- **`preview=True`** ‚Äî Truncated/simplified output for UI previews

Built-in preview behaviors:

- Strings longer than 1000 characters are truncated with `...`
- Lists are limited to the first 10 items
- Large arrays may use simplified representations

______________________________________________________________________

## Registering Custom Encoders

### Simple Encoder (Tuple Return)

```python
from funcnodes_core.utils.serialization import JSONEncoder

def my_encoder(obj, preview=False):
    """Simple encoder returning (data, handled) tuple."""
    if isinstance(obj, MyCustomType):
        return obj.to_dict(), True  # (encoded_data, was_handled)
    return obj, False  # Not handled, pass to next encoder

JSONEncoder.add_encoder(my_encoder)
```

### Advanced Encoder (Encdata Return)

For more control, return an `Encdata` object:

```python
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def my_encoder(obj, preview=False):
    """Advanced encoder with Encdata control."""
    if isinstance(obj, MyCustomType):
        return Encdata(
            data=obj.to_dict(),
            handeled=True,
            done=False,           # Continue encoding nested objects
            continue_preview=None # Inherit preview setting
        )
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(my_encoder)
```

### Encdata Parameters

| Parameter          | Type             | Description                                                                                                  |
| ------------------ | ---------------- | ------------------------------------------------------------------------------------------------------------ |
| `data`             | `Any`            | The encoded data                                                                                             |
| `handeled`         | `bool`           | Whether this encoder processed the object                                                                    |
| `done`             | `bool`           | If `True`, stop encoding (return data as-is). If `False`, continue encoding nested objects. Default: `False` |
| `continue_preview` | `Optional[bool]` | Override preview flag for nested encoding. `None` inherits current setting.                                  |

### Type-Specific Registration

Register encoders for specific types to improve performance:

```python
from pathlib import Path
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def path_encoder(obj, preview=False):
    if isinstance(obj, Path):
        return Encdata(data=obj.as_posix(), handeled=True)
    return Encdata(data=obj, handeled=False)

# Only called for Path objects (and subclasses)
JSONEncoder.add_encoder(path_encoder, enc_cls=[Path])
```

### Encoder Priority

Use `prepend_encoder` to add an encoder at the front of the queue (higher priority):

```python
# This encoder will be tried before others for the specified types
JSONEncoder.prepend_encoder(my_high_priority_encoder, enc_cls=[MyType])
```

______________________________________________________________________

## Real-World Encoder Examples

### NumPy Arrays

```python
import numpy as np
import funcnodes_core as fn

def numpy_encoder(obj, preview=False):
    if isinstance(obj, np.ndarray):
        if preview:
            # Simplified preview for UI
            return obj.tolist()[:10], True
        return obj.tolist(), True
    return obj, False

fn.JSONEncoder.add_encoder(numpy_encoder)
```

### Plotly Figures

```python
import plotly.graph_objects as go
import funcnodes_core as fn

def figure_encoder(figure: go.Figure, preview=False):
    if isinstance(figure, go.Figure):
        return fn.Encdata(
            data=figure.to_plotly_json(),
            handeled=True,
            done=False,              # Allow nested encoding
            continue_preview=False,  # Disable preview for nested data
        )
    return fn.Encdata(data=figure, handeled=False)

fn.JSONEncoder.add_encoder(figure_encoder, enc_cls=[go.Figure])
```

### Pydantic Models

```python
from pydantic import BaseModel
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def pydantic_encoder(obj, preview=False):
    if isinstance(obj, BaseModel):
        return Encdata(
            data=obj.model_dump(mode="json"),
            handeled=True,
            done=True,  # Already JSON-compatible
        )
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(pydantic_encoder, enc_cls=[BaseModel])
```

______________________________________________________________________

## JSONDecoder

`JSONDecoder` restores Python objects from JSON using registered decoders.

### Basic Usage

```python
import json
from funcnodes_core.utils.serialization import JSONDecoder

# Decode JSON string
data = json.loads(json_string, cls=JSONDecoder)
```

### Registering Decoders

Decoders are called for each dict/value during parsing:

```python
from funcnodes_core.utils.serialization import JSONDecoder

def my_decoder(obj):
    """Decoder returning (result, handled) tuple."""
    if isinstance(obj, dict) and obj.get("__type__") == "MyCustomType":
        return MyCustomType.from_dict(obj), True
    return obj, False

JSONDecoder.add_decoder(my_decoder)
```

### Decoder Signature

```python
def decoder(obj: Any) -> Tuple[Any, bool]:
    """
    Args:
        obj: The JSON value (dict, list, str, int, float, bool, None)

    Returns:
        Tuple of (decoded_object, was_handled)
    """
```

______________________________________________________________________

## ByteEncoder

`ByteEncoder` converts objects to binary data with MIME types for efficient transfer.

### Basic Usage

```python
from funcnodes_core.utils.serialization import ByteEncoder

result = ByteEncoder.encode(my_object, preview=False)
# result.data: bytes
# result.mime: str (e.g., "application/json", "image/png")
# result.handeled: bool
```

### Registering Byte Encoders

```python
from funcnodes_core.utils.serialization import ByteEncoder, BytesEncdata

def image_byte_encoder(obj, preview=False):
    if isinstance(obj, MyImageType):
        return BytesEncdata(
            data=obj.to_png_bytes(),
            handeled=True,
            mime="image/png"
        )
    return BytesEncdata(data=obj, handeled=False)

ByteEncoder.add_encoder(image_byte_encoder, enc_cls=[MyImageType])
```

### BytesEncdata Parameters

| Parameter  | Type            | Description                               |
| ---------- | --------------- | ----------------------------------------- |
| `data`     | `bytes \| Any`  | The encoded binary data                   |
| `handeled` | `bool`          | Whether this encoder processed the object |
| `mime`     | `Optional[str]` | MIME type of the encoded data             |

### Built-in MIME Types

| Type          | MIME                       |
| ------------- | -------------------------- |
| `str`         | `text/plain`               |
| `bytes`       | `application/octet-stream` |
| `int`         | `application/fn.struct.!q` |
| `float`       | `application/fn.struct.!d` |
| `bool`        | `application/fn.struct.?`  |
| `None`        | `application/fn.null`      |
| JSON fallback | `application/json`         |

______________________________________________________________________

## Built-in Type Handlers

### Bytes

Bytes are Base64 encoded for JSON:

```python
import base64

# Encoding: bytes ‚Üí base64 string
encoded = base64.b64encode(my_bytes).decode("utf-8")

# Built-in handler does this automatically
```

### Dataclasses

Dataclasses are automatically converted to dictionaries:

```python
from dataclasses import dataclass

@dataclass
class MyData:
    name: str
    value: int

# Automatically serializes to {"name": "...", "value": ...}
```

### Objects with `_repr_json_`

Objects implementing `_repr_json_()` method are automatically encoded:

```python
class MyType:
    def _repr_json_(self):
        """Return JSON-serializable representation."""
        return {"type": "MyType", "data": self._internal_data}
```

______________________________________________________________________

## Persistence Files

FuncNodes uses these files for persistence:

| File                 | Content                                       | Format  |
| -------------------- | --------------------------------------------- | ------- |
| `nodespace.json`     | Serialized graph state (nodes, edges, groups) | JSON    |
| `worker_<uuid>.json` | Worker configuration and metadata             | JSON    |
| `config.json`        | Global FuncNodes settings                     | JSON    |
| `io_values/`         | Large IO values stored separately             | Various |

### Nodespace Serialization

```python
# Save nodespace
nodespace.serialize()  # Returns dict
json.dumps(nodespace.serialize(), cls=JSONEncoder)

# Load nodespace
nodespace.deserialize(data)
```

### Node Serialization

```python
# Full serialization (for persistence)
node.full_serialize()

# Returns:
{
    "node_id": "my_node",
    "uuid": "abc123...",
    "io": [...],  # Serialized inputs/outputs
    "render_options": {...},
    "properties": {...}
}
```

______________________________________________________________________

## Performance Considerations

### Large Data

For large arrays or binary data:

1. **Use file references** instead of embedding data:

```python
# Instead of storing array in JSON
# Store path to file and load on demand
{"__file__": "data/large_array.npy"}
```

1. **Use ByteEncoder** for binary transfer (more efficient than Base64)
1. **Enable preview mode** for UI display to truncate large data

### Circular References

The encoder detects circular references and raises `ValueError`:

```python
# This will raise ValueError
a = {}
a["self"] = a
JSONEncoder.apply_custom_encoding(a)  # ValueError: Circular reference detected
```

### Encoder Ordering

- Register type-specific encoders with `enc_cls` for better performance
- Use `prepend_encoder` for high-priority handlers
- The encoder chain stops at the first handler that returns `handeled=True`

______________________________________________________________________

## Module Integration

### Registering Encoders in Modules

Add encoders in your module's `__init__.py`:

```python
# mymodule/__init__.py
import funcnodes_core as fn
from .types import MyCustomType

def my_encoder(obj, preview=False):
    if isinstance(obj, MyCustomType):
        return fn.Encdata(
            data={"__type__": "MyCustomType", **obj.to_dict()},
            handeled=True
        )
    return fn.Encdata(data=obj, handeled=False)

# Register when module is imported
fn.JSONEncoder.add_encoder(my_encoder, enc_cls=[MyCustomType])
```

### Render Options for Custom Types

Tell the UI how to display your type:

```python
FUNCNODES_RENDER_OPTIONS: fn.RenderOptions = {
    "typemap": {
        "mymodule.MyCustomType": "json",  # Render as JSON viewer
    },
    "inputconverter": {
        "mymodule.MyCustomType": "str_to_json",  # Parse JSON input
    },
}
```

______________________________________________________________________

## Complete Example

```python
import funcnodes_core as fn
from funcnodes_core.utils.serialization import (
    JSONEncoder, JSONDecoder, ByteEncoder,
    Encdata, BytesEncdata
)
from dataclasses import dataclass

@dataclass
class Measurement:
    timestamp: float
    values: list[float]
    unit: str

# JSON Encoder
def measurement_encoder(obj, preview=False):
    if isinstance(obj, Measurement):
        data = {
            "__type__": "Measurement",
            "timestamp": obj.timestamp,
            "values": obj.values[:10] if preview else obj.values,
            "unit": obj.unit,
        }
        return Encdata(data=data, handeled=True, done=True)
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(measurement_encoder, enc_cls=[Measurement])

# JSON Decoder
def measurement_decoder(obj):
    if isinstance(obj, dict) and obj.get("__type__") == "Measurement":
        return Measurement(
            timestamp=obj["timestamp"],
            values=obj["values"],
            unit=obj["unit"]
        ), True
    return obj, False

JSONDecoder.add_decoder(measurement_decoder)

# Byte Encoder (for efficient binary transfer)
def measurement_byte_encoder(obj, preview=False):
    if isinstance(obj, Measurement):
        import json
        data = json.dumps({
            "timestamp": obj.timestamp,
            "values": obj.values,
            "unit": obj.unit,
        }).encode("utf-8")
        return BytesEncdata(data=data, handeled=True, mime="application/json")
    return BytesEncdata(data=obj, handeled=False)

ByteEncoder.add_encoder(measurement_byte_encoder, enc_cls=[Measurement])
```

______________________________________________________________________

## Best Practices

1. **Keep IO values serializable** ‚Äî Use JSON-compatible types or register encoders
1. **Use `enc_cls` for type-specific encoders** ‚Äî Improves performance by skipping irrelevant handlers
1. **Support preview mode** ‚Äî Truncate large data for UI display
1. **Use `done=True` for terminal encodings** ‚Äî When data is already JSON-compatible
1. **Avoid embedding large binary data** ‚Äî Use file references or ByteEncoder
1. **Register decoders for round-trip support** ‚Äî Ensure deserialization works correctly
1. **Handle edge cases** ‚Äî `None`, empty collections, `NaN` values

______________________________________________________________________

## See Also

- [Nodespace](https://linkdlab.github.io/FuncNodes/components/nodespace/index.md) ‚Äî Graph state and persistence
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî IO serialization
- [Writing Modules](https://linkdlab.github.io/FuncNodes/extending/writing-modules/index.md) ‚Äî Module development

# Shelves (Node Library Groups)

Shelves are the catalog entries that tell FuncNodes which node classes are available and how they are grouped in the UI. A shelf is a small tree that contains node classes (`funcnodes_core.node.Node`) and optional subshelves.

## Structure

- **Data model:** `funcnodes_core.lib.Shelf` holds `name`, `description`, `nodes` (list of node classes), and `subshelves` (list of Shelves). Each shelf gets a generated `shelf_id` when validated.
- **Serialization:** Shelves serialize to JSON via `funcnodes_core.lib.serialize_shelf`, emitting `name`, `description`, `nodes` (serialized node classes), and nested `subshelves`.
- **Storage:** The runtime keeps a flat registry (`funcnodes_core.lib.Library`) keyed by tuple paths (`("Top", "Child", ...)`) for GC‚Äëfriendly storage. Complete shelf trees are materialized on demand.

## How shelves are discovered

FuncNodes loads shelves from installed Python packages via the `funcnodes.module` entry point group:

- If a distribution exposes `shelf = "<pkg>:<object>"` under `project.entry-points."funcnodes.module"`, that object is read and validated with `funcnodes_core.lib.check_shelf`. Dictionaries are accepted and converted to `Shelf` instances.
- If no `shelf` entry point is present, FuncNodes falls back to introspection: every non‚Äëabstract subclass of `Node` defined in the module is collected into a shelf named after the module (`funcnodes_core.lib.libparser.module_to_shelf`).
- Additional optional entry points (`render_options`, `external_worker`, `plugin_setup`) may also be exported; they are processed in `_setup.py` but do not affect shelf discovery itself.

Example (from `modules/funcnodes_files/pyproject.toml`):

```toml
[project.entry-points."funcnodes.module"]
module = "funcnodes_files"
shelf = "funcnodes_files:NODE_SHELF"
react_plugin = "funcnodes_files:REACT_PLUGIN"
```

Here `NODE_SHELF` is the authoritative shelf object; the React plugin entry point is consumed by the UI host but does not change the shelf tree.

## How shelves are mounted at runtime

- The Workermanager/Worker loads installed modules, parses their entry points, and registers shelves into a `Library` instance attached to each `NodeSpace`.
- `Library.add_shelf` merges shelves by path, keeping node IDs unique per shelf. External shelves can be mounted via weak references (`add_external_shelf`, `add_subshelf_weak`) so they disappear automatically when their owner is GC‚Äôd.
- Finding nodes is path‚Äëaware: `Library.find_nodeid` returns all shelf paths containing a node ID, and `get_node_by_id` only succeeds if the node is both registered and referenced by at least one shelf.

## Authoring guidance for module writers

- Export a `Shelf` (or dict convertible to one) through the `funcnodes.module` entry point to get precise grouping and descriptions.
- Ensure each node class has a globally unique `node_id`; shelves store only node IDs, so duplicates are skipped when the Library deduplicates.
- Organize subshelves for UI grouping‚Äîpaths are preserved (`["Vision", "Filters", ...]`) and rendered as nested menus in the editor host.

## What is a Worker?

Workers are long-lived processes that execute FuncNodes graphs. Each worker owns:

- A **NodeSpace** (graph state, groups, properties).
- An isolated **environment** (virtualenv by default) and dependency set.
- A **data directory** (`~/.funcnodes/workers/worker_<uuid>/`) containing `nodespace.json`, uploaded `files/`, optional `pyproject.toml`, and `worker.log`.
- A **WebSocket/HTTP server** that exposes RPC commands and large-payload endpoints.

Workers are started and supervised by the **Workermanager**, but you can also launch them directly via `funcnodes worker start`.

## Runtime loops & health

The worker event loop runs several recurring tasks:

- **NodeSpaceLoop** ‚Äî drains pending triggers (`NodeSpace.await_done`) on a short interval (default 5‚ÄØms).
- **SaveLoop** ‚Äî writes process/runstate files and persists the graph when `request_save()` is flagged.
- **LocalWorkerLookupLoop** ‚Äî discovers external worker classes in `data_path/local_scripts`.
- **HeartbeatLoop** ‚Äî optional; if `required_heartbeat` is set and no `heartbeat()` RPC arrives in time, the worker stops itself.

Defaults can be tuned via worker config (e.g., `nodespace_delay`, `save_delay`) for responsiveness vs. CPU/disk usage.

## RPC surface (WebSocket JSON)

Clients send `{"type":"cmd","cmd":<name>,"kwargs":{...}}`; worker replies with `result` or `error`. Common commands:

- **Identity/meta**: `uuid`, `name`, `get_meta`, `heartbeat`
- **State**: `full_state`, `get_nodes`, `get_edges`, `get_groups`, `view_state`, `get_save_state`
- **Mutations**: `update_node`, `update_group`, `group_nodes`, `remove_group`, `clear`, `save`, `load_data`, `export_worker`, `import_worker`
- **Library/modules**: `get_library`, `get_worker_dependencies`, `get_plugin_keys`, `get_plugin`, `add_package_dependency`, `remove_package_dependency`
- **External tooling**: `list_local_workers`, `start_local_worker`, `stop_local_worker`, `upload`

Ping/pong is built in (`{"type":"ping"}` ‚Üí `{"type":"pong"}`) and is how the UI detects liveness.

## Messaging & large payloads

- Standard messages travel over WebSockets as JSON.
- Messages larger than `MESSAGE_SIZE_BEFORE_REQUEST` (default 1‚ÄØMB) are staged in memory; the worker sends a `large_message` stub and exposes a temporary HTTP endpoint `/message/<msg_id>` for retrieval.
- Binary streams (e.g., image frames) are chunked with headers `chunk=<i>/<n>` to avoid blocking the socket.
- Uploads use `POST /upload/` and are forcibly rooted to `files/` inside the worker‚Äôs data dir; attempts to traverse elsewhere are rejected.

## Lifecycle & files on disk

When running, the worker writes:

- `worker_<uuid>.json` ‚Äî config (host/port, env paths, flags)
- `worker_<uuid>.p` ‚Äî PID file for liveness detection
- `worker_<uuid>.runstate` ‚Äî human-readable status (‚Äústarting‚Ä¶‚Äù, ‚Äúrunning‚Äù, etc.)

Shutting down clears PID/runstate and flushes a final save. Exports bundle `config`, `state`, optional `pyproject.toml`, and `files/` into a ZIP for backup/migration.

## Isolation & performance

- **Process/thread offload**: Nodes can set `separate_thread=True` or `separate_process=True` to avoid blocking the event loop.
- **Message size caps**: `MAX_DATA_SIZE` (default 10‚ÄØGB) protects memory; adjust via env if needed.
- **Logging**: Per-worker rotating file handler (~100‚ÄØKB √ó 5). Change location/level via config.

## Security considerations

- Workers do **not** implement authentication. In production, front them with an authenticated proxy (e.g., nginx/Traefik) and keep ports non-public. File writes are constrained to `files/`, but you should still sandbox network access and enforce upload size limits at the proxy.
- TLS termination is not provided by the worker itself; the `ssl` field in the config defaults to `False` and the WebSocket loop always starts plain HTTP. Terminate TLS in your proxy/load balancer instead.

## Environments & dependencies

- New workers create their own virtualenv unless started with `--not-in-venv`; sharing the interpreter is possible but increases the risk of version conflicts.
- The worker config carries `update_on_startup` flags (default `True` for `funcnodes`, `funcnodes-core`, `funcnodes-worker`) so core packages can be upgraded automatically when a worker starts.
- Additional packages installed via `funcnodes worker ... modules install ...` are tracked per worker in `package_dependencies`; isolated envs let different workers pin incompatible versions safely.

## Subprocess/offload options

- `@NodeDecorator(..., separate_thread=True)` runs the wrapped function in a thread; `separate_process=True` wraps it in a `ProcessPoolExecutor` (`funcnodes_core.utils.functions.make_run_in_new_process`).
- Workers expose an optional `subprocess_monitor` host/port in their config; if set, heavy external commands can be supervised by the `subprocess_monitor` service. FuncNodes itself does not enforce per-node resource limits‚Äîrely on the monitor/OS for that.

# Worker Configuration

Each worker keeps its own config file at `~/.funcnodes/workers/worker_<uuid>.json`. Key fields include:

- **uuid** / **name** ‚Äî worker identity.
- **data_path** ‚Äî worker data dir (nodespace.json, files/, logs).
- **env_path** ‚Äî virtualenv location (absent when created with `--not-in-venv`).
- **host/port/ssl** ‚Äî where the worker‚Äôs WS/HTTP server listens.
- **update_on_startup** ‚Äî flags to auto-upgrade `funcnodes`, `funcnodes-core`, and unpinned dependencies on activation.
- **nodespace_path** ‚Äî path to the current NodeSpace state file.
- **required_heartbeat** ‚Äî optional timeout for heartbeat enforcement.
- **workertype** ‚Äî worker class (defaults to WSWorker; extension point for external workers).
- **subprocess_monitor** ‚Äî optional host/port if using the subprocess monitor.

Creation and lifecycle:

- Generated when you run `funcnodes worker new ...`; updated when workers start/stop.
- The Workermanager reads this file to decide how to spawn and to report status.
- Edits can be made manually for advanced tuning (e.g., changing host/port) ‚Äî stop the worker first, edit, then restart.

Related liveness files:

- `worker_<uuid>.p` ‚Äî PID of the running process.
- `worker_<uuid>.runstate` ‚Äî human-readable startup/run status used by the UI.

## What is the Workermanager?

The Workermanager is a lightweight aiohttp service that supervises all workers on a host. It:

- Maintains worker metadata on disk (`~/.funcnodes/workers/worker_<uuid>.json/.p/.runstate`).
- Spawns, stops, restarts, deletes, and lists workers.
- Acts as a WebSocket hub so UIs can discover and control workers.
- Optionally provisions per-worker virtualenvs and upgrades packages on activation.

By default it listens on `localhost:9380` at `/` for WebSocket clients (no auth by default‚Äîsee Security).

## Message protocol (WebSocket)

Simple string commands:

- `ping` ‚Üí `pong`
- `identify` ‚Üí JSON `{ "class": "WorkerManager", "py": sys.executable }`
- `worker_status` ‚Üí lists active/inactive workers
- `stop` ‚Üí stop the manager

JSON commands (selected):

- `{ "type": "new_worker", "kwargs": {...} }` ‚Üí create worker (options: name, reference, copyLib, copyNS, in_venv toggle)
- `{ "type": "set_active", "workerid": uuid }` ‚Üí activate (start) worker
- `{ "type": "stop_worker", "workerid": uuid }`
- `{ "type": "restart_worker", "workerid": uuid }`
- `{ "type": "delete_worker", "workerid": uuid }`

Responses/broadcasts include:

- `worker_status` (active/inactive lists)
- `worker_created` / `worker_deleted`
- `set_worker` (full worker config once reachable)
- `progress` (text + progress float) to drive UI HUDs

## Files & liveness

Each worker has:

- `worker_<uuid>.json` ‚Äî config (host/port/env paths/nodespace path/flags)
- `worker_<uuid>.p` ‚Äî PID file written by the worker
- `worker_<uuid>.runstate` ‚Äî textual status during startup/running

Missing or stale files mark workers as inactive; status is refreshed every ~10‚ÄØs.

## Virtualenv & dependency management

- New workers default to their own venv unless `--not-in-venv` was set.
- On activation, optional `update_on_startup` flags can reinstall `funcnodes`, `funcnodes-core`, and unpinned dependencies.
- CLI helpers `funcnodes worker modules ‚Ä¶` run inside the worker env.

## Auto-start behavior

Clients (e.g., `funcnodes runserver`) call `assert_worker_manager_running`: it pings/identifies the manager and, if unreachable, spawns a fresh instance via `python -m funcnodes startworkermanager` (optionally through `subprocess_monitor`).

## Security

- No built-in authentication; expose only behind an authenticated reverse proxy.
- Keep the WS/HTTP ports private; block direct internet access.
- Size limits: large message/store defaults come from worker settings (`MAX_DATA_SIZE`, message expiry).
- TLS termination is not handled by the Workermanager itself; it serves plain HTTP/WebSocket. Terminate TLS at your proxy/load balancer if you need HTTPS/WSS.

## Operations cheat sheet

- Start manager: `funcnodes startworkermanager --host 0.0.0.0 --port 9380`
- List workers: `funcnodes worker list [--full]`
- New worker: `funcnodes worker new --name demo`
- Start worker: `funcnodes worker --name demo start`
- Delete worker: `funcnodes worker --name demo delete`
# Extending FuncNodes

# React Plugin Development

FuncNodes modules can include React plugins to provide custom UI components ‚Äî specialized input editors, output previews, and widgets that enhance the user experience for your node types.

______________________________________________________________________

## Overview

React plugins integrate with `@linkdlab/funcnodes_react_flow` (the FuncNodes UI host) and can provide:

- **Custom Previews** ‚Äî Rich rendering of output values (charts, images, 3D views)
- **Custom Inputs** ‚Äî Specialized editors (color pickers, molecule editors, file browsers)
- **Custom Widgets** ‚Äî Additional UI for node headers or panels

```text
my_module/
‚îú‚îÄ‚îÄ src/funcnodes_mymodule/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ nodes.py
‚îÇ   ‚îî‚îÄ‚îÄ _react_plugin.py    # Plugin info export
‚îî‚îÄ‚îÄ react_plugin/
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ vite.config.ts
    ‚îú‚îÄ‚îÄ tsconfig.json
    ‚îî‚îÄ‚îÄ src/
        ‚îî‚îÄ‚îÄ index.tsx       # Plugin implementation
```

______________________________________________________________________

## Quick Start

### 1. Scaffold with funcnodes_module

```bash
funcnodes_module create funcnodes_mymodule --with-react-plugin
```

This creates a complete React plugin scaffold ready to customize.

### 2. Manual Setup

Create the plugin directory:

```bash
mkdir -p react_plugin/src
cd react_plugin
```

Create `package.json`:

```json
{
  "name": "funcnodes-mymodule-react",
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "vite build --watch",
    "build": "vite build"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0"
  },
  "devDependencies": {
    "@linkdlab/funcnodes_react_flow": "latest",
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "@vitejs/plugin-react": "^4.0.0",
    "typescript": "^5.0.0",
    "vite": "^5.0.0"
  },
  "peerDependencies": {
    "@linkdlab/funcnodes_react_flow": "*",
    "react": "^18.2.0",
    "react-dom": "^18.2.0"
  }
}
```

Create `vite.config.ts`:

```typescript
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react";
import { resolve } from "path";

export default defineConfig({
  plugins: [react()],
  build: {
    lib: {
      entry: resolve(__dirname, "src/index.tsx"),
      name: "FuncNodesPlugin",  // MUST be "FuncNodesPlugin"
      formats: ["es"],
      fileName: () => "funcnodes_mymodule_react.es.js"
    },
    rollupOptions: {
      external: [
        "react",
        "react-dom",
        "@linkdlab/funcnodes_react_flow"
      ],
      output: {
        globals: {
          react: "React",
          "react-dom": "ReactDOM",
          "@linkdlab/funcnodes_react_flow": "FuncNodesReactFlow"
        }
      }
    },
    outDir: "../src/funcnodes_mymodule/react_plugin"
  }
});
```

Create `tsconfig.json`:

```json
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true
  },
  "include": ["src"]
}
```

______________________________________________________________________

## Plugin Implementation

### Basic Plugin Structure

Create `src/index.tsx`:

```typescript
import React from "react";
import {
  FuncNodesReactPlugin,
  RenderNodeOutputProps,
  RenderNodeInputProps,
} from "@linkdlab/funcnodes_react_flow";

// Custom preview component
const MyTypePreview: React.FC<{ value: any }> = ({ value }) => {
  return (
    <div style={{ padding: 8, background: "#f0f0f0", borderRadius: 4 }}>
      <pre>{JSON.stringify(value, null, 2)}</pre>
    </div>
  );
};

// Custom input component
const MyTypeInput: React.FC<{
  value: any;
  onChange: (value: any) => void;
}> = ({ value, onChange }) => {
  return (
    <input
      type="text"
      value={value || ""}
      onChange={(e) => onChange(e.target.value)}
      style={{ width: "100%" }}
    />
  );
};

// Plugin definition
const MyPlugin: FuncNodesReactPlugin = {
  // Render custom output previews
  renderNodeOutput: (props: RenderNodeOutputProps) => {
    const { type, value, fullscreen } = props;

    if (type === "MyCustomType") {
      return <MyTypePreview value={value} />;
    }

    // Return null to use default renderer
    return null;
  },

  // Render custom input editors
  renderNodeInput: (props: RenderNodeInputProps) => {
    const { type, value, onChange, render_options } = props;

    if (render_options?.type === "my_custom_input") {
      return <MyTypeInput value={value} onChange={onChange} />;
    }

    return null;
  },
};

// MUST export as default
export default MyPlugin;
```

### Register the Plugin in Python

Create `src/funcnodes_mymodule/_react_plugin.py`:

```python
from pathlib import Path

# Path to the built React plugin
REACT_PLUGIN = {
    "js": Path(__file__).parent / "react_plugin" / "funcnodes_mymodule_react.es.js",
}
```

Update `__init__.py`:

```python
from ._react_plugin import REACT_PLUGIN

__all__ = ["NODE_SHELF", "REACT_PLUGIN"]
```

Update `pyproject.toml` entry points:

```toml
[project.entry-points."funcnodes.module"]
module = "funcnodes_mymodule"
shelf = "funcnodes_mymodule:NODE_SHELF"
react_plugin = "funcnodes_mymodule:REACT_PLUGIN"
```

______________________________________________________________________

## Plugin API Reference

### FuncNodesReactPlugin Interface

```typescript
interface FuncNodesReactPlugin {
  // Render custom output previews
  renderNodeOutput?: (props: RenderNodeOutputProps) => React.ReactNode | null;

  // Render custom input editors
  renderNodeInput?: (props: RenderNodeInputProps) => React.ReactNode | null;

  // Render custom node header content
  renderNodeHeader?: (props: RenderNodeHeaderProps) => React.ReactNode | null;

  // Called when plugin is loaded
  onLoad?: () => void;

  // Called when plugin is unloaded
  onUnload?: () => void;
}
```

### RenderNodeOutputProps

```typescript
interface RenderNodeOutputProps {
  // The type string of the output
  type: string;

  // Current output value
  value: any;

  // Whether rendering in fullscreen/expanded mode
  fullscreen: boolean;

  // Node UUID
  nodeId: string;

  // Output ID
  outputId: string;

  // Render options from the node definition
  render_options?: Record<string, any>;
}
```

### RenderNodeInputProps

```typescript
interface RenderNodeInputProps {
  // The type string of the input
  type: string;

  // Current input value
  value: any;

  // Callback to update the value
  onChange: (value: any) => void;

  // Node UUID
  nodeId: string;

  // Input ID
  inputId: string;

  // Value constraints (min, max, options, etc.)
  value_options?: {
    min?: number;
    max?: number;
    step?: number;
    options?: string[] | { type: "enum"; keys: string[]; values: any[] };
  };

  // Render options from the node definition
  render_options?: Record<string, any>;

  // Whether input is disabled
  disabled?: boolean;
}
```

______________________________________________________________________

## Common Plugin Patterns

### Image Preview

```typescript
const ImagePreview: React.FC<{ value: any }> = ({ value }) => {
  if (!value) return null;

  // Assume value is base64 encoded image
  const src = `data:image/png;base64,${value}`;

  return (
    <img
      src={src}
      alt="Preview"
      style={{ maxWidth: "100%", maxHeight: 300 }}
    />
  );
};

const plugin: FuncNodesReactPlugin = {
  renderNodeOutput: (props) => {
    if (props.type === "ImageFormat" || props.type === "np.ndarray") {
      return <ImagePreview value={props.value} />;
    }
    return null;
  }
};
```

### Color Picker Input

```typescript
const ColorInput: React.FC<{
  value: string;
  onChange: (value: string) => void;
}> = ({ value, onChange }) => {
  return (
    <input
      type="color"
      value={value || "#000000"}
      onChange={(e) => onChange(e.target.value)}
      style={{ width: 40, height: 24, padding: 0, border: "none" }}
    />
  );
};

const plugin: FuncNodesReactPlugin = {
  renderNodeInput: (props) => {
    if (props.render_options?.type === "color") {
      return <ColorInput value={props.value} onChange={props.onChange} />;
    }
    return null;
  }
};
```

### Plotly Chart Preview

```typescript
import Plot from "react-plotly.js";

const PlotlyPreview: React.FC<{ value: any; fullscreen: boolean }> = ({
  value,
  fullscreen
}) => {
  if (!value) return null;

  const { data, layout } = value;

  return (
    <Plot
      data={data}
      layout={{
        ...layout,
        width: fullscreen ? 800 : 300,
        height: fullscreen ? 600 : 200,
        margin: { t: 20, r: 20, b: 30, l: 40 }
      }}
      config={{ displayModeBar: fullscreen }}
    />
  );
};
```

### Dropdown with Custom Styling

```typescript
const StyledDropdown: React.FC<{
  value: string;
  options: string[];
  onChange: (value: string) => void;
}> = ({ value, options, onChange }) => {
  return (
    <select
      value={value || ""}
      onChange={(e) => onChange(e.target.value)}
      style={{
        width: "100%",
        padding: "4px 8px",
        borderRadius: 4,
        border: "1px solid #ccc"
      }}
    >
      {options.map((opt) => (
        <option key={opt} value={opt}>
          {opt}
        </option>
      ))}
    </select>
  );
};
```

### File Upload Input

```typescript
const FileUploadInput: React.FC<{
  onChange: (file: File) => void;
}> = ({ onChange }) => {
  const handleChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      onChange(file);
    }
  };

  return (
    <input
      type="file"
      onChange={handleChange}
      style={{ width: "100%" }}
    />
  );
};
```

______________________________________________________________________

## Building and Deploying

### Development Build

```bash
cd react_plugin
npm install
npm run dev  # Watch mode
```

### Production Build

```bash
npm run build
```

The built file lands in `src/funcnodes_mymodule/react_plugin/`.

### Include in Package

Ensure the built JS file is included in your Python package:

```toml
# pyproject.toml
[tool.hatch.build.targets.wheel]
packages = ["src/funcnodes_mymodule"]

# Include the react_plugin directory
[tool.hatch.build.targets.wheel.force-include]
"src/funcnodes_mymodule/react_plugin" = "funcnodes_mymodule/react_plugin"
```

Or with setuptools:

```python
# setup.py or pyproject.toml
package_data = {
    "funcnodes_mymodule": ["react_plugin/*.js", "react_plugin/*.css"]
}
```

______________________________________________________________________

## Styling

### CSS Modules

```typescript
// styles.module.css
.preview {
  padding: 8px;
  border-radius: 4px;
  background: var(--fn-bg-secondary);
}

// index.tsx
import styles from "./styles.module.css";

const Preview = () => <div className={styles.preview}>...</div>;
```

### CSS-in-JS

```typescript
const Preview = () => (
  <div
    style={{
      padding: 8,
      borderRadius: 4,
      background: "var(--fn-bg-secondary)"
    }}
  >
    ...
  </div>
);
```

### FuncNodes CSS Variables

The host provides CSS variables for consistent theming:

| Variable              | Description          |
| --------------------- | -------------------- |
| `--fn-bg-primary`     | Primary background   |
| `--fn-bg-secondary`   | Secondary background |
| `--fn-text-primary`   | Primary text color   |
| `--fn-text-secondary` | Secondary text color |
| `--fn-accent`         | Accent color         |
| `--fn-border`         | Border color         |
| `--fn-radius`         | Border radius        |

______________________________________________________________________

## Debugging

### Development Tips

1. **Use React DevTools** ‚Äî Install the browser extension
1. **Console logging** ‚Äî `console.log()` in your plugin
1. **Hot reload** ‚Äî Use `npm run dev` for watch mode
1. **Check Network tab** ‚Äî Verify plugin JS is loaded

### Common Issues

**Plugin not loading:**

- Check entry point path in `pyproject.toml`
- Verify built JS file exists
- Check browser console for errors

**Component not rendering:**

- Verify type string matches exactly
- Check `renderNodeOutput` returns JSX, not null
- Ensure default export is the plugin object

**Styling issues:**

- Use CSS variables for theme consistency
- Avoid global styles that might conflict

______________________________________________________________________

## Examples from Official Modules

### funcnodes_plotly

Renders Plotly figures with zoom/pan controls:

```typescript
// Simplified example
const PlotlyPlugin: FuncNodesReactPlugin = {
  renderNodeOutput: (props) => {
    if (props.type === "plotly.graph_objs.Figure") {
      return <PlotlyRenderer figure={props.value} fullscreen={props.fullscreen} />;
    }
    return null;
  }
};
```

### funcnodes_files

File browser and upload widgets:

```typescript
const FilesPlugin: FuncNodesReactPlugin = {
  renderNodeInput: (props) => {
    if (props.render_options?.type === "file_browser") {
      return <FileBrowser onSelect={props.onChange} />;
    }
    return null;
  }
};
```

### funcnodes_rdkit

Molecule structure editor using JSME:

```typescript
const RDKitPlugin: FuncNodesReactPlugin = {
  renderNodeInput: (props) => {
    if (props.type === "Mol" && props.render_options?.editor) {
      return <MoleculeEditor smiles={props.value} onChange={props.onChange} />;
    }
    return null;
  },
  renderNodeOutput: (props) => {
    if (props.type === "Mol") {
      return <MoleculePreview smiles={props.value} />;
    }
    return null;
  }
};
```

______________________________________________________________________

## See Also

- [Writing Modules](https://linkdlab.github.io/FuncNodes/extending/writing-modules/index.md) ‚Äî Complete module guide
- [Testing Modules](https://linkdlab.github.io/FuncNodes/extending/testing-modules/index.md) ‚Äî Testing your module
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî Render options reference
- [funcnodes_plotly](https://github.com/Linkdlab/funcnodes_plotly) ‚Äî Example with React plugin

# Testing FuncNodes Modules

This guide covers testing strategies for FuncNodes modules using `pytest_funcnodes` ‚Äî the official testing plugin that provides decorators, fixtures, and utilities for comprehensive node testing.

______________________________________________________________________

## Setup

### Install pytest_funcnodes

```bash
pip install pytest-funcnodes
```

### Project Structure

```text
funcnodes_mymodule/
‚îú‚îÄ‚îÄ src/funcnodes_mymodule/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ nodes.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îú‚îÄ‚îÄ test_nodes.py
‚îÇ   ‚îî‚îÄ‚îÄ test_all_nodes_pytest.py
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ pytest.ini
```

### Configure pytest

Create `pytest.ini`:

```ini
[pytest]
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function
testpaths = tests
python_files = test_*.py
python_functions = test_*
```

Or in `pyproject.toml`:

```toml
[tool.pytest.ini_options]
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
testpaths = ["tests"]
```

______________________________________________________________________

## Two Testing Decorators

The plugin provides two main decorators:

| Decorator                                             | Purpose                                           | Sync/Async |
| ----------------------------------------------------- | ------------------------------------------------- | ---------- |
| `@nodetest(NodeClass)` or `@nodetest([Node1, Node2])` | Test specific node classes with coverage tracking | Async only |
| `@funcnodes_test`                                     | General FuncNodes testing with isolated context   | Both       |

______________________________________________________________________

## The `@nodetest` Decorator

Use `@nodetest` to mark async tests that test specific node classes. **The decorator takes a node class or list of node classes** to track test coverage.

### Signature

```python
@nodetest(node: Union[None, Type[Node], List[Type[Node]]] = None)
```

### Basic Usage

```python
from pytest_funcnodes import nodetest
import funcnodes_core as fn

@fn.NodeDecorator("my_module.add")
def add_numbers(a: int, b: int) -> int:
    return a + b

# Pass a single node CLASS to @nodetest for coverage tracking
@nodetest(add_numbers)
async def test_add_numbers():
    node = add_numbers()  # Create instance

    node.inputs["a"].value = 5
    node.inputs["b"].value = 3

    await node

    assert node.outputs["out"].value == 8
```

### What `@nodetest` Does

1. **Registers node for coverage** ‚Äî The `NodeClass` argument is added to `session.tested_nodes`
1. **Applies markers** ‚Äî Adds `@pytest.mark.nodetest` and `@pytest.mark.asyncio`
1. **Isolates environment** ‚Äî Wraps test in `test_context()` for clean state
1. **Sets temp config dir** ‚Äî Uses isolated `FUNCNODES_CONFIG_DIR` in temp folder

### Testing Multiple Node Classes

Pass a **list** of node classes to track coverage for multiple nodes in one test:

```python
from pytest_funcnodes import nodetest

# Test multiple related nodes - pass list of classes
@nodetest([add_numbers, multiply_numbers])
async def test_math_operations():
    add_node = add_numbers()
    mult_node = multiply_numbers()

    add_node.inputs["a"].value = 2
    add_node.inputs["b"].value = 3
    await add_node
    assert add_node.outputs["out"].value == 5

    mult_node.inputs["a"].value = 4
    mult_node.inputs["b"].value = 2
    await mult_node
    assert mult_node.outputs["out"].value == 8
```

Both `add_numbers` and `multiply_numbers` will be marked as tested for coverage tracking.

### Without Coverage Tracking

If you don't need coverage tracking, use empty `@nodetest()`:

```python
@nodetest()
async def test_node_behavior():
    # Test won't be counted toward coverage
    node = some_node()
    await node
```

______________________________________________________________________

## The `@funcnodes_test` Decorator

Use `@funcnodes_test` for general FuncNodes testing. It works with both sync and async functions and accepts configuration options.

### Basic Usage

```python
from pytest_funcnodes import funcnodes_test

# Async test
@funcnodes_test
async def test_async_operation():
    node = my_node()
    await node
    assert node.outputs["out"].value is not None

# Sync test (also works!)
@funcnodes_test
def test_sync_operation():
    node = my_node()
    assert "input1" in node.inputs
```

### With Configuration Options

Pass keyword arguments to customize the test context:

```python
@funcnodes_test(
    clear=True,           # Clear temp directory before test
    no_prefix=False,      # Use unique prefix for isolation
    disable_file_handler=True,  # Disable file logging
    fail_on_warnings=[FuncNodesDeprecationWarning],  # Fail on these warnings
)
async def test_with_options():
    node = my_node()
    await node
```

### Available Options

| Option                 | Type   | Default                         | Description                                  |
| ---------------------- | ------ | ------------------------------- | -------------------------------------------- |
| `clear`                | `bool` | `True`                          | Clear config directory before test           |
| `no_prefix`            | `bool` | `False`                         | If `True`, use fixed temp dir (not isolated) |
| `disable_file_handler` | `bool` | `True`                          | Disable file logging handler                 |
| `config`               | `dict` | `None`                          | Custom FuncNodes config to apply             |
| `fail_on_warnings`     | `list` | `[FuncNodesDeprecationWarning]` | Warning types that fail tests                |

______________________________________________________________________

## Coverage Testing with `all_nodes_tested`

### How Coverage Tracking Works

1. Decorate tests with `@nodetest(NodeClass)` to register tested nodes
1. The `all_nodes` fixture collects all registered node classes
1. Call `all_nodes_tested(all_nodes, shelf)` to verify complete coverage

### Complete Example

```python
# tests/test_all_nodes_pytest.py
from pytest_funcnodes import all_nodes_tested
import funcnodes_mymodule as fnmodule

def test_all_nodes_tested(all_nodes):
    """Ensure every node in the shelf has at least one test."""
    all_nodes_tested(all_nodes, fnmodule.NODE_SHELF)
```

### The `all_nodes` Fixture

The `all_nodes` fixture is a **set of node classes** (not instances) that have been passed to `@nodetest()`:

```python
# This fixture is automatically provided by pytest_funcnodes
@pytest.fixture(scope="session", autouse=True)
def all_nodes(request):
    return request.session.tested_nodes  # Set of node classes
```

### `all_nodes_tested` Function Signature

```python
def all_nodes_tested(
    tested_nodes: List[Type[fn.Node]],  # From all_nodes fixture
    shelf: fn.Shelf,                     # Shelf to check coverage
    ignore: Optional[List[Union[Type[fn.Node], fn.Shelf]]] = None,  # Skip these
):
```

### Ignoring Nodes or Shelves

You can ignore specific nodes or entire shelves:

```python
def test_all_nodes_tested(all_nodes):
    all_nodes_tested(
        all_nodes,
        fnmodule.NODE_SHELF,
        ignore=[
            fnmodule.deprecated_node,      # Ignore single node class
            fnmodule.EXPERIMENTAL_SHELF,   # Ignore entire shelf
        ]
    )
```

______________________________________________________________________

## Test Context and Isolation

### What `test_context()` Does

Every `@nodetest` and `@funcnodes_test` test runs inside a `test_context()` that:

1. **Creates temp config directory** ‚Äî `{tempdir}/funcnodes_test_{pid}_{uuid}/`
1. **Isolates state** ‚Äî Fresh config, logging, and node registry
1. **Cleans up after** ‚Äî Removes temp directory and clears registered nodes

### Manual Test Context

For custom test scenarios:

```python
from pytest_funcnodes import test_context

def test_manual_context():
    with test_context(clear=True, config={"logging": {"level": "DEBUG"}}):
        # Test code runs in isolated environment
        node = my_node()
        # ...
    # Context is cleaned up automatically
```

### Checking Test Mode

```python
from pytest_funcnodes import get_in_test

def test_check_mode():
    assert get_in_test() is True  # Inside test context
```

______________________________________________________________________

## Testing Patterns

### Testing Node Structure

```python
@funcnodes_test
def test_node_structure():
    node = my_node()

    # Check inputs exist
    assert "input1" in node.inputs
    assert "input2" in node.inputs

    # Check outputs exist
    assert "result" in node.outputs

    # Check default values
    assert node.inputs["threshold"].value == 0.5
```

### Testing Node Execution

```python
@nodetest(process_data)
async def test_process_data():
    node = process_data()

    node.inputs["data"].value = [1, 2, 3, 4, 5]
    node.inputs["operation"].value = "sum"

    await node

    assert node.outputs["result"].value == 15
```

### Testing Multiple Cases

```python
@nodetest(add_numbers)
async def test_add_numbers_cases():
    node = add_numbers()

    test_cases = [
        (1, 2, 3),
        (0, 0, 0),
        (-5, 5, 0),
        (1.5, 2.5, 4.0),
    ]

    for a, b, expected in test_cases:
        node.inputs["a"].value = a
        node.inputs["b"].value = b
        await node
        assert node.outputs["out"].value == expected, f"Failed for {a} + {b}"
```

### Testing Error Handling

```python
import pytest

@nodetest(divide)
async def test_division_by_zero():
    node = divide()
    node.inputs["a"].value = 10
    node.inputs["b"].value = 0

    with pytest.raises(ZeroDivisionError):
        await node
```

### Testing Dynamic IO Updates

```python
@nodetest(column_selector)
async def test_dynamic_options():
    import pandas as pd

    node = column_selector()
    df = pd.DataFrame({"a": [1, 2], "b": [3, 4], "c": [5, 6]})

    node.inputs["dataframe"].value = df

    # Check that column options are updated
    options = node.inputs["column"].value_options.get("options", [])
    assert "a" in options
    assert "b" in options
    assert "c" in options
```

### Testing Node Chains

```python
import funcnodes_core as fn

@funcnodes_test
async def test_node_chain():
    # Create connected nodes
    add = add_numbers()
    mult = multiply_numbers()

    # Connect output to input
    add.outputs["out"].connect(mult.inputs["a"])

    # Set values
    add.inputs["a"].value = 2
    add.inputs["b"].value = 3
    mult.inputs["b"].value = 4

    # Wait for execution cascade
    await fn.run_until_complete(add, mult)

    # Result: (2+3) * 4 = 20
    assert mult.outputs["out"].value == 20
```

______________________________________________________________________

## Running Tests

### Basic Commands

```bash
# Run all tests
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/test_nodes.py

# Run specific test
pytest tests/test_nodes.py::test_add_numbers
```

### Node Tests Only

```bash
# Run only tests marked with @nodetest
pytest --nodetests-only
```

### With Coverage

```bash
# Install coverage
pip install pytest-cov

# Run with coverage report
pytest --cov=funcnodes_mymodule --cov-report=html
```

______________________________________________________________________

## Complete Test File Example

```python
# tests/test_nodes.py
import pytest
from pytest_funcnodes import nodetest, funcnodes_test

# Import your module
from funcnodes_mymodule import add_numbers, multiply_numbers, divide

# Test specific node with coverage tracking
@nodetest(add_numbers)
async def test_add_numbers():
    node = add_numbers()
    node.inputs["a"].value = 5
    node.inputs["b"].value = 3
    await node
    assert node.outputs["out"].value == 8

@nodetest(multiply_numbers)
async def test_multiply_numbers():
    node = multiply_numbers()
    node.inputs["a"].value = 4
    node.inputs["b"].value = 7
    await node
    assert node.outputs["out"].value == 28

@nodetest(divide)
async def test_divide():
    node = divide()
    node.inputs["a"].value = 10
    node.inputs["b"].value = 2
    await node
    assert node.outputs["out"].value == 5

@nodetest(divide)
async def test_divide_by_zero():
    node = divide()
    node.inputs["a"].value = 10
    node.inputs["b"].value = 0
    with pytest.raises(ZeroDivisionError):
        await node
```

```python
# tests/test_all_nodes_pytest.py
from pytest_funcnodes import all_nodes_tested
import funcnodes_mymodule as fnmodule

def test_all_nodes_tested(all_nodes):
    """Verify all nodes in the shelf have tests."""
    all_nodes_tested(all_nodes, fnmodule.NODE_SHELF, ignore=[])
```

______________________________________________________________________

## Best Practices

### Do

‚úÖ Use `@nodetest(NodeClass)` to track coverage ‚úÖ Create a `test_all_nodes_pytest.py` for coverage verification ‚úÖ Test both happy path and error cases ‚úÖ Use `@funcnodes_test` for sync tests and general utilities ‚úÖ Test dynamic IO updates and value_options changes

### Don't

‚ùå Use `@nodetest()` without the node class (no coverage tracking) ‚ùå Forget to pass node classes to `@nodetest` decorator ‚ùå Skip the `all_nodes_tested` check in CI ‚ùå Test implementation details instead of behavior ‚ùå Use real network calls in unit tests

______________________________________________________________________

## Troubleshooting

### "Already in test mode" Error

```python
# Wrong: nested test contexts
@funcnodes_test
async def test_outer():
    with test_context():  # Error!
        pass

# Right: let decorator handle context
@funcnodes_test
async def test_correct():
    # No manual test_context needed
    pass
```

### Coverage Shows Missing Nodes

Make sure you pass the node **class** (not instance) to `@nodetest`:

```python
# Wrong: passing instance
@nodetest(add_numbers())  # Creates instance - won't track!
async def test_wrong():
    pass

# Right: passing single class
@nodetest(add_numbers)  # Pass the class itself
async def test_correct():
    node = add_numbers()  # Create instance inside
    pass

# Right: passing list of classes
@nodetest([add_numbers, multiply_numbers])  # Pass list of classes
async def test_multiple():
    pass
```

### Tests Not Isolated

Ensure you're using the decorators, not running tests without them:

```python
# Wrong: no isolation
async def test_no_isolation():  # Missing decorator!
    pass

# Right: proper isolation
@funcnodes_test
async def test_isolated():
    pass
```

______________________________________________________________________

## See Also

- [Writing Modules](https://linkdlab.github.io/FuncNodes/extending/writing-modules/index.md) ‚Äî Complete module guide
- [React Plugins](https://linkdlab.github.io/FuncNodes/extending/react-plugins/index.md) ‚Äî UI plugin testing
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî Node fundamentals

# Creating Custom Modules

This guide walks you through creating a FuncNodes module from scratch ‚Äî a Python package that provides nodes for the FuncNodes ecosystem.

______________________________________________________________________

## Overview

A FuncNodes module is a standard Python package with:

1. **Node definitions** ‚Äî Functions or classes decorated as nodes
1. **Shelf organization** ‚Äî Grouping nodes into a browsable hierarchy
1. **Entry points** ‚Äî Registration so FuncNodes discovers your module
1. **Optional: React plugin** ‚Äî Custom UI components for your nodes

```text
my_funcnodes_module/
‚îú‚îÄ‚îÄ pyproject.toml          # Package metadata + entry points
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ funcnodes_mymodule/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py     # Exports NODE_SHELF
‚îÇ       ‚îú‚îÄ‚îÄ nodes.py        # Node definitions
‚îÇ       ‚îî‚îÄ‚îÄ _react_plugin.py  # Optional: React plugin info
‚îî‚îÄ‚îÄ react_plugin/           # Optional: React UI components
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ vite.config.ts
    ‚îî‚îÄ‚îÄ src/
        ‚îî‚îÄ‚îÄ index.tsx
```

______________________________________________________________________

## Quick Start with funcnodes_module

The fastest way to create a module is using the `funcnodes_module` scaffolding tool:

```bash
# Install the tool
pip install funcnodes-module

# Create a new module
funcnodes_module create funcnodes_mymodule

# Or with options
funcnodes_module create funcnodes_mymodule \
    --description "My awesome nodes" \
    --author "Your Name" \
    --with-react-plugin
```

This generates a complete project structure with:

- Pre-configured `pyproject.toml`
- Example node definitions
- Test setup with `funcnodes_pytest`
- Optional React plugin scaffold

______________________________________________________________________

## Manual Setup

### Step 1: Project Structure

Create your package structure:

```bash
mkdir funcnodes_mymodule
cd funcnodes_mymodule
mkdir -p src/funcnodes_mymodule
touch src/funcnodes_mymodule/__init__.py
touch src/funcnodes_mymodule/nodes.py
touch pyproject.toml
```

### Step 2: pyproject.toml

Configure your package with the required entry points:

```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "funcnodes-mymodule"
version = "0.1.0"
description = "My custom FuncNodes module"
readme = "README.md"
license = "MIT"
authors = [
    { name = "Your Name", email = "you@example.com" }
]
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
]
dependencies = [
    "funcnodes-core>=0.2.0",
]

[project.optional-dependencies]
dev = [
    "pytest",
    "funcnodes-pytest",
]

# CRITICAL: Entry points for FuncNodes discovery
[project.entry-points."funcnodes.module"]
module = "funcnodes_mymodule"
shelf = "funcnodes_mymodule:NODE_SHELF"

[tool.hatch.build.targets.wheel]
packages = ["src/funcnodes_mymodule"]
```

### Step 3: Define Nodes

Create your nodes in `src/funcnodes_mymodule/nodes.py`:

```python
import funcnodes_core as fn
from typing import List

@fn.NodeDecorator(
    node_id="funcnodes_mymodule.greet",
    name="Greet",
    description="Creates a greeting message"
)
def greet(name: str = "World") -> str:
    """Generate a greeting for the given name."""
    return f"Hello, {name}!"


@fn.NodeDecorator(
    node_id="funcnodes_mymodule.sum_list",
    name="Sum List",
    description="Sums all numbers in a list"
)
def sum_list(numbers: List[float]) -> float:
    """Calculate the sum of a list of numbers."""
    return sum(numbers)


@fn.NodeDecorator(
    node_id="funcnodes_mymodule.multiply",
    name="Multiply",
    description="Multiplies two numbers"
)
def multiply(
    a: float = 1.0,
    b: float = 1.0
) -> float:
    """Multiply two numbers together."""
    return a * b
```

### Step 4: Create the Shelf

Export your nodes in `src/funcnodes_mymodule/__init__.py`:

```python
from funcnodes_core import Shelf

from .nodes import greet, sum_list, multiply

# Define the shelf structure
NODE_SHELF = Shelf(
    name="My Module",
    description="Custom nodes for demonstration",
    nodes=[greet, sum_list, multiply],
    subshelves=[]
)

# Export for convenience
__all__ = ["NODE_SHELF", "greet", "sum_list", "multiply"]
```

### Step 5: Install and Test

```bash
# Install in development mode
pip install -e .

# Verify discovery
funcnodes modules list
# Should show: funcnodes_mymodule

# Test in the UI
funcnodes runserver
```

______________________________________________________________________

## Entry Points Reference

The `[project.entry-points."funcnodes.module"]` section tells FuncNodes how to load your module:

| Entry Point       | Required    | Description                      |
| ----------------- | ----------- | -------------------------------- |
| `module`          | Yes         | Import path to your module root  |
| `shelf`           | Recommended | Path to your `NODE_SHELF` object |
| `react_plugin`    | Optional    | Path to React plugin info dict   |
| `render_options`  | Optional    | Custom render options for types  |
| `external_worker` | Optional    | Custom worker class              |

### Example with All Entry Points

```toml
[project.entry-points."funcnodes.module"]
module = "funcnodes_mymodule"
shelf = "funcnodes_mymodule:NODE_SHELF"
react_plugin = "funcnodes_mymodule:REACT_PLUGIN"
render_options = "funcnodes_mymodule:RENDER_OPTIONS"
```

______________________________________________________________________

## Shelf Organization

### Flat Structure

For simple modules with few nodes:

```python
NODE_SHELF = Shelf(
    name="My Module",
    nodes=[node1, node2, node3]
)
```

### Nested Structure

For larger modules, use subshelves:

```python
from funcnodes_core import Shelf

from .math_nodes import add, subtract, multiply, divide
from .string_nodes import concat, split, upper, lower
from .io_nodes import read_file, write_file

NODE_SHELF = Shelf(
    name="My Module",
    description="Comprehensive utility nodes",
    subshelves=[
        Shelf(
            name="Math",
            description="Mathematical operations",
            nodes=[add, subtract, multiply, divide]
        ),
        Shelf(
            name="Strings",
            description="String manipulation",
            nodes=[concat, split, upper, lower]
        ),
        Shelf(
            name="I/O",
            description="File operations",
            nodes=[read_file, write_file]
        ),
    ]
)
```

### Best Practices

1. **Consistent naming**: Use lowercase with underscores for node_id
1. **Prefix with module name**: `funcnodes_mymodule.category.node_name`
1. **Group by function**: Math, I/O, Transforms, etc.
1. **Limit depth**: 2-3 levels of subshelves maximum
1. **Add descriptions**: Help users understand each shelf's purpose

______________________________________________________________________

## Advanced Node Patterns

### Nodes with Multiple Outputs

```python
from typing import Tuple

@fn.NodeDecorator(
    node_id="funcnodes_mymodule.divmod",
    name="Divmod",
    outputs=[
        {"name": "quotient"},
        {"name": "remainder"}
    ]
)
def divmod_node(a: int, b: int) -> Tuple[int, int]:
    """Return quotient and remainder of division."""
    return divmod(a, b)
```

### Nodes with Dynamic Options

```python
from funcnodes_core.io_hooks import update_other_io_options

@fn.NodeDecorator(node_id="funcnodes_mymodule.select_column")
@update_other_io_options("column", modifier=lambda df: df.columns.tolist())
def select_column(df: "pd.DataFrame", column: str) -> "pd.Series":
    """Select a column from a DataFrame."""
    return df[column]
```

### Nodes with Value Constraints

```python
@fn.NodeDecorator(
    node_id="funcnodes_mymodule.clamp",
    name="Clamp Value"
)
def clamp(
    value: float,
    min_val: float = 0.0,
    max_val: float = 1.0
) -> float:
    """Clamp a value to a range."""
    return max(min_val, min(max_val, value))

# Add constraints via class-based approach for more control
class ClampNode(fn.Node):
    node_id = "funcnodes_mymodule.clamp_v2"
    node_name = "Clamp (Advanced)"

    value = fn.NodeInput(id="value", type=float, default=0.5)
    min_val = fn.NodeInput(
        id="min_val",
        type=float,
        default=0.0,
        value_options={"max": 1.0}
    )
    max_val = fn.NodeInput(
        id="max_val",
        type=float,
        default=1.0,
        value_options={"min": 0.0}
    )
    result = fn.NodeOutput(id="result", type=float)

    async def func(self, value, min_val, max_val):
        self.outputs["result"].value = max(min_val, min(max_val, value))
```

### Async Nodes

```python
import aiohttp

@fn.NodeDecorator(node_id="funcnodes_mymodule.fetch_url")
async def fetch_url(url: str) -> str:
    """Fetch content from a URL."""
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.text()
```

### Heavy Computation Nodes

```python
@fn.NodeDecorator(
    node_id="funcnodes_mymodule.heavy_compute",
    separate_thread=True  # Run in thread pool
)
def heavy_compute(data: list) -> list:
    """CPU-intensive operation."""
    import time
    time.sleep(2)  # Simulating heavy work
    return [x * 2 for x in data]


@fn.NodeDecorator(
    node_id="funcnodes_mymodule.very_heavy",
    separate_process=True  # Run in separate process
)
def very_heavy_compute(data: list) -> list:
    """Very CPU-intensive operation (process isolation)."""
    # This runs in a completely separate process
    return expensive_operation(data)
```

### Nodes with Progress

```python
@fn.NodeDecorator(node_id="funcnodes_mymodule.process_items")
async def process_items(items: list, node: fn.Node = None) -> list:
    """Process items with progress reporting."""
    results = []
    for item in node.progress(items):
        results.append(await process_single(item))
    return results
```

______________________________________________________________________

## Custom Types and Rendering

### DataEnum for Dropdowns

```python
from funcnodes_core import DataEnum

class ColorMode(DataEnum):
    RGB = ("rgb", "RGB Color")
    HSV = ("hsv", "HSV Color")
    GRAYSCALE = ("gray", "Grayscale")

@fn.NodeDecorator(node_id="funcnodes_mymodule.convert_color")
def convert_color(image: "np.ndarray", mode: ColorMode = ColorMode.RGB) -> "np.ndarray":
    """Convert image color mode."""
    return do_conversion(image, mode.v())
```

### Custom Render Options

Register custom render options for your types:

```python
# In __init__.py
RENDER_OPTIONS = {
    "typemap": {
        "MyCustomType": "custom_renderer"
    },
    "inputconverter": {
        "MyCustomType": "custom_input"
    }
}
```

### Preview Rendering

Configure how node outputs are previewed:

```python
class ImageProcessorNode(fn.Node):
    node_id = "funcnodes_mymodule.image_processor"

    # Tell UI to render the 'output_image' as the preview
    default_render_options = {
        "data": {"src": "output_image"}
    }

    input_image = fn.NodeInput(id="input_image", type="np.ndarray")
    output_image = fn.NodeOutput(id="output_image", type="np.ndarray")
```

______________________________________________________________________

## Publishing Your Module

### 1. Prepare for Release

```bash
# Update version in pyproject.toml
# Write changelog
# Ensure tests pass
pytest
```

### 2. Build the Package

```bash
pip install build
python -m build
```

### 3. Publish to PyPI

```bash
pip install twine
twine upload dist/*
```

### 4. Register with funcnodes_repositories (Optional)

To appear in the official module list:

1. Fork [funcnodes_repositories](https://github.com/Linkdlab/funcnodes_repositories)
1. Add your module to `available_repositories.yaml`:

```yaml
funcnodes-mymodule:
  package: funcnodes-mymodule
  description: My awesome nodes
  category: utilities
```

1. Submit a pull request

______________________________________________________________________

## Testing Your Module

### Setup pytest-funcnodes

```bash
pip install funcnodes-pytest
```

### Write Node Tests

```python
# tests/test_nodes.py
import pytest
from funcnodes_pytest import nodetest, all_nodes_tested

from funcnodes_mymodule import NODE_SHELF
from funcnodes_mymodule.nodes import greet, sum_list, multiply


@nodetest
async def test_greet():
    node = greet()
    node.inputs["name"].value = "Alice"
    await node
    assert node.outputs["out"].value == "Hello, Alice!"


@nodetest
async def test_sum_list():
    node = sum_list()
    node.inputs["numbers"].value = [1, 2, 3, 4, 5]
    await node
    assert node.outputs["out"].value == 15


@nodetest
async def test_multiply():
    node = multiply()
    node.inputs["a"].value = 3.0
    node.inputs["b"].value = 4.0
    await node
    assert node.outputs["out"].value == 12.0


def test_all_nodes_covered(all_nodes):
    """Ensure all nodes in the shelf have tests."""
    all_nodes_tested(all_nodes, NODE_SHELF)
```

### Run Tests

```bash
# Run all tests
pytest

# Run only node tests
pytest --nodetests-only

# With coverage
pytest --cov=funcnodes_mymodule
```

See [Testing Modules](https://linkdlab.github.io/FuncNodes/extending/testing-modules/index.md) for comprehensive testing guidance.

______________________________________________________________________

## React Plugin Development

For custom UI components (editors, previews, widgets), see [React Plugins](https://linkdlab.github.io/FuncNodes/extending/react-plugins/index.md).

Quick overview:

```typescript
// react_plugin/src/index.tsx
import { FuncNodesReactPlugin } from "@linkdlab/funcnodes_react_flow";

const MyPlugin: FuncNodesReactPlugin = {
  renderNodeOutput: (props) => {
    if (props.type === "MyCustomType") {
      return <MyCustomPreview data={props.value} />;
    }
    return null;
  }
};

export default MyPlugin;
```

______________________________________________________________________

## Common Patterns

### File-Based Nodes

```python
from pathlib import Path

@fn.NodeDecorator(node_id="funcnodes_mymodule.read_json")
def read_json(filepath: str) -> dict:
    """Read a JSON file."""
    import json
    with open(filepath) as f:
        return json.load(f)
```

### Configuration Nodes

```python
from dataclasses import dataclass

@dataclass
class Config:
    threshold: float = 0.5
    max_iterations: int = 100

@fn.NodeDecorator(node_id="funcnodes_mymodule.create_config")
def create_config(
    threshold: float = 0.5,
    max_iterations: int = 100
) -> Config:
    """Create a configuration object."""
    return Config(threshold=threshold, max_iterations=max_iterations)
```

### Wrapper Nodes for External Libraries

```python
@fn.NodeDecorator(
    node_id="funcnodes_mymodule.sklearn_fit",
    name="Fit Model"
)
def fit_model(
    model: "sklearn.base.BaseEstimator",
    X: "np.ndarray",
    y: "np.ndarray"
) -> "sklearn.base.BaseEstimator":
    """Fit a scikit-learn model."""
    return model.fit(X, y)
```

______________________________________________________________________

## Checklist

Before publishing, ensure:

- [ ] All nodes have unique `node_id` with module prefix
- [ ] All nodes have `name` and `description`
- [ ] All inputs have type hints
- [ ] All outputs have type hints
- [ ] Shelf is properly organized
- [ ] Entry points are configured in `pyproject.toml`
- [ ] Tests cover all nodes
- [ ] README documents installation and usage
- [ ] Version follows semantic versioning

______________________________________________________________________

## See Also

- [React Plugins](https://linkdlab.github.io/FuncNodes/extending/react-plugins/index.md) ‚Äî Custom UI components
- [Testing Modules](https://linkdlab.github.io/FuncNodes/extending/testing-modules/index.md) ‚Äî Comprehensive testing guide
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî Node fundamentals
- [Shelves](https://linkdlab.github.io/FuncNodes/components/shelf/index.md) ‚Äî Shelf organization
- [Available Modules](https://linkdlab.github.io/FuncNodes/modules/index.md) ‚Äî Official module examples
# Reference

# FuncNodes CLI Guide

The FuncNodes command-line interface (CLI) allows users to manage workflows, workers, and configurations efficiently. This guide provides an overview of available commands and usage examples.

______________________________________________________________________

## **Getting Started**

To check if FuncNodes is installed and accessible, run:

```bash
funcnodes --version
```

To view all available commands:

```bash
funcnodes --help
```

______________________________________________________________________

## **CLI Commands**

### Common Options

The basic command structure for the CLI is:

```bash
funcnodes [common_options] {task}
```

where {task} specifies an operation. The shared common options for all tasks are:

- `--version` ‚Üí Prints the current version of FuncNodes.
- `-h, --help` ‚Üí Displays CLI help.
- `--dir <path>` ‚Üí Specifies a custom base directory where workflow data is stored (default: `~/.funcnodes`). In this directory all configurations, logs, worker data, worker environments etc. is stored. So by defining a custom path it is possible to completly seperate instances of FuncNodes. For development purposes we recomment setting `--dir .funcnodes` (1) which will create a respective folder in your current worspace.
- `--debug` ‚Üí Enables debugging logs for all processes (and child processes).
- `--profile` ‚Üí Only available if FuncNodes was installed with the optional dependency `fundnodes[profiling]` Runs the task under profiling mode using [yappi](https://github.com/sumerc/yappi), generating a *funcnodesprofile.pstat* file in your current directory. This file than can be opened with different profiling views such as [snakeviz](https://jiffyclub.github.io/snakeviz/)

1. This is also what `--funcnodes-module demoworker` does.

### Tasks

The `funcnodes` command expects a specific task, which can be one of the following:

- runserver ‚Üí Runs the [browser interface](https://linkdlab.github.io/FuncNodes/ui-guide/react_flow/web-ui/index.md) with various [options](#runserver)
- standalone ‚Üí Opens a single `.fnw` file with a dedicated worker ([experimental](https://linkdlab.github.io/FuncNodes/experimental/standalone/index.md))
- worker ‚Üí Allows running and management of a [Worker](https://linkdlab.github.io/FuncNodes/components/worker/index.md)([options](#worker))
- startworkermanager ‚Üí Starts the [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md)([options](#workermanager))
- modules ‚Üí Gives access to the installed FuncNodes modules ([options](#modules))

#### runserver

To start the [FuncNodes web UI](https://linkdlab.github.io/FuncNodes/ui-guide/react_flow/web-ui/index.md), use:

```bash
funcnodes [common_options] runserver [server_options]
```

This will run a simple server that serves all the static static files necessary to use Funcnodes in the browser. By default the server runs on `localhost:8000` and a corresponding browser window is opened autoamtically. To interact with the [Workers](https://linkdlab.github.io/FuncNodes/components/worker/index.md) the server tries to find a running instance of a [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md) under `localhost:9380` and if it cannot find a running instance it will spawn a new one. Optional argument to the command are:

| Argument              | Description                                                                                                                                                                                                                                                                                                               |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| --host                | The host adress of the server, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["frontend"]["host"] (default:localhost)                                                                                                                                                          |
| --port                | The port of the server, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["frontend"]["port"] (default:8000)                                                                                                                                                                      |
| --no-browser          | If present, does not open a browser window                                                                                                                                                                                                                                                                                |
| --no-manager          | The server does not automatically spawns a [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md)                                                                                                                                                                                        |
| --worker_manager_host | The host adress of the [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md) the server tries to rach or under which a new one will be spawned, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["worker_manager"]["host"] (default:localhost) |
| --worker_manager_port | The port of the [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md) the server tries to rach or under which a new one will be spawned, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["worker_manager"]["port"] (default:9380)             |
| --frontend            | Which frontend to use in the UI (currently only [`react_flow`](https://linkdlab.github.io/FuncNodes/ui-guide/react_flow/web-ui/index.md) is supported)                                                                                                                                                                    |

#### worker

The task command `worker` allows to create, start, stop and interact with the [Worker](https://linkdlab.github.io/FuncNodes/components/worker/index.md) instances of FuncNodes. The command is build up as:

```bash
funcnodes [common_options] worker [worker_options] workertask
```

where the worker_options are mainy to define which worker to acess:

| Argument | Description                                                                                            |
| -------- | ------------------------------------------------------------------------------------------------------ |
| --uuid   | The unique id of the Worker, for a new worker it will be created automatically                         |
| --name   | The (non-unique) name of the Worker, for a new worker it defaults to the uuid but can be changed later |

To interact with an existing Worker either `--uuid` or `--name` have to be present. If only name is given the first worker with the given name will be picked (as it is not unqiue). For new Workers a if no `--uuid` is given, it will be created automatically and if `--name` is not set, it will be the `uuid` by default.

The command then requires a worker specific task:

- [new](#worker_new) ‚Üí Creates a new Worker
- [start](#worker_start) ‚Üí Runs the existing worker
- [stop](#worker_stop) ‚Üí Stops the existing, running worker
- [modules](#worker_modules) ‚Üí Runs the `funcnodes module` command in the Worker env
- [list](#worker_list) ‚Üí List all existing workers
- [listen](#worker_listen) ‚Üí Listens to the output of an existing worker
- [activate](#worker_activate) ‚Üí Activates the environment of an existing worker (if present)
- [py](#worker_py) ‚Üí Runs the Python instance of the respective worker

##### new worker

To create a new worker via the CLI the basic command is:

```bash
funcnodes [common_options] worker [worker_options] new [new_worker_options]
```

This command creates a new worker in your current `<funcnodes directory>/worker` defined via the [common_options](#commonoptions) (default `~/.funcnodes/worker`). If the uuid and name are not set in the [worker_options](#worker) they will be created automatically.

The worker can be created with a bunch of creation options via `[new_worker_options]`:

| Argument       | Description                                                                                                                                                                                                                                                      |
| -------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| --create-only  | By default a newly created worker will automatically start. By setting this flag it will only be created and not started                                                                                                                                         |
| --not-in-venv  | By default new workers will also create their own virtual environment in there respective path. By setting this flag the worker will be initiated with the current python interpreter (and always use this interpreter even if started from another environment) |
| (--workertype) | Defines the workertype (this feature is under development and should not be used currently)                                                                                                                                                                      |

--not-in-venv

The `--not-in-venv`-flag should be used carefully, since workers can automatically install packages in their environment, which is why it creates a new one by default.

But the --not-in-venv command commes especially handy during the development of new node packages which should be tested within a worker while it is only locally available.

This behaviour is also used by the `--funcnodes-module demoworker` command.

##### start worker

To start an existing worker via the cli simlpy run

```bash
funcnodes [common_options] worker --uuid|--name start
```

This will continously run the respective worker until stopped.

A Worker can only run one instance at a time

The workers are running their node based programm continously. Since they have a fixed state at a given time it is not possible to run a single worker on the same machine (to be more exact with the same base folder) multiple times in paralell. As such if you try to run a worker at it is already running it will automatically stop imediatly.

If you want to start a worker and it is not working because it says it is already running, you can either try stopping it with the [stop worker](#worker_stop) command, or go into the worker directory `<funcnodes directory>/worker` and check for the `worker_<uuid>.p` file. This file contains the pid for the Worker which can be used to kill it, or you can try to delet the file.\
Note: If the file is deleted, but the worker is still running, it will be recreated.

##### stop worker

To stop a running worker via the cli simlpy run

```bash
funcnodes [common_options] worker --uuid|--name stop
```

##### list all worker

To get a list of all workers the `list` worker task can be utilized:

```bash
funcnodes [common_options] worker list [--full]
```

e.g.

```bash
>> funcnodes worker list
15e84e74d25446cdafc9339e8a437e73        myworker
0a60b90c55e24a448b6714fce3d08aed        test
c52079f077f94929908bbc9013941a08        dummy
```

Without the `--full` option this command will print a list of all existing workers in the form of:

```bash
<uuid>\t<name>
```

if the `--full` option is set the output will print all configuration dictionaries of the existing Workers (see: [Worker config](https://linkdlab.github.io/FuncNodes/components/worker_config/index.md) )

```bash
>> funcnodes worker list --full
[{'data_path': '~/.funcnodes/workers/worker_myworker',
  'env_path': '~/.funcnodes/workers/worker_myworker/.venv',
  'host': 'localhost',
  'name': 'myworker',
  'package_dependencies': {},
  'pid': 39692,
  'port': 9382,
  'python_path': '~/.funcnodes/workers/worker_myworker/.venv/Scripts/python.exe',
  'ssl': False,
  'type': 'WSWorker',
  'update_on_startup': {'funcnodes': True},
  'uuid': 'myworker',
  'worker_dependencies': {}},
 {'data_path': '~/.funcnodes/workers/worker_0a60b90c55e24a448b6714fce3d08aed',
  'env_path': '~/.funcnodes/workers/worker_0a60b90c55e24a448b6714fce3d08aed/.venv',
  'host': 'localhost',
  'name': 'test',
  'package_dependencies': {'funcnodes-basic': {'package': 'funcnodes-basic',
                                               'version': '>=0.2.1'},
                           'funcnodes-files': {'package': 'funcnodes-files',
                                               'version': '0.2.7'},
                           'funcnodes-images': {'package': 'funcnodes-images',
                                                'version': '0.2.2'},
                           'funcnodes-numpy': {'package': 'funcnodes-numpy',
                                               'version': '0.2.9'},
                           'funcnodes-opencv': {'package': 'funcnodes-opencv',
                                                'version': '0.2.2'},
                           'funcnodes-storage': {'package': 'funcnodes-storage',
                                                 'version': '0.1.0'}},
  'pid': 31112,
  'port': 9383,
  'python_path': '~/.funcnodes/workers/worker_0a60b90c55e24a448b6714fce3d08aed/.venv/Scripts/python.exe',
  'ssl': False,
  'type': 'WSWorker',
  'update_on_startup': {'funcnodes': True},
  'uuid': '0a60b90c55e24a448b6714fce3d08aed',
  'worker_dependencies': {}},
 {'data_path': '~/.funcnodes/workers/worker_15e84e74d25446cdafc9339e8a437e73',
  'env_path': '~/.funcnodes/workers/worker_15e84e74d25446cdafc9339e8a437e73/.venv',
  'host': 'localhost',
  'name': 'dummy2',
  'package_dependencies': {'funcnodes-files': {'package': 'funcnodes-files',
                                               'version': '0.2.7'},
                           'funcnodes-opencv': {'package': 'funcnodes-opencv',
                                                'version': '0.2.2'}},
  'pid': 18300,
  'port': 9383,
  'python_path': '~/.funcnodes/workers/worker_15e84e74d25446cdafc9339e8a437e73/.venv/Scripts/python.exe',
  'ssl': False,
  'type': 'WSWorker',
  'update_on_startup': {'funcnodes': True},
  'uuid': '15e84e74d25446cdafc9339e8a437e73',
  'worker_dependencies': {}},
 {'data_path': '~/.funcnodes/workers/worker_c52079f077f94929908bbc9013941a08',
  'env_path': '~/.funcnodes/workers/worker_c52079f077f94929908bbc9013941a08/.venv',
  'host': 'localhost',
  'name': 'dummy',
  'package_dependencies': {'funcnodes-basic': {'package': 'funcnodes-basic',
                                               'version': None},
                           'funcnodes-files': {'package': 'funcnodes-files',
                                               'version': None},
                           'funcnodes-hplc': {'package': 'funcnodes-hplc',
                                              'version': None},
                           'funcnodes-opencv': {'package': 'funcnodes-opencv',
                                                'version': '0.2.2'},
                           'funcnodes-pandas': {'package': 'funcnodes-pandas',
                                                'version': None},
                           'funcnodes-plotly': {'package': 'funcnodes-plotly',
                                                'version': None}},
  'pid': 10568,
  'port': 9382,
  'python_path': '~/.funcnodes/workers/worker_c52079f077f94929908bbc9013941a08/.venv/Scripts/python.exe',
  'ssl': False,
  'type': 'WSWorker',
  'update_on_startup': {'funcnodes': True},
  'uuid': 'c52079f077f94929908bbc9013941a08',
  'worker_dependencies': {}}]
```

##### listen to a worker

The CLI provides the option to listen to a worker. It basically continously prints the log of the worker to the current output until the command is terminated. It always prints the current full log data of the worker, so it will also work with workers that are not running, in which case it will simply print the histroical logs, without any new output until the worker starts.

```bash
funcnodes [common_options] worker --uuid|--name listen
```

e.g.

```bash
>> funcnodes worker --name dummy listen
2025-01-30 13:30:03,491 - funcnodes.c52079f077f94929908bbc9013941a08 - INFO - Starting worker forever
2025-01-30 13:30:09,273 - funcnodes.c52079f077f94929908bbc9013941a08 - INFO - Setup loop manager to run
2025-01-30 13:30:09,273 - funcnodes.c52079f077f94929908bbc9013941a08 - INFO - Starting loop manager
2025-01-30 13:30:09,392 - funcnodes.c52079f077f94929908bbc9013941a08 - INFO - WebSocket server running on localhost:9382
```

##### worker modules

This command allows to run the [funcnodes module](#modules) command within the worker environment

e.g.

```bash
funcnodes [common_options] worker --uuid|--name modules list
```

##### activate worker

By default each worker has its own virtual environment to make the installed modules independed for each worker.

```bash
funcnodes [common_options] worker --uuid|--name activate
```

gives a convinient way of directly entering the virtual environment (mainly for debugging purposes or if a package has to be installed manually via the terminal)

e.g.

```bash
>> funcnodes worker --name dummy activate
(worker_c52079f077f94929908bbc9013941a08)>>‚ñà
```

##### run py in worker

```bash
>> funcnodes  worker --uuid|--name py [python_args]
```

This worker task is short for

```bash
>> funcnodes  worker --uuid|--name activate
(env)>> python [python_args]
```

and can be used to directly execute python scripts or task with the python interpreter of the worker

e.g.

```bash
>> funcnodes worker --name dummy py -- -c "print(\"hello\")" # (1)!
hello
>> funcnodes worker --name dummy py -- --version
```

1. If arguments have to be passed to the python directly command they must be seperated via -- from the main command and string quotations need to be properly escaped.

or: with a local srypt `myscript.py`

```py
# myscript.py
import sys
print(sys.argv)
```

```bash
>> funcnodes worker --name dummy py myscript.py  --innerarg
['myscript.py', '--innerarg']
```

#### workermanager

To start a [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md) via the cli you can run

```bash
funcnodes [common_options] startworkermanager [workermanager_options]
```

The optional arguments for this command are:

| Argument | Description                                                                                                                                                            |
| -------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| --host   | The host of the Workermanager, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["worker_manager"]["host"] (default:localhost) |
| --port   | The port of the Workermanager, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["worker_manager"]["port"] (default:9380)      |

#### modules

Funcnodes has a way of automatically detecting available Nodes in the current environment.

The nodes have to be packed in a common [NodeModule](https://linkdlab.github.io/FuncNodes/modules/index.md).

To list all Modules in the current environment run:

```bash
funcnodes [common_options] modules list
```

the output will be an indent list of the installed funcnodes modules: in the form of:

```bash
funcnodes_basic:
        InstalledModule(name=funcnodes_basic, description=Basic functionalities for
                funcnodes, entry_points=['module', 'shelf'], version=0.2.1, react_plugin=False,
                render_options=False)
```
# Help

## Common Issues & Fixes

### ‚ÄúUI can‚Äôt connect to Workermanager‚Äù

- Ensure the manager is running on the expected host/port (`localhost:9380` by default). Start it with `funcnodes startworkermanager`.
- If using a remote host or custom port, set `--worker_manager_host/--worker_manager_port` in `funcnodes runserver` or update `~/.funcnodes/config.json`.
- Check firewalls/proxy rules; the WS endpoint must be reachable.

### Worker says it is already running / won‚Äôt start

- Only one instance of a worker can run at a time. Stop it via `funcnodes worker --name <n> stop`.
- If it still claims to run, delete stale PID file `worker_<uuid>.p` in `~/.funcnodes/workers/` (after confirming no process is active) and start again.
- For venv issues, recreate with `funcnodes worker --name <n> start --not-in-venv` temporarily or rebuild the worker.

### Missing modules in ‚ÄúManage Libraries‚Äù

- The UI reads from the module registry. Verify internet access to `funcnodes_repositories` or provide a mirrored list.
- Install via CLI inside the worker env: `funcnodes worker --name <n> modules install funcnodes-plotly`.
- After install, restart the worker so shelves reload.

### Large uploads or preview errors

- WebSocket messages above the threshold are offloaded to HTTP. If previews fail, check proxy/body-size limits and the env vars `FUNCNODES_WS_WORKER_MAX_SIZE` / `FUNCNODES_WS_WORKER_MAX_DATA_SIZE`.
- For huge data, prefer staging files in the worker `files/` directory and pass paths instead of blobs.

### ‚ÄúPermission denied‚Äù writing config or logs

- By default FuncNodes writes to `~/.funcnodes`. Override with `funcnodes --dir .funcnodes` during development or set `FUNCNODES_CONFIG_DIR`.
- On containers, ensure the volume is writable by the FuncNodes user.

### Tests hang or fail with async errors

- Make sure node tests are marked with `@pytest_funcnodes.nodetest` so the plugin sets up an isolated test context.
- Avoid blocking calls in nodes; use `separate_thread=True` or `separate_process=True` for heavy work.

### Docker / port conflicts

- Default UI port is `8000`, Workermanager `9380`. Use `--port` flags or adjust `config.json` to avoid clashes.
- When reverse proxying (nginx/Traefik), keep WS upgrade headers intact for both UI‚Üîmanager and manager‚Üîworker sockets.

### How do I reset to a clean state?

- Stop all workers, then move or delete `~/.funcnodes` (or your custom `--dir`) to reset configs, workers, and logs. This deletes worker data‚Äîexport first if needed.
# API

# FuncNodes CLI Guide

The FuncNodes command-line interface (CLI) allows users to manage workflows, workers, and configurations efficiently. This guide provides an overview of available commands and usage examples.

______________________________________________________________________

## **Getting Started**

To check if FuncNodes is installed and accessible, run:

```bash
funcnodes --version
```

To view all available commands:

```bash
funcnodes --help
```

______________________________________________________________________

## **CLI Commands**

### Common Options

The basic command structure for the CLI is:

```bash
funcnodes [common_options] {task}
```

where {task} specifies an operation. The shared common options for all tasks are:

- `--version` ‚Üí Prints the current version of FuncNodes.
- `-h, --help` ‚Üí Displays CLI help.
- `--dir <path>` ‚Üí Specifies a custom base directory where workflow data is stored (default: `~/.funcnodes`). In this directory all configurations, logs, worker data, worker environments etc. is stored. So by defining a custom path it is possible to completly seperate instances of FuncNodes. For development purposes we recomment setting `--dir .funcnodes` (1) which will create a respective folder in your current worspace.
- `--debug` ‚Üí Enables debugging logs for all processes (and child processes).
- `--profile` ‚Üí Only available if FuncNodes was installed with the optional dependency `fundnodes[profiling]` Runs the task under profiling mode using [yappi](https://github.com/sumerc/yappi), generating a *funcnodesprofile.pstat* file in your current directory. This file than can be opened with different profiling views such as [snakeviz](https://jiffyclub.github.io/snakeviz/)

1. This is also what `--funcnodes-module demoworker` does.

### Tasks

The `funcnodes` command expects a specific task, which can be one of the following:

- runserver ‚Üí Runs the [browser interface](https://linkdlab.github.io/FuncNodes/ui-guide/react_flow/web-ui/index.md) with various [options](#runserver)
- standalone ‚Üí Opens a single `.fnw` file with a dedicated worker ([experimental](https://linkdlab.github.io/FuncNodes/experimental/standalone/index.md))
- worker ‚Üí Allows running and management of a [Worker](https://linkdlab.github.io/FuncNodes/components/worker/index.md)([options](#worker))
- startworkermanager ‚Üí Starts the [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md)([options](#workermanager))
- modules ‚Üí Gives access to the installed FuncNodes modules ([options](#modules))

#### runserver

To start the [FuncNodes web UI](https://linkdlab.github.io/FuncNodes/ui-guide/react_flow/web-ui/index.md), use:

```bash
funcnodes [common_options] runserver [server_options]
```

This will run a simple server that serves all the static static files necessary to use Funcnodes in the browser. By default the server runs on `localhost:8000` and a corresponding browser window is opened autoamtically. To interact with the [Workers](https://linkdlab.github.io/FuncNodes/components/worker/index.md) the server tries to find a running instance of a [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md) under `localhost:9380` and if it cannot find a running instance it will spawn a new one. Optional argument to the command are:

| Argument              | Description                                                                                                                                                                                                                                                                                                               |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| --host                | The host adress of the server, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["frontend"]["host"] (default:localhost)                                                                                                                                                          |
| --port                | The port of the server, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["frontend"]["port"] (default:8000)                                                                                                                                                                      |
| --no-browser          | If present, does not open a browser window                                                                                                                                                                                                                                                                                |
| --no-manager          | The server does not automatically spawns a [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md)                                                                                                                                                                                        |
| --worker_manager_host | The host adress of the [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md) the server tries to rach or under which a new one will be spawned, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["worker_manager"]["host"] (default:localhost) |
| --worker_manager_port | The port of the [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md) the server tries to rach or under which a new one will be spawned, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["worker_manager"]["port"] (default:9380)             |
| --frontend            | Which frontend to use in the UI (currently only [`react_flow`](https://linkdlab.github.io/FuncNodes/ui-guide/react_flow/web-ui/index.md) is supported)                                                                                                                                                                    |

#### worker

The task command `worker` allows to create, start, stop and interact with the [Worker](https://linkdlab.github.io/FuncNodes/components/worker/index.md) instances of FuncNodes. The command is build up as:

```bash
funcnodes [common_options] worker [worker_options] workertask
```

where the worker_options are mainy to define which worker to acess:

| Argument | Description                                                                                            |
| -------- | ------------------------------------------------------------------------------------------------------ |
| --uuid   | The unique id of the Worker, for a new worker it will be created automatically                         |
| --name   | The (non-unique) name of the Worker, for a new worker it defaults to the uuid but can be changed later |

To interact with an existing Worker either `--uuid` or `--name` have to be present. If only name is given the first worker with the given name will be picked (as it is not unqiue). For new Workers a if no `--uuid` is given, it will be created automatically and if `--name` is not set, it will be the `uuid` by default.

The command then requires a worker specific task:

- [new](#worker_new) ‚Üí Creates a new Worker
- [start](#worker_start) ‚Üí Runs the existing worker
- [stop](#worker_stop) ‚Üí Stops the existing, running worker
- [modules](#worker_modules) ‚Üí Runs the `funcnodes module` command in the Worker env
- [list](#worker_list) ‚Üí List all existing workers
- [listen](#worker_listen) ‚Üí Listens to the output of an existing worker
- [activate](#worker_activate) ‚Üí Activates the environment of an existing worker (if present)
- [py](#worker_py) ‚Üí Runs the Python instance of the respective worker

##### new worker

To create a new worker via the CLI the basic command is:

```bash
funcnodes [common_options] worker [worker_options] new [new_worker_options]
```

This command creates a new worker in your current `<funcnodes directory>/worker` defined via the [common_options](#commonoptions) (default `~/.funcnodes/worker`). If the uuid and name are not set in the [worker_options](#worker) they will be created automatically.

The worker can be created with a bunch of creation options via `[new_worker_options]`:

| Argument       | Description                                                                                                                                                                                                                                                      |
| -------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| --create-only  | By default a newly created worker will automatically start. By setting this flag it will only be created and not started                                                                                                                                         |
| --not-in-venv  | By default new workers will also create their own virtual environment in there respective path. By setting this flag the worker will be initiated with the current python interpreter (and always use this interpreter even if started from another environment) |
| (--workertype) | Defines the workertype (this feature is under development and should not be used currently)                                                                                                                                                                      |

--not-in-venv

The `--not-in-venv`-flag should be used carefully, since workers can automatically install packages in their environment, which is why it creates a new one by default.

But the --not-in-venv command commes especially handy during the development of new node packages which should be tested within a worker while it is only locally available.

This behaviour is also used by the `--funcnodes-module demoworker` command.

##### start worker

To start an existing worker via the cli simlpy run

```bash
funcnodes [common_options] worker --uuid|--name start
```

This will continously run the respective worker until stopped.

A Worker can only run one instance at a time

The workers are running their node based programm continously. Since they have a fixed state at a given time it is not possible to run a single worker on the same machine (to be more exact with the same base folder) multiple times in paralell. As such if you try to run a worker at it is already running it will automatically stop imediatly.

If you want to start a worker and it is not working because it says it is already running, you can either try stopping it with the [stop worker](#worker_stop) command, or go into the worker directory `<funcnodes directory>/worker` and check for the `worker_<uuid>.p` file. This file contains the pid for the Worker which can be used to kill it, or you can try to delet the file.\
Note: If the file is deleted, but the worker is still running, it will be recreated.

##### stop worker

To stop a running worker via the cli simlpy run

```bash
funcnodes [common_options] worker --uuid|--name stop
```

##### list all worker

To get a list of all workers the `list` worker task can be utilized:

```bash
funcnodes [common_options] worker list [--full]
```

e.g.

```bash
>> funcnodes worker list
15e84e74d25446cdafc9339e8a437e73        myworker
0a60b90c55e24a448b6714fce3d08aed        test
c52079f077f94929908bbc9013941a08        dummy
```

Without the `--full` option this command will print a list of all existing workers in the form of:

```bash
<uuid>\t<name>
```

if the `--full` option is set the output will print all configuration dictionaries of the existing Workers (see: [Worker config](https://linkdlab.github.io/FuncNodes/components/worker_config/index.md) )

```bash
>> funcnodes worker list --full
[{'data_path': '~/.funcnodes/workers/worker_myworker',
  'env_path': '~/.funcnodes/workers/worker_myworker/.venv',
  'host': 'localhost',
  'name': 'myworker',
  'package_dependencies': {},
  'pid': 39692,
  'port': 9382,
  'python_path': '~/.funcnodes/workers/worker_myworker/.venv/Scripts/python.exe',
  'ssl': False,
  'type': 'WSWorker',
  'update_on_startup': {'funcnodes': True},
  'uuid': 'myworker',
  'worker_dependencies': {}},
 {'data_path': '~/.funcnodes/workers/worker_0a60b90c55e24a448b6714fce3d08aed',
  'env_path': '~/.funcnodes/workers/worker_0a60b90c55e24a448b6714fce3d08aed/.venv',
  'host': 'localhost',
  'name': 'test',
  'package_dependencies': {'funcnodes-basic': {'package': 'funcnodes-basic',
                                               'version': '>=0.2.1'},
                           'funcnodes-files': {'package': 'funcnodes-files',
                                               'version': '0.2.7'},
                           'funcnodes-images': {'package': 'funcnodes-images',
                                                'version': '0.2.2'},
                           'funcnodes-numpy': {'package': 'funcnodes-numpy',
                                               'version': '0.2.9'},
                           'funcnodes-opencv': {'package': 'funcnodes-opencv',
                                                'version': '0.2.2'},
                           'funcnodes-storage': {'package': 'funcnodes-storage',
                                                 'version': '0.1.0'}},
  'pid': 31112,
  'port': 9383,
  'python_path': '~/.funcnodes/workers/worker_0a60b90c55e24a448b6714fce3d08aed/.venv/Scripts/python.exe',
  'ssl': False,
  'type': 'WSWorker',
  'update_on_startup': {'funcnodes': True},
  'uuid': '0a60b90c55e24a448b6714fce3d08aed',
  'worker_dependencies': {}},
 {'data_path': '~/.funcnodes/workers/worker_15e84e74d25446cdafc9339e8a437e73',
  'env_path': '~/.funcnodes/workers/worker_15e84e74d25446cdafc9339e8a437e73/.venv',
  'host': 'localhost',
  'name': 'dummy2',
  'package_dependencies': {'funcnodes-files': {'package': 'funcnodes-files',
                                               'version': '0.2.7'},
                           'funcnodes-opencv': {'package': 'funcnodes-opencv',
                                                'version': '0.2.2'}},
  'pid': 18300,
  'port': 9383,
  'python_path': '~/.funcnodes/workers/worker_15e84e74d25446cdafc9339e8a437e73/.venv/Scripts/python.exe',
  'ssl': False,
  'type': 'WSWorker',
  'update_on_startup': {'funcnodes': True},
  'uuid': '15e84e74d25446cdafc9339e8a437e73',
  'worker_dependencies': {}},
 {'data_path': '~/.funcnodes/workers/worker_c52079f077f94929908bbc9013941a08',
  'env_path': '~/.funcnodes/workers/worker_c52079f077f94929908bbc9013941a08/.venv',
  'host': 'localhost',
  'name': 'dummy',
  'package_dependencies': {'funcnodes-basic': {'package': 'funcnodes-basic',
                                               'version': None},
                           'funcnodes-files': {'package': 'funcnodes-files',
                                               'version': None},
                           'funcnodes-hplc': {'package': 'funcnodes-hplc',
                                              'version': None},
                           'funcnodes-opencv': {'package': 'funcnodes-opencv',
                                                'version': '0.2.2'},
                           'funcnodes-pandas': {'package': 'funcnodes-pandas',
                                                'version': None},
                           'funcnodes-plotly': {'package': 'funcnodes-plotly',
                                                'version': None}},
  'pid': 10568,
  'port': 9382,
  'python_path': '~/.funcnodes/workers/worker_c52079f077f94929908bbc9013941a08/.venv/Scripts/python.exe',
  'ssl': False,
  'type': 'WSWorker',
  'update_on_startup': {'funcnodes': True},
  'uuid': 'c52079f077f94929908bbc9013941a08',
  'worker_dependencies': {}}]
```

##### listen to a worker

The CLI provides the option to listen to a worker. It basically continously prints the log of the worker to the current output until the command is terminated. It always prints the current full log data of the worker, so it will also work with workers that are not running, in which case it will simply print the histroical logs, without any new output until the worker starts.

```bash
funcnodes [common_options] worker --uuid|--name listen
```

e.g.

```bash
>> funcnodes worker --name dummy listen
2025-01-30 13:30:03,491 - funcnodes.c52079f077f94929908bbc9013941a08 - INFO - Starting worker forever
2025-01-30 13:30:09,273 - funcnodes.c52079f077f94929908bbc9013941a08 - INFO - Setup loop manager to run
2025-01-30 13:30:09,273 - funcnodes.c52079f077f94929908bbc9013941a08 - INFO - Starting loop manager
2025-01-30 13:30:09,392 - funcnodes.c52079f077f94929908bbc9013941a08 - INFO - WebSocket server running on localhost:9382
```

##### worker modules

This command allows to run the [funcnodes module](#modules) command within the worker environment

e.g.

```bash
funcnodes [common_options] worker --uuid|--name modules list
```

##### activate worker

By default each worker has its own virtual environment to make the installed modules independed for each worker.

```bash
funcnodes [common_options] worker --uuid|--name activate
```

gives a convinient way of directly entering the virtual environment (mainly for debugging purposes or if a package has to be installed manually via the terminal)

e.g.

```bash
>> funcnodes worker --name dummy activate
(worker_c52079f077f94929908bbc9013941a08)>>‚ñà
```

##### run py in worker

```bash
>> funcnodes  worker --uuid|--name py [python_args]
```

This worker task is short for

```bash
>> funcnodes  worker --uuid|--name activate
(env)>> python [python_args]
```

and can be used to directly execute python scripts or task with the python interpreter of the worker

e.g.

```bash
>> funcnodes worker --name dummy py -- -c "print(\"hello\")" # (1)!
hello
>> funcnodes worker --name dummy py -- --version
```

1. If arguments have to be passed to the python directly command they must be seperated via -- from the main command and string quotations need to be properly escaped.

or: with a local srypt `myscript.py`

```py
# myscript.py
import sys
print(sys.argv)
```

```bash
>> funcnodes worker --name dummy py myscript.py  --innerarg
['myscript.py', '--innerarg']
```

#### workermanager

To start a [Workermanager](https://linkdlab.github.io/FuncNodes/components/workermanager/index.md) via the cli you can run

```bash
funcnodes [common_options] startworkermanager [workermanager_options]
```

The optional arguments for this command are:

| Argument | Description                                                                                                                                                            |
| -------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| --host   | The host of the Workermanager, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["worker_manager"]["host"] (default:localhost) |
| --port   | The port of the Workermanager, defaults to the [config](https://linkdlab.github.io/FuncNodes/components/config/index.md)["worker_manager"]["port"] (default:9380)      |

#### modules

Funcnodes has a way of automatically detecting available Nodes in the current environment.

The nodes have to be packed in a common [NodeModule](https://linkdlab.github.io/FuncNodes/modules/index.md).

To list all Modules in the current environment run:

```bash
funcnodes [common_options] modules list
```

the output will be an indent list of the installed funcnodes modules: in the form of:

```bash
funcnodes_basic:
        InstalledModule(name=funcnodes_basic, description=Basic functionalities for
                funcnodes, entry_points=['module', 'shelf'], version=0.2.1, react_plugin=False,
                render_options=False)
```
# UI Guide

# Using the Web-Based UI

FuncNodes provides a web-based UI for managing and visualizing workflows in an interactive and intuitive manner. This guide walks you through setting up and using the UI effectively.

______________________________________________________________________

## **Starting the Web UI**

To start the web UI, ensure you have FuncNodes installed and then run:

```bash
funcnodes runserver
```

This will start the FuncNodes server, and you can access the UI by navigating to:

```bash
http://localhost:8000
```

______________________________________________________________________

## **UI Features**

### **1Ô∏è‚É£ Workflow Editor**

- Drag-and-drop interface for creating workflows.
- Connect nodes visually to define execution flow.
- Edit node properties directly in the UI.

### **2Ô∏è‚É£ Node Configuration**

- Click on a node to modify its parameters.
- Supports custom inputs and outputs.
- Dynamic validation and live updates.

### **3Ô∏è‚É£ Execution Monitoring**

- Start, stop, and debug workflows.
- Real-time status updates for node execution.
- View logs and error messages directly in the UI.

### **4Ô∏è‚É£ Saving & Loading Workflows**

- Save workflows as JSON configurations.
- Load previously saved workflows.
- Export workflows for sharing or deployment.

______________________________________________________________________

## **Advanced Configuration**

### **Customizing the UI Port**

By default, the UI runs on port `8000`. To change this:

```bash
funcnodes runserver --port 8080
```

### **Securing the Web UI**

To enable authentication or SSL, modify the FuncNodes configuration file at:

```bash
~/.funcnodes/config.json
```

Add:

```json
{
  "frontend": {
    "host": "0.0.0.0",
    "port": 8000,
    "ssl": true
  }
}
```

______________________________________________________________________

## **What You Might Need to Add**

- **User Authentication**: If access control is required, add login functionality.
- **API Integration**: Document how to interact with the UI programmatically.
- **Custom Themes**: Explain how to modify the UI styling.
- **Performance Optimization**: Guide on handling large workflows efficiently.
- **Deployment Guide**: Steps to host the UI on a remote server.

For more details, visit the [FuncNodes GitHub repository](https://github.com/Linkdlab/funcnodes).

```text

```
# Components

# Configuration

FuncNodes stores its configuration in `config.json` under the base directory (default `~/.funcnodes`). Override the base with `funcnodes --dir <path>` or by setting `FUNCNODES_CONFIG_DIR`.

## Structure (key sections)

- **env_dir** ‚Äî base path for configs/logs/workers (usually the base dir itself).
- **worker_manager** ‚Äî `host`, `port`, `ssl` for the Workermanager service.
- **frontend** ‚Äî `host`, `port`, `ssl` for the UI server (`funcnodes runserver`).
- **nodes** ‚Äî runtime defaults such as `pretrigger_delay` or test-mode flags.
- **logging** ‚Äî handlers, log level, and format limits (see Logging section).
- **render_options** ‚Äî global `typemap` and `inputconverter` hints for special types.

Defaults come from `DEFAULT_CONFIG` in `funcnodes_core.config`. On load, FuncNodes:

1. Ensures the config directory exists.
1. Reads `config.json` (or the `.bu` backup).
1. Fills missing keys from defaults, then writes back.

## Editing config

- Use any editor to adjust `~/.funcnodes/config.json`; restart UI/manager/workers to apply.
- CLI overrides: `funcnodes runserver --host ... --port ...` take precedence for that run.
- Environment: a `.env` file is loaded if present; env vars can override individual settings.

## Test mode

`funcnodes_core.config.set_in_test()` switches to a temporary config dir, disables file logging, promotes warnings to errors (optional), and is automatically used by `pytest_funcnodes` nodetests.

## Render options registry

`render_options` can be extended at runtime (e.g., by modules) via `fn.update_render_options`, normalizing type strings so the UI knows how to preview custom classes.

# Inputs & Outputs

In FuncNodes, inputs and outputs (IOs) serve as the fundamental connection points between nodes. They are responsible for handling the flow of data and triggering execution throughout a workflow. Both inputs and outputs extend from a common foundation‚Äîthe NodeIO Base Class‚Äîwhich provides shared functionality for connection management, value handling, serialization, and event emission.

The main principle is that each IO can hold an arbitrary data object, referenceable via the `value` property. If the value is not set it is automatically set to the NoValue singleton object which is used to represent the absence of a value. This is important because None is a valid value for an IO.

If the value of an IO is changed this may trigger a range of events, including *e.g.* triggering the Node or passing its value to connected IOs.

## NodeIO Base Class

The inputs and outputs of a Node are both derived from the `NodeIO` base class. This class accepts the following parameters (for nromal use cases NodeIO is never intialized directly, but always via the child classes):

- **uuid**: Each IO has a unique ID that is generated when the IO is created. (1)
- **name**: Each IO has a name that is used as the referencing key and also for display purposes (defaults to the uuid).
- **description**: A description of the IO, mainly used for display purposes.
- **type**: The data type of the IO. This is treated as a hint for the UI and the backend, but is not enforced.
- **allow_multiple**: A boolean flag that indicates whether the IO have multiple connections to other IOs. By default this is False for inputs and True for outputs.
- **hidden**: A boolean flag that indicates whether the IO is hidden in the UI. This is useful for internal IOs or for very IO-rich nodes, to make them more usable.
- **render_options**: See [Render Options](#render-options).
- **value_options**: See [Value Options](#value-options).

1. Note: if the IO is derived of a function parameter, the id becomes the signature name of the parameter, so it is not individually unique. But IOs are always attasched to a node, with a unique id, so the combination of node id and IO id is always unique.

## Render Options

The IO-Render options are used to control and customize the appearance of the IO in the UI. In its base form these options are available:

- **type**: If the IO Type is different than what is should be rendered at (e.g. a number that should be rendered as a string or a custom frontend component, this can be set here).
- **set_default**: If the value of the IO is set manually, this flag indicates whether the new value should be set as the default value for the IO (meaning it will also be serialized, and has to be [serializable](https://linkdlab.github.io/FuncNodes/components/serialization/index.md)).

The render options are a dictionary, meaning it can be arbitrary extended with custom options. Which will be passed to the frontend and can there be used to customize the rendering of the IO.

## Value Options

The IO-Value options are used to control and customize the behavior of the IO-value. Currently these values are not directly enforced, but are used as hints for the UI and the backend and if required should be enforced in the respective node functions:

- **min**: The minimum value of the IO, currently used for number types.
- **max**: The maximum value of the IO, currently used for number types (1).
- **step**: The step size of the IO, currently used for number types.
- **options**: A list of options that the IO can take, rendered as a dropdown (2).

1. Note: If min and max are set the default frontend renders the IO as a slider.
1. For more control this can also be defined as a enum type in the form of a dictionary with keys and values (see example below).

```python
import funcnodes as fn

class IOModNode(fn.Node):
    node_id = "iomodnode"
    a = fn.NodeInput(
        value_options={"min": 0, "max": 1, "step": 0.1}, default=0.5, type=float
    )

    b = fn.NodeInput(
        render_options={"type": "color"}, type=str, default="#ff0000"
    )

    c = fn.NodeInput(
        value_options={"options": ["a", "b", "c"]}, default="a", type=str
    )
    d = fn.NodeInput(
        value_options={
            "options": {
                "type": "enum",
                "keys": ["full", "empty"],
                "values": [1, 0],
            }
        }
    )

    async def func(self, a: float, b: str, c: str, d: float):
        self.inputs["a"].set_value(float(d), does_trigger=False)
```

## Events & triggering

- Inputs fire `after_set_value` events when `emit_value_set=True`; outputs fire on `trigger`.
- Inputs can opt out of triggering the node with `does_trigger=False` (useful for control signals or staged values).
- Hidden maintenance ports (e.g., the auto-created `_triggerinput`/`_triggeroutput`) use `hidden=True` to stay out of the UI.

## Dynamic IO updates

Use decorator helpers to recompute options based on other inputs:

- `update_other_io_options("target", modifier=...)` ‚Äî recalc dropdown contents.
- `update_other_io_value_options("target", options_generator=...)` ‚Äî recalc numeric bounds (`min/max/step`).

Patterns in the shipped modules:

- Pandas column selectors rebuild `options` from `df.columns`.
- Basic list nodes adjust valid indices to the current list length.
- File/folder pickers repopulate from the worker `files_dir`.

## Enumerations & `DataEnum`

For stable choice lists, subclass `fn.DataEnum`; it registers a type string and exposes `.v()` to resolve stored values. Example:

```python
class BorderTypes(fn.DataEnum):
    CONSTANT = (0, "Constant")
    REFLECT = (2, "Reflect")
```

Attach the enum as the IO `type` or use `value_options={"options": BorderTypes}`; the UI renders friendly labels while storing the underlying values.

## `NoValue` and optional outputs

`NoValue` represents ‚Äúno data‚Äù and **suppresses downstream triggers**. Return it from optional outputs or routers to avoid firing branches unintentionally. Inputs default to `NoValue` until set; disconnecting an input resets it to its class default if provided.

## Render routing & previews

Node-level `default_render_options` can point the UI at a specific IO, e.g. `{"data": {"src": "figure"}}` for Plotly or images. Per-IO `render_options` can request widgets (`{"type": "color"}`, sliders via min/max) or mark values as preview-only.

### Custom renderers and type hints

- The global render-option registry lives in `funcnodes_core.config.FUNCNODES_RENDER_OPTIONS`. Modules can extend it at import time via an entry point (`render_options`) or by calling `funcnodes_core.config.update_render_options`.
- Serialization uses `funcnodes_core.utils.serialization.JSONEncoder/Decoder`; modules may register additional encoders so custom types can be stored in `nodespace.json` and previewed in the UI.
- Enums for dropdowns should subclass `fn.DataEnum` so both values and display labels are preserved.

## Connection rules & multiplicity

- Inputs default to **single connection**; set `allow_multiple=True` for fan-in semantics.
- Outputs allow multiple downstream connections.
- Connection validation prevents input‚Üíinput and output‚Üíoutput wiring and enforces `allow_multiple`; violations raise `NodeConnectionError` / `MultipleConnectionsError`.
- There is no automatic cycle detection across the graph; avoid feedback loops unless your node logic guards against it.

## Serialization hints

- All IO values must be JSON-serializable by the registered encoders to persist in `nodespace.json`.
- Set `render_options["set_default"]=True` when user-set values should become the new default and be serialized with the graph.

# Library (Shelf Registry)

The Library is the runtime registry that exposes shelves and node classes to a `NodeSpace`. It lives in `funcnodes_core.lib.Library` and is attached to every worker.

## Storage model

- Internally a flat dict keyed by tuple paths (`("Top", "Child", ...)`) pointing to `_ShelfRecord` entries that store **only node IDs**, not class objects.
- Weak references can be mounted (`add_external_shelf`, `add_subshelf_weak`) so externally owned shelves disappear automatically when GC‚Äôd.
- Materialized shelves are rebuilt on demand with `Shelf` objects; missing node classes are skipped if they are no longer registered.

## API highlights

- `add_shelf(shelf)` ‚Äî merge/insert a full shelf tree (deduplicates node IDs).
- `add_node(s)/add_nodes` ‚Äî append one or many node classes to a shelf path, creating intermediate shelves as needed.
- `remove_shelf`, `remove_shelf_path` ‚Äî drop shelves (and descendants) by object or path.
- `find_nodeid` / `find_nodeclass` ‚Äî return all shelf paths that reference a node.
- `get_node_by_id` ‚Äî resolves a node class only if it is both registered and referenced somewhere; otherwise raises `NodeClassNotFoundError`.
- `full_serialize()` ‚Äî JSON snapshot of all shelves, used by `NodeSpace.full_serialize()`.

## Population from installed modules

Module discovery runs via `funcnodes_core.libparser.module_to_shelf` and `_setup.py`:

1. Installed distributions are inspected for `funcnodes.module` entry points. If a `shelf` object is exported, it is validated (`check_shelf`) and mounted.
1. If no `shelf` entry point is provided, all non‚Äëabstract `Node` subclasses in the module are grouped into a shelf named after the module.
1. Render options or external workers exported via entry points are applied separately and do not affect the library tree.

## Why flat storage?

Keeping only node IDs in `_records` avoids strong references to node classes and keeps the GC happy, while still allowing quick materialization of nested shelves when the UI or serialization needs them.

Nodes are the most fundamental building blocks of FuncNodes. Each node encapsulates a function with defined inputs and outputs. Nodes execute when all required inputs are available, producing output data for downstream nodes. Nodes can be created with two different methods: [class based](#class-based-nodes) and [decorator based](#decorator-based-nodes). While class based nodes are more flexible and can be used to create complex nodes, decorator based nodes are simpler and faster to create.

## Class Based Nodes

Class based nodes are created by subclassing the `Node` class from the `funcnodes` package. This method is more flexible and allows for more complex nodes to be created. The `Node` class provides a number of methods and properties that can be overridden to customize the behavior of the node.

The basic layout of a class based node is as follows:

```python
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node"
    node_id = "my_node"

    async def func(self):
        """The function to be executed when the node is triggered."""
```

The `node_name` and `node_id` required properties define the name and ID of the node, respectively. It is important that the 'node_id' is unique across all nodes in the system since it is used for serialization and deserialization of the node. So it is recommended to make it as descriptive as possible, e.g. if the node CalculateOrbit is part of a public package named 'funcnodes_astronomy' and the node the node_id could be 'funcnodes_astronomy.calculate_orbit'. And while this is not enforced it is recommended to use a similar naming scheme for the ids, to prevent id clashes. The node name is the human readable name of the node and is used in the UI.

The async `func` method is the entry point for the node's execution. This method is called when the node is triggered and should contain the logic for the node's function.In the class based nodes the `func` method is the only method that is required to be implemented. The `func` method has to be an async method since the execution of the node is done asynchronously.

The node above has no inputs or outputs, which makes it relatively useless. inputs and outputs can be added on the class level as well:

```python
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node"
    node_id = "my_node"

    input1 = fn.NodeInput(id="input1", type=int)
    input2 = fn.NodeInput(id="input2", type=int)

    output1 = fn.NodeOutput(id="output1", type=int)


    async def func(self, input1, input2):

        result =  input1 + input2
        self.outputs["output1"].value = result
```

In the example above, the node has two inputs, `input1` and `input2`, and one output, `output`. The `func` method now takes two arguments, `input1` and `input2`, which are the values of the inputs. The `func` method then adds the two inputs together and sets the result as the value of the output. While the class attributes of the inputs and outputs can be arbitrary named, it is recommended to use the same name as the id of the input or output (IO), to make the code more readable. setting the type of the IO is optional, but it is recommended since this will be used to render the corresponding IO in the UI (defaults to Any).

Warning

The typing of the IO is not enforced, to stay as pythonic as possible. If the value is not of the expected type, the node will still trigger and raise an exception if it occurs.

This is important to keep the system flexible: e.g. numpy arrays can be passed to inputs that expect a list and it should still work.

If enforcing is required, it should be done in the `func` method.

During triggering all inputs are passed to the `func` method as keyword arguments, so the order of the inputs does not matter, but the ids should be valid python variable names. In the class based approach outputs have to be set **explicitly**, by setting the value of the output in the `func` method. For more details on the `IO` see the [Inputs and Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md).

## Decorator Based Nodes

A even simpler way to create nodes is by using the `@fn.NodeDecorator` decorator. This decorator can be used to create nodes from a simple function. The function should take the inputs as arguments and return the outputs as a dictionary. The decorator will automatically create the node and set the inputs and outputs based on the function signature.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(input1: int, input2: int) -> float:
    return input1 / input2
```

This will create a node with the id `my_node`, which has two inputs, `input1` and `input2` (of type `int`), and one output, `output1` (of type `float`).

The `@fn.NodeDecorator` decorator has the required argument `node_id`, which is the id of the node, similar to the `node_id` property in the class based nodes. The inputs are automatically created based on the function signature, as such the function should have only defined positional and keyword arguments and no expanding arguments like `*args` or `**kwargs`. Similar to the class based nodes, the type of the inputs is optional, but recommended.

The Decorator can also be used to create a Node from an arbitrary external function, by passing the function as an argument to the decorator. The corresponding inputs and outputs will be created based on the signature of the function and the type hints.

```python
import funcnodes as fn

def myfunction(a: int=1, b: int=2) -> int:
    return a + b

MyFuncNode = fn.NodeDecorator(
    node_id="my_node",
)(myfunction)
```

The outputs are defined by the return type of the function, the output type is also interpreted from the return type, if present. The default id if the output is `out` and the default type is `Any`.

How the Node input and Output can be further customized with decorators is described in the [Inputs and Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) section.

### Defining multiple outputs

Will the class based approach allows for multiple outputs simply by defining multiple outputs, the decorator requires a little modification.

To have multiple outputs, the function should return multiple values, which would make the return type a tuple.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(input1: int, input2: int) -> tuple:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

But this will result in a single output `out` of the type tuple. To actually have multiple outputs the return type has to be a typed tuple, to be able to interfere the number of outputs:

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
)
def my_node(input1: int, input2: int) -> Tuple[int, int]:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

By default the outputs are numbered, to give them a more descriptive name, the outputs can be customized with the `outputs` argument of the decorator:

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
    outputs=[
        {"name": "output1"},
        {"name": "output2"},
    ]
)
def my_node(input1: int, input2: int) -> Tuple[int, int]:
    result1 =  input1 + input2
    result2 =  input1 - input2
    return result1, result2
```

The `outputs` argument of the decorator is a list of dictionaries, where each dictionary represents an output. The dictionary should have the key `name` which is the id of the output. To specify the type, the `type` argument can be used. Alternatively, the type can be specified in the return type of the function as in the example above.

### Further info in IO in decorator

In a similar manner the inputs can be customized with the `inputs` argument.

```python
from typing import Tuple
import funcnodes as fn

@fn.NodeDecorator(
    node_id="my_node",
    inputs=[
        {"name": "a"},
        {"name": "b"},
    ],
)
def myfunction(var_name_i_dont_like_a: int=1, var_name_i_dont_like_b: int=2) -> int:
    return var_name_i_dont_like_a + var_name_i_dont_like_b
```

Defining the inputs and outputs in the decorator is especially useful when the function is an external function and the signature cannot be changed.

In the following example, the function `divmod` is an external function and the signature cannot be changed.

```python
from typing import Tuple
import funcnodes as fn

MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
)(divmod)
```

As you can see the function has the expected inputs, but it is not typed. As such the inputs are of type `Any`, which allows no manual input and the return type is not defined, meaning the function has no output.

To fix this, the inputs and outputs can be defined in the decorator.

```python
from typing import Tuple
import funcnodes as fn


MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
    inputs=[
        {"name": "a"},
        {"name": "b"},
    ],
    outputs=[
        {"name": "quotient", "type": int},
        {"name": "remainder", "type": int},
    ]
)(divmod)
```

While under normal circumstances this works as expected, it is recommended to use the `fn.NodeDecorator` as a decorator, and create a wrapper function that calls the external function, to make the node more readable and to allow for more customization.

```python
from typing import Tuple
import funcnodes as fn


@fn.NodeDecorator(
    node_id="divmod",
    outputs=[
        {"name": "quotient"},
        {"name": "remainder"},
    ]
)
def divmod_node(a: int=11, b: int=5) -> Tuple[int, int]:
    return divmod(a, b)
```

Furthermore by wrapping it in a function, it can be make sure, that the function accepts all arguments as keyword arguments. Since internally Funcnodes calls the function with all-keyword arguments, which is some functions don't accept:

```python
from typing import Tuple
import funcnodes as fn

MyFuncNode = fn.NodeDecorator(
    node_id="divmod",
    inputs=[
        {"name": "a", "default":11}, # setting default to show the effect
        {"name": "b", "default":5},
    ],
    outputs=[
        {"name": "quotient", "type": int},
        {"name": "remainder", "type": int},
    ]
)(divmod) # this will not work since divmod does not accept keyword arguments
```

### Defining the node name

The node name is especially important for the UI, as it is the human readable name of the node. If not present, the node name will be the name of the function or the class. To set the node name, the `node_name` class attribute or the `name` argument of the decorator can be used.

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node1", name="My Node Decorator")
def my_node(input1: int, input2: int) -> float:
    return input1 / input2

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node2"

    async def func(self):
        pass
```

### Defining the node description

In a similar manner the node description can be set with the `description` argument of the decorator or the `description` class attribute of the class based nodes.

Description is a human readable description of the node, which can be used to provide more information about the node to the user.

Additionaly if no description is provided, the docstring of the function or the class will be used as the description (if present).

```python
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node1", description="This is a node created with the decorator")
def my_node(ip:int) -> float:
    return ip/2

@fn.NodeDecorator(node_id="my_node2")
def my_node(ip:int) -> float:
    """This is a node created with the decorator and a docstring"""
    return ip/2

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node3"
    description = """
This is a node created with the class

Multi line is supported
    """

    ip = fn.NodeInput(id="ip", type=int)

    async def func(self, ip):
        self.outputs["output1"].value = ip / 2
```

(Hover over the node header in the UI to see the description)

Future Plans

We plan to render the description as via Markdown/Sphinx in the UI, so it is recommended to use Markdown in the description.

### Node progress bar

Especially for long running nodes, it is recommended to provide a progress bar to the user. For this purpose the node has a custom property `progress` which wraps the `tqdm` progress bar and automatically streams the progress to the UI.

```python
import asyncio
import funcnodes as fn

class MyNode(fn.Node):
    node_name = "My Node Class"
    node_id = "my_node3"
    description = "This is a node created with the class"

    ip = fn.NodeInput(id="ip", type=int,default=30)

    async def func(self, ip):
        for i in self.progress(range(ip)):
            await asyncio.sleep(10)
```

(All nodes on this page here run in parallel processes in [pyodide](https://pyodide.org/en/stable/), each with all the individual management overhead, which is why the progress bar is not 100% iterating with the sleep time. A normal use-case would be only little processes with multiple nodes per process)

To access the progress bar in a decorator based node, we need to access the underlying node object. For this purpose an input argument `node` can be added, which will not be considered as normal input, but as a reference to the node object.

```python
import asyncio
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
async def my_node(ip:int=30, node: fn.Node=None) -> float:
    for i in node.progress(range(ip)):
        await asyncio.sleep(10)

    return ip/2
```

### Heavy Tasks

Since Funcnodes uses the asyncio library, a blocking function will block the event loop and prevent other nodes from executing. To prevent this, heavy tasks should be executed in a separate thread or process. This can be done e.g. by using the `asyncio.to_thread` function, which will run the function in a separate thread and return the result.

```python
import asyncio
import time
import funcnodes as fn

@fn.NodeDecorator(node_id="my_node")
async def my_node(input1: int, input2: int) -> int:
    def heavy_task(input1, input2):
        time.sleep(1)
        return input1 + input2

    return await asyncio.to_thread(heavy_task, input1, input2)
```

Pyodide Runtime

Funcnodes is also able to run in [pyodide](https://pyodide.org/en/stable/) ("Pyodide makes it possible to install and run Python packages in the browser"). We use this also in all the Nodes you see here running live. But pyodide does not yet support multithreading or multiprocessing.

This works for both class based and decorator based nodes. Alternatively, the NodeDecorator accepts a `separate_thread=True` argument, which will automatically run the function in a separate thread. (The decorator alternativly accepts a `separate_process=True` argument, which will run the function in a separate process, but this is still experimental and should only considered for heavy CPU bound tasks)

`separate_process` wraps the function with `funcnodes_core.utils.functions.make_run_in_new_process`, which uses a `ProcessPoolExecutor`. Resource limits or sandboxing are not applied by FuncNodes; if you need supervision, point the worker at a running `subprocess_monitor` (see Worker config).

### Nested Inheritance

While the class based approach allows for more complex inheritance patterns:

```python
import funcnodes as fn

class BaseNode(fn.Node):
    """
    `Abstract` base class does not need a `func` method or a `node_id`
    """

    my_id = fn.NodeOutput(id="my_id", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["my_id"].value = id(self)


class MyNode(BaseNode):
    node_name = "My Node"
    node_id = "my_node"

    input1 = fn.NodeInput(id="input1", type=int)
    input2 = fn.NodeInput(id="input2", type=int)

    output1 = fn.NodeOutput(id="output1", type=int)

    async def func(self, input1, input2):
        result =  input1 + input2
        self.outputs["output1"].value = result

class MyNodeTwo(BaseNode):
    node_name = "My Node Two"
    node_id = "my_node_two"

    input1 = fn.NodeInput(id="input1", type=int)
    output1 = fn.NodeOutput(id="output1", type=float)

    async def func(self, input1):
        self.outputs["output1"].value = input1/2
```

The decorator also allows to use different baseclasses than the default `Node` class, by using the `superclass` argument of the decorator.

```python
import funcnodes as fn

class BaseNode(fn.Node):
    """
    `Abstract` base class does not need a `func` method or a `node_id`
    """

    my_id = fn.NodeOutput(id="my_id", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["my_id"].value = id(self)


@fn.NodeDecorator(node_id="my_node", superclass=BaseNode)
def my_node(input1: int, input2: int) -> int:
    return input1 + input2

instance = my_node()
instance.outputs["my_id"].value == id(instance) # True
```

### Try it out yourself

# Node Inputs

`NodeInput` is the input connection point for nodes in FuncNodes. It extends `NodeIO` with input-specific behavior including triggering, default values, and required/optional semantics.

______________________________________________________________________

## Constructor Parameters

```python
fn.NodeInput(
    id: str,                           # Unique identifier (required)
    type: Type = Any,                  # Data type hint
    name: str = None,                  # Display name (defaults to id)
    description: str = None,           # Help text
    default: Any = NoValue,            # Default value
    required: bool = True,             # Must have value to execute?
    does_trigger: bool = True,         # Triggers node on value change?
    allow_multiple: bool = False,      # Allow multiple connections?
    hidden: bool = False,              # Hide in UI
    value_options: dict = None,        # Value constraints
    render_options: dict = None,       # UI rendering hints
    emit_value_set: bool = True,       # Emit events on value change?
    on: dict = None,                   # Event handlers
)
```

### Parameter Details

| Parameter        | Type   | Default   | Description                                                                                                                 |
| ---------------- | ------ | --------- | --------------------------------------------------------------------------------------------------------------------------- |
| `id`             | `str`  | Required  | Unique identifier within the node. Used for programmatic access via `node.inputs["id"]`. Must be a valid Python identifier. |
| `type`           | `Type` | `Any`     | Python type hint. Affects UI rendering (e.g., `int` shows number input, `bool` shows checkbox). Not enforced at runtime.    |
| `name`           | `str`  | `id`      | Human-readable display name shown in UI.                                                                                    |
| `description`    | `str`  | `None`    | Tooltip/help text shown on hover in UI.                                                                                     |
| `default`        | `Any`  | `NoValue` | Default value when input is not connected and not manually set.                                                             |
| `required`       | `bool` | `True`    | If `True`, node won't execute until this input has a value.                                                                 |
| `does_trigger`   | `bool` | `True`    | If `True`, setting this input triggers node execution.                                                                      |
| `allow_multiple` | `bool` | `False`   | If `True`, multiple outputs can connect to this input.                                                                      |
| `hidden`         | `bool` | `False`   | If `True`, input is hidden from UI (but still functional).                                                                  |
| `value_options`  | `dict` | `None`    | Constraints like `min`, `max`, `step`, `options`.                                                                           |
| `render_options` | `dict` | `None`    | UI hints like custom renderer type.                                                                                         |
| `emit_value_set` | `bool` | `True`    | If `True`, emits `after_set_value` event when value changes.                                                                |
| `on`             | `dict` | `None`    | Event handlers to register (e.g., `{"after_set_value": handler}`).                                                          |

______________________________________________________________________

## Basic Usage

### Class-Based Nodes

```python
import funcnodes_core as fn

class MyNode(fn.Node):
    node_id = "my_module.my_node"
    node_name = "My Node"

    # Basic input with type and default
    value = fn.NodeInput(id="value", type=float, default=0.0)

    # Required input (must be set before node executes)
    data = fn.NodeInput(id="data", type=list, required=True)

    # Optional input with description
    label = fn.NodeInput(
        id="label",
        type=str,
        default="",
        required=False,
        description="Optional label for the output"
    )

    async def func(self, value, data, label):
        result = process(data, value)
        return f"{label}: {result}" if label else str(result)
```

### Decorator-Based Nodes

With decorators, inputs are created automatically from function parameters:

```python
@fn.NodeDecorator(node_id="add_numbers")
def add(a: int = 0, b: int = 0) -> int:
    return a + b
```

This creates:

- Input `a` with type `int`, default `0`
- Input `b` with type `int`, default `0`

### Using Type Annotations with `InputMeta`

For more control in decorator-based nodes, use `typing.Annotated` with `fn.InputMeta` to define all input properties inline:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(
    a: Annotated[
        int,
        fn.InputMeta(
            name="Amount",           # Display name
            description="The amount to process",
            default=1,
            does_trigger=False,
            hidden=True,
        ),
    ],
) -> int:
    return a + 1
```

This approach:

- Uses the **parameter name** (`a`) as the input ID
- The **type** comes from the first argument to `Annotated`
- All input properties are specified in `InputMeta`

### `InputMeta` with Dynamic Options

You can also include event handlers directly in `InputMeta`:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="dict_selector")
def dict_selector(
    data: Annotated[
        dict[str, int],
        fn.InputMeta(
            name="Data",
            description="Dictionary to select from",
            on={
                "after_set_value": fn.decorator.update_other_io_options(
                    "key",
                    list,  # Updates key's options to list(data.keys())
                )
            },
        ),
    ],
    key: str,
) -> int:
    return data[key]
```

Each node instance maintains **separate state** ‚Äî setting `data` on one instance updates only that instance's `key` options:

```python
node1 = dict_selector()
node2 = dict_selector()

node1["data"] = {"k1": 1, "k2": 2}
node2["data"] = {"k3": 3, "k4": 4}

# node1's key options: ["k1", "k2"]
# node2's key options: ["k3", "k4"]
```

### `InputMeta` Parameters

| Parameter        | Type   | Description                               |
| ---------------- | ------ | ----------------------------------------- |
| `name`           | `str`  | Display name (defaults to parameter name) |
| `description`    | `str`  | Help text                                 |
| `default`        | `Any`  | Default value                             |
| `does_trigger`   | `bool` | Whether setting triggers execution        |
| `required`       | `bool` | Whether input must have value             |
| `hidden`         | `bool` | Whether to hide in UI                     |
| `value_options`  | `dict` | Constraints like `min`, `max`, `options`  |
| `render_options` | `dict` | UI rendering hints                        |
| `on`             | `dict` | Event handlers                            |

______________________________________________________________________

## Value Constraints (`value_options`)

### Numeric Constraints

```python
# Slider with min/max (renders as slider in UI)
amount = fn.NodeInput(
    id="amount",
    type=float,
    default=0.5,
    value_options={"min": 0.0, "max": 1.0, "step": 0.1}
)

# Integer with minimum only
count = fn.NodeInput(
    id="count",
    type=int,
    default=1,
    value_options={"min": 1}
)
```

### Dropdown Options

```python
# Simple string options
mode = fn.NodeInput(
    id="mode",
    type=str,
    default="fast",
    value_options={"options": ["fast", "balanced", "accurate"]}
)

# Enum-style options (display labels different from values)
border_type = fn.NodeInput(
    id="border",
    type=int,
    default=0,
    value_options={
        "options": {
            "type": "enum",
            "keys": ["Constant", "Reflect", "Replicate"],
            "values": [0, 2, 1]
        }
    }
)
```

### Using DataEnum for Type-Safe Options

```python
from funcnodes_core import DataEnum

class ColorMode(DataEnum):
    RGB = ("rgb", "RGB Color")
    HSV = ("hsv", "HSV Color")
    GRAY = ("gray", "Grayscale")

@fn.NodeDecorator(node_id="convert_color")
def convert_color(
    image: "np.ndarray",
    mode: ColorMode = ColorMode.RGB
) -> "np.ndarray":
    return convert(image, mode.v())  # .v() gets the actual value
```

______________________________________________________________________

## Dynamic Value Options

Update input constraints based on other inputs using decorators:

### Dynamic Dropdown (Column Selector)

```python
from funcnodes_core.decorator import update_other_io_options

@fn.NodeDecorator(
    node_id="select_column",
    default_io_options={
        "df": {
            "on": {
                "after_set_value": update_other_io_options(
                    "column",  # Target input to update
                    lambda df: list(df.columns)  # Generate options
                )
            }
        },
    },
)
def select_column(df: "pd.DataFrame", column: str) -> "pd.Series":
    return df[column]
```

### Dynamic Numeric Bounds (List Index)

```python
from funcnodes_core.decorator import update_other_io_value_options

@fn.NodeDecorator(
    node_id="list_get",
    default_io_options={
        "lst": {
            "on": {
                "after_set_value": update_other_io_value_options(
                    "index",  # Target input
                    lambda lst: {
                        "min": -len(lst),
                        "max": len(lst) - 1 if len(lst) > 0 else 0,
                    }
                )
            }
        },
    },
)
def list_get(lst: list, index: int = -1) -> Any:
    return lst[index]
```

______________________________________________________________________

## Triggering Behavior

### `does_trigger` Parameter

Controls whether setting this input triggers node execution:

```python
class WaitNode(fn.Node):
    node_id = "wait_node"

    # Setting delay does NOT trigger the node
    delay = fn.NodeInput(
        id="delay",
        type=float,
        default=1.0,
        does_trigger=False,  # Change this without re-executing
        value_options={"min": 0.0}
    )

    # Setting input DOES trigger the node
    input = fn.NodeInput(id="input", type=Any)

    output = fn.NodeOutput(id="output", type=Any)

    async def func(self, delay, input):
        await asyncio.sleep(delay)
        self.outputs["output"].value = input
```

**Use cases for `does_trigger=False`:**

- Configuration parameters that shouldn't cause re-execution
- Parameters that are read during execution but don't initiate it
- Collector inputs in loop constructs

### Programmatic Value Setting

```python
# Set value and trigger (default)
node.inputs["value"].set_value(42)

# Set value without triggering
node.inputs["value"].set_value(42, does_trigger=False)

# Using property (always triggers based on does_trigger setting)
node.inputs["value"].value = 42
```

______________________________________________________________________

## Required vs Optional Inputs

### Required Inputs (`required=True`)

Node will **not execute** until all required inputs have values:

```python
class ProcessNode(fn.Node):
    node_id = "process_node"

    # Must be set before node can run
    data = fn.NodeInput(id="data", type=list, required=True)

    async def func(self, data):
        return process(data)
```

### Optional Inputs (`required=False`)

Node can execute even if these inputs have no value:

```python
class FormatNode(fn.Node):
    node_id = "format_node"

    value = fn.NodeInput(id="value", type=float, required=True)

    # Optional: uses default if not provided
    precision = fn.NodeInput(
        id="precision",
        type=int,
        default=2,
        required=False
    )

    async def func(self, value, precision):
        return f"{value:.{precision}f}"
```

______________________________________________________________________

## Default Values

### Static Defaults

```python
threshold = fn.NodeInput(id="threshold", type=float, default=0.5)
enabled = fn.NodeInput(id="enabled", type=bool, default=True)
items = fn.NodeInput(id="items", type=list, default=[])
```

### Dynamic Defaults with DefaultFactory

For defaults that depend on input state:

```python
class MyNode(fn.Node):
    node_id = "my_node"

    @staticmethod
    @fn.NodeInput.DefaultFactory
    def _default_timestamp(input: fn.NodeInput):
        """Generate timestamp when accessed."""
        import time
        return time.time()

    timestamp = fn.NodeInput(
        id="timestamp",
        type=float,
        default=_default_timestamp
    )
```

______________________________________________________________________

## Connection Behavior

### Single Connection (Default)

```python
# Only one output can connect to this input
input = fn.NodeInput(id="input", type=int, allow_multiple=False)
```

### Multiple Connections

```python
# Multiple outputs can connect (fan-in)
inputs = fn.NodeInput(id="inputs", type=Any, allow_multiple=True)
```

Fan-in Semantics

When multiple outputs connect to a single input, only the **last value set** is used. The values don't accumulate automatically.

### Disconnection Behavior

When an input is disconnected, it resets to its default value:

```python
# If default is NoValue, input becomes "not set"
# If default is provided, input gets that value
```

______________________________________________________________________

## Input Forwarding

Inputs can forward their values to other inputs (useful for subgraphs):

```python
# Forward value from one input to another
input_a.forward(input_b)

# Remove forwarding
input_a.unforward(input_b)

# Check forwarding relationships
input_a.has_forward_to(input_b)
input_b.has_forwards_from(input_a)
```

______________________________________________________________________

## Events

### Available Events

| Event               | When Fired              | Payload                               |
| ------------------- | ----------------------- | ------------------------------------- |
| `after_set_value`   | After value changes     | `{"src": input, "result": new_value}` |
| `before_connect`    | Before connection made  | Connection info                       |
| `after_connect`     | After connection made   | Connection info                       |
| `before_disconnect` | Before disconnection    | Disconnection info                    |
| `after_disconnect`  | After disconnection     | Disconnection info                    |
| `before_forward`    | Before input forwarding | Forward info                          |
| `after_forward`     | After input forwarding  | Forward info                          |

### Subscribing to Events

```python
# In class-based node
class MyNode(fn.Node):
    node_id = "my_node"

    value = fn.NodeInput(id="value", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.inputs["value"].on("after_set_value", self._on_value_change)

    def _on_value_change(self, msg):
        print(f"Value changed to: {msg['result']}")

# Using on parameter
value = fn.NodeInput(
    id="value",
    type=int,
    on={"after_set_value": lambda msg: print(f"New: {msg['result']}")}
)
```

______________________________________________________________________

## Render Options

### Custom Renderer Type

```python
# Render as color picker
color = fn.NodeInput(
    id="color",
    type=str,
    default="#ff0000",
    render_options={"type": "color"}
)

# Render with custom step display
delay = fn.NodeInput(
    id="delay",
    type=float,
    default=1.0,
    render_options={"step": "0.1"}
)
```

### Set Default on Manual Edit

```python
# When user manually edits, save as new default
config = fn.NodeInput(
    id="config",
    type=dict,
    render_options={"set_default": True}
)
```

______________________________________________________________________

## Status and State

### Check Input State

```python
input = node.inputs["value"]

# Check if value is set
has_value = input.value is not fn.NoValue

# Check if connected
is_connected = input.is_connected()

# Check if ready (has value or not required)
is_ready = input.ready()

# Get full status
status = input.status()
# Returns: {"has_value": bool, "has_node": bool, "ready": bool,
#           "connected": bool, "required": bool}
```

______________________________________________________________________

## Serialization

### Serialize Input State

```python
# Get serialized representation
serialized = input.serialize()
# Returns: {"id": "value", "type": "int", "value": 42, ...}

# Full serialization with all details
full = input.full_serialize(with_value=True)
```

### Restore from Serialized

```python
input.deserialize({"value": 42, "required": False})
```

______________________________________________________________________

## Complete Example

```python
import funcnodes_core as fn
from funcnodes_core.decorator import update_other_io_value_options
from typing import List, Any

@fn.NodeDecorator(
    node_id="funcnodes_example.list_processor",
    name="List Processor",
    description="Process a list with configurable options",
    default_io_options={
        "items": {
            "on": {
                "after_set_value": update_other_io_value_options(
                    "start_index",
                    lambda lst: {"min": 0, "max": len(lst) - 1} if lst else {"min": 0, "max": 0}
                )
            }
        }
    }
)
def list_processor(
    items: List[Any],
    start_index: int = 0,
    reverse: bool = False,
    limit: int = 10
) -> List[Any]:
    """Process a list with various options."""
    result = items[start_index:]
    if reverse:
        result = list(reversed(result))
    return result[:limit]
```

______________________________________________________________________

## See Also

- [Node Outputs](https://linkdlab.github.io/FuncNodes/components/nodeoutput/index.md) ‚Äî Output connection points
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî Complete IO reference
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî Node creation patterns
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event handling

# Node Outputs

`NodeOutput` is the output connection point for nodes in FuncNodes. It extends `NodeIO` and is responsible for sending data to connected inputs, triggering downstream execution.

______________________________________________________________________

## Constructor Parameters

```python
fn.NodeOutput(
    id: str,                           # Unique identifier (required)
    type: Type = Any,                  # Data type hint
    name: str = None,                  # Display name (defaults to id)
    description: str = None,           # Help text
    allow_multiple: bool = True,       # Allow multiple connections?
    hidden: bool = False,              # Hide in UI?
    value_options: dict = None,        # Value constraints (for previews)
    render_options: dict = None,       # UI rendering hints
    emit_value_set: bool = True,       # Emit events on value change?
    on: dict = None,                   # Event handlers
)
```

### Parameter Details

| Parameter        | Type   | Default  | Description                                                                               |
| ---------------- | ------ | -------- | ----------------------------------------------------------------------------------------- |
| `id`             | `str`  | Required | Unique identifier within the node. Used for programmatic access via `node.outputs["id"]`. |
| `type`           | `Type` | `Any`    | Python type hint. Affects how value is previewed in UI and serialized.                    |
| `name`           | `str`  | `id`     | Human-readable display name shown in UI.                                                  |
| `description`    | `str`  | `None`   | Tooltip/help text shown on hover in UI.                                                   |
| `allow_multiple` | `bool` | `True`   | If `True`, can connect to multiple inputs (fan-out). Almost always `True`.                |
| `hidden`         | `bool` | `False`  | If `True`, output is hidden from UI (but still functional).                               |
| `value_options`  | `dict` | `None`   | Metadata for previews (rarely used for outputs).                                          |
| `render_options` | `dict` | `None`   | UI hints for rendering previews.                                                          |
| `emit_value_set` | `bool` | `True`   | If `True`, emits `after_set_value` event when value changes.                              |
| `on`             | `dict` | `None`   | Event handlers to register.                                                               |

______________________________________________________________________

## Basic Usage

### Class-Based Nodes

```python
import funcnodes_core as fn

class CalculatorNode(fn.Node):
    node_id = "calculator"
    node_name = "Calculator"

    a = fn.NodeInput(id="a", type=float, default=0.0)
    b = fn.NodeInput(id="b", type=float, default=0.0)

    # Single output
    result = fn.NodeOutput(id="result", type=float)

    async def func(self, a, b):
        # Explicitly set output value
        self.outputs["result"].value = a + b
```

### Decorator-Based Nodes

With decorators, outputs are created from return type annotations:

```python
# Single output (named "out" by default)
@fn.NodeDecorator(node_id="double")
def double(x: float) -> float:
    return x * 2
```

### Using Type Annotations with `OutputMeta`

For more control over output properties in decorator-based nodes, use `typing.Annotated` with `fn.OutputMeta`:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="process")
def process(
    value: int
) -> Annotated[int, fn.OutputMeta(name="result", description="Processed value")]:
    return value + 1
```

This approach:

- Uses `Annotated` on the **return type**
- The output **type** comes from the first argument to `Annotated`
- The output **name** and other properties come from `OutputMeta`

### `OutputMeta` Parameters

| Parameter        | Type   | Description                 |
| ---------------- | ------ | --------------------------- |
| `name`           | `str`  | Display name for the output |
| `description`    | `str`  | Help text shown in UI       |
| `hidden`         | `bool` | Whether to hide in UI       |
| `render_options` | `dict` | UI rendering hints          |

### Combining `InputMeta` and `OutputMeta`

You can use both in the same node for full control:

```python
from typing import Annotated
import funcnodes_core as fn

@fn.NodeDecorator(node_id="my_node")
def my_node(
    a: Annotated[
        int,
        fn.InputMeta(
            name="Input Value",
            description="Value to increment",
            default=1,
            does_trigger=False,
        ),
    ],
) -> Annotated[int, fn.OutputMeta(name="Result", description="Incremented value")]:
    return a + 1
```

______________________________________________________________________

## Setting Output Values

### In Class-Based Nodes

Outputs must be set **explicitly** in the `func` method:

```python
class MyNode(fn.Node):
    node_id = "my_node"

    input = fn.NodeInput(id="input", type=int)
    output = fn.NodeOutput(id="output", type=int)
    debug = fn.NodeOutput(id="debug", type=str)

    async def func(self, input):
        # Set outputs explicitly
        self.outputs["output"].value = input * 2
        self.outputs["debug"].value = f"Processed: {input}"
```

### In Decorator-Based Nodes

Return values are automatically assigned to outputs:

```python
# Single return ‚Üí single output "out"
@fn.NodeDecorator(node_id="add")
def add(a: int, b: int) -> int:
    return a + b  # Assigned to output "out"
```

______________________________________________________________________

## Multiple Outputs

### Class-Based Approach

Simply define multiple `NodeOutput` attributes:

```python
class DivModNode(fn.Node):
    node_id = "divmod_node"

    a = fn.NodeInput(id="a", type=int)
    b = fn.NodeInput(id="b", type=int)

    quotient = fn.NodeOutput(id="quotient", type=int)
    remainder = fn.NodeOutput(id="remainder", type=int)

    async def func(self, a, b):
        q, r = divmod(a, b)
        self.outputs["quotient"].value = q
        self.outputs["remainder"].value = r
```

### Decorator with Typed Tuple

For multiple outputs in decorators, use `Tuple` with type hints:

```python
from typing import Tuple

@fn.NodeDecorator(node_id="divmod")
def divmod_node(a: int, b: int) -> Tuple[int, int]:
    return divmod(a, b)  # Creates outputs "out_0" and "out_1"
```

### Named Multiple Outputs

Use the `outputs` parameter to name them:

```python
from typing import Tuple

@fn.NodeDecorator(
    node_id="divmod",
    outputs=[
        {"name": "quotient"},
        {"name": "remainder"}
    ]
)
def divmod_node(a: int, b: int) -> Tuple[int, int]:
    q, r = divmod(a, b)
    return q, r  # quotient, remainder
```

### With Types in Output Spec

```python
@fn.NodeDecorator(
    node_id="stats",
    outputs=[
        {"name": "mean", "type": float},
        {"name": "std", "type": float},
        {"name": "count", "type": int}
    ]
)
def statistics(data: list) -> Tuple[float, float, int]:
    import statistics as st
    return st.mean(data), st.stdev(data), len(data)
```

______________________________________________________________________

## NoValue ‚Äî Conditional Outputs

`NoValue` is a special sentinel that indicates "no data". When an output is set to `NoValue`, it **does not trigger** connected inputs.

### Suppressing Downstream Triggers

```python
from funcnodes_core import NoValue

class ConditionalNode(fn.Node):
    node_id = "conditional"

    condition = fn.NodeInput(id="condition", type=bool)
    value = fn.NodeInput(id="value", type=Any)

    on_true = fn.NodeOutput(id="on_true", type=Any)
    on_false = fn.NodeOutput(id="on_false", type=Any)

    async def func(self, condition, value):
        if condition:
            self.outputs["on_true"].value = value
            self.outputs["on_false"].value = NoValue  # Won't trigger connected nodes
        else:
            self.outputs["on_true"].value = NoValue
            self.outputs["on_false"].value = value
```

### In Decorators

```python
from funcnodes_core import NoValue

@fn.NodeDecorator(
    node_id="filter_positive",
    outputs=[{"name": "positive"}, {"name": "negative"}]
)
def filter_positive(value: float) -> Tuple[float, float]:
    if value >= 0:
        return value, NoValue  # Only positive output triggers
    else:
        return NoValue, value  # Only negative output triggers
```

______________________________________________________________________

## Output Value Propagation

When an output value is set, it automatically propagates to all connected inputs:

```
flowchart TD
    SetOutput["Output.value = x"]
    ForEach["For each<br/>connected input"]
    SetInput["input.set_value(x)"]
    InputTrigger["input.trigger()"]
    NodeTrigger["node.trigger()<br/>(if ready)"]

    SetOutput --> ForEach
    ForEach --> SetInput
    SetInput --> InputTrigger
    InputTrigger --> NodeTrigger
```

### Propagation Timing

- Values propagate **immediately** when set
- All connected inputs receive the value
- Each input may trigger its node (if `does_trigger=True`)
- Execution cascades through the graph

______________________________________________________________________

## Connection Behavior

### Fan-Out (Default)

Outputs can connect to **multiple inputs** by default:

```python
# Single output connected to multiple nodes
output = fn.NodeOutput(id="result", type=float)

# Connect to multiple inputs
output.connect(node1.inputs["a"])
output.connect(node2.inputs["x"])
output.connect(node3.inputs["value"])
# All three inputs receive the same value
```

### Restricting Connections

Rarely needed, but you can limit to single connection:

```python
# Only one input can connect (unusual for outputs)
exclusive_output = fn.NodeOutput(
    id="exclusive",
    type=Any,
    allow_multiple=False
)
```

### Connection on Value Set

When a new connection is made, the current output value is **immediately sent** to the newly connected input:

```python
# If output.value is already 42
output.connect(new_input)
# new_input.value is now 42
```

______________________________________________________________________

## Hidden Outputs

Hide outputs that are for internal use or debugging:

```python
class DebugNode(fn.Node):
    node_id = "debug_node"

    input = fn.NodeInput(id="input", type=Any)

    # Visible in UI
    result = fn.NodeOutput(id="result", type=Any)

    # Hidden from UI (for debugging/internal use)
    trace = fn.NodeOutput(id="trace", type=str, hidden=True)

    async def func(self, input):
        self.outputs["result"].value = process(input)
        self.outputs["trace"].value = f"Processed at {time.time()}"
```

______________________________________________________________________

## Preview Rendering

### Default Render Options

Configure how the output preview is displayed:

```python
class ImageNode(fn.Node):
    node_id = "image_processor"

    # Tell UI which output to use for node preview
    default_render_options = {
        "data": {"src": "output_image"}
    }

    input_image = fn.NodeInput(id="input_image", type="np.ndarray")
    output_image = fn.NodeOutput(id="output_image", type="np.ndarray")
```

### Per-Output Render Options

```python
# Plotly figure output
figure = fn.NodeOutput(
    id="figure",
    type="plotly.graph_objs.Figure",
    render_options={"type": "plotly"}
)
```

______________________________________________________________________

## Events

### Available Events

| Event               | When Fired             | Payload                                |
| ------------------- | ---------------------- | -------------------------------------- |
| `after_set_value`   | After value changes    | `{"src": output, "result": new_value}` |
| `before_connect`    | Before connection made | Connection info                        |
| `after_connect`     | After connection made  | Connection info                        |
| `before_disconnect` | Before disconnection   | Disconnection info                     |
| `after_disconnect`  | After disconnection    | Disconnection info                     |

### Subscribing to Events

```python
class MyNode(fn.Node):
    node_id = "my_node"

    output = fn.NodeOutput(id="output", type=int)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.outputs["output"].on("after_set_value", self._on_output_change)

    def _on_output_change(self, msg):
        print(f"Output set to: {msg['result']}")
```

______________________________________________________________________

## Status and State

### Check Output State

```python
output = node.outputs["result"]

# Check if value is set
has_value = output.value is not fn.NoValue

# Check if connected
is_connected = output.is_connected()

# Get connections
connections = output.connections  # List of connected NodeInputs

# Get full status
status = output.status()
# Returns: {"has_value": bool, "has_node": bool, "ready": bool, "connected": bool}
```

______________________________________________________________________

## Manual Triggering

Force propagation to connected inputs:

```python
# Trigger all connected inputs with current value
output.trigger()

# This:
# 1. Sets value on all connected inputs (without triggering them)
# 2. Then triggers each connected input
```

______________________________________________________________________

## Serialization

### Serialize Output State

```python
# Get serialized representation
serialized = output.serialize()
# Returns: {"id": "result", "type": "float", ...}

# Full serialization with value
full = output.full_serialize(with_value=True)
```

______________________________________________________________________

## Complete Examples

### Router Node (Conditional Output)

```python
import funcnodes_core as fn
from funcnodes_core import NoValue
from typing import Any

class RouterNode(fn.Node):
    """Routes input to one of multiple outputs based on a selector."""

    node_id = "router"
    node_name = "Router"

    value = fn.NodeInput(id="value", type=Any)
    route = fn.NodeInput(
        id="route",
        type=int,
        default=0,
        value_options={"min": 0, "max": 2}
    )

    out_0 = fn.NodeOutput(id="out_0", type=Any)
    out_1 = fn.NodeOutput(id="out_1", type=Any)
    out_2 = fn.NodeOutput(id="out_2", type=Any)

    async def func(self, value, route):
        outputs = [self.outputs["out_0"],
                   self.outputs["out_1"],
                   self.outputs["out_2"]]

        for i, out in enumerate(outputs):
            if i == route:
                out.value = value
            else:
                out.value = NoValue  # Don't trigger other routes
```

### Statistics Node (Multiple Typed Outputs)

```python
from typing import Tuple, List
import statistics

@fn.NodeDecorator(
    node_id="statistics",
    name="Statistics",
    outputs=[
        {"name": "mean", "type": float},
        {"name": "median", "type": float},
        {"name": "stdev", "type": float},
        {"name": "min", "type": float},
        {"name": "max", "type": float},
    ]
)
def calc_statistics(
    data: List[float]
) -> Tuple[float, float, float, float, float]:
    """Calculate various statistics for a list of numbers."""
    return (
        statistics.mean(data),
        statistics.median(data),
        statistics.stdev(data) if len(data) > 1 else 0.0,
        min(data),
        max(data),
    )
```

### Image Processing with Preview

```python
import funcnodes_core as fn

class GrayscaleNode(fn.Node):
    """Convert image to grayscale."""

    node_id = "grayscale"
    node_name = "To Grayscale"

    # Configure preview to show output_image
    default_render_options = {
        "data": {"src": "output_image"}
    }

    input_image = fn.NodeInput(id="input_image", type="np.ndarray")
    output_image = fn.NodeOutput(id="output_image", type="np.ndarray")

    async def func(self, input_image):
        import cv2
        gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)
        self.outputs["output_image"].value = gray
```

______________________________________________________________________

## Comparison: Input vs Output

| Aspect                     | NodeInput             | NodeOutput          |
| -------------------------- | --------------------- | ------------------- |
| **Direction**              | Receives data         | Sends data          |
| **allow_multiple default** | `False`               | `True`              |
| **Triggers node**          | Yes (configurable)    | No                  |
| **Has default value**      | Yes                   | No                  |
| **required parameter**     | Yes                   | No                  |
| **does_trigger parameter** | Yes                   | No                  |
| **Value propagation**      | From connected output | To connected inputs |

______________________________________________________________________

## See Also

- [Node Inputs](https://linkdlab.github.io/FuncNodes/components/nodeinput/index.md) ‚Äî Input connection points
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî Complete IO reference
- [Creating Nodes](https://linkdlab.github.io/FuncNodes/components/node/index.md) ‚Äî Node creation patterns
- [Event System](https://linkdlab.github.io/FuncNodes/architecture/event-system/index.md) ‚Äî Event handling

# NodeSpace (Graph State)

`NodeSpace` is the in‚Äëmemory representation of a FuncNodes graph plus its library snapshot. Each worker owns exactly one `NodeSpace`.

## What a NodeSpace contains

- **Nodes:** Instances of node classes keyed by UUID.
- **Edges:** Connections between outputs and inputs (stored as tuples of source/target UUIDs and IO IDs).
- **Library:** A `funcnodes_core.lib.Library` with all shelves/nodes visible to this worker.
- **Properties:** Public `prop` (JSON‚Äëserializable) and non‚Äëserialized `secret` properties for runtime state.
- **Groups:** Optional node group metadata from `GroupingLogic`.

## Serialization

Two JSON shapes are used:

- `serialize()` ‚Üí minimal `NodeSpaceJSON` with `nodes`, `edges`, `prop`, `groups`. IO values are included only if set as defaults; secret properties are excluded.
- `full_serialize(with_io_values=False)` ‚Üí adds `lib` (full shelf tree) and can embed current IO values when requested.

Files on disk (`nodespace.json` inside each worker‚Äôs data directory) use `serialize()`. They are read back with `deserialize`, which re‚Äëhydrates nodes via the library; missing classes become `PlaceHolderNode` instances.

## Edge and connection rules

- Connections must be output‚Üíinput (or input forwarding) and honor each IO‚Äôs `allow_multiple` flag; violations raise `NodeConnectionError` / `MultipleConnectionsError`.
- There is no automatic cycle detection; avoid wiring graphs that feed back indefinitely unless your node logic guards against it.

## Lifecycle hooks

`NodeSpace` emits events on node add/remove, trigger errors (`node_error` / `node_trigger_error`), and cleanup. Workers subscribe to these to update clients.

Error handling is event-only: there is no built-in retry/backoff. When a node raises, the error event is emitted and the node stays in its current state until retriggered by another input change or a manual trigger.

## Persistence cadence

Workers run a `SaveLoop` that writes the serialized NodeSpace to disk when `request_save()` is set (e.g., after edits). Exporting a worker bundles this serialized graph together with config and optional files.

# Serialization

FuncNodes uses a custom JSON serialization system to persist workflows, transfer data between workers, and render previews in the UI. This page covers the complete serialization API.

______________________________________________________________________

## Overview

The serialization system consists of:

| Component      | Purpose                                          |
| -------------- | ------------------------------------------------ |
| `JSONEncoder`  | Converts Python objects to JSON-compatible types |
| `JSONDecoder`  | Restores Python objects from JSON                |
| `ByteEncoder`  | Converts objects to binary data with MIME types  |
| `Encdata`      | Return type for JSON encoders                    |
| `BytesEncdata` | Return type for byte encoders                    |

______________________________________________________________________

## JSONEncoder

`JSONEncoder` extends Python's `json.JSONEncoder` with a registry of custom handlers.

### Basic Usage

```python
import json
from funcnodes_core.utils.serialization import JSONEncoder

# Encode an object
data = {"array": my_numpy_array, "figure": my_plotly_figure}
json_string = json.dumps(data, cls=JSONEncoder)

# Apply encoding without full JSON serialization
encoded = JSONEncoder.apply_custom_encoding(my_object, preview=False)
```

### The `preview` Parameter

Encoders receive a `preview` flag that indicates lightweight encoding for UI display:

- **`preview=False`** ‚Äî Full serialization for persistence/transfer
- **`preview=True`** ‚Äî Truncated/simplified output for UI previews

Built-in preview behaviors:

- Strings longer than 1000 characters are truncated with `...`
- Lists are limited to the first 10 items
- Large arrays may use simplified representations

______________________________________________________________________

## Registering Custom Encoders

### Simple Encoder (Tuple Return)

```python
from funcnodes_core.utils.serialization import JSONEncoder

def my_encoder(obj, preview=False):
    """Simple encoder returning (data, handled) tuple."""
    if isinstance(obj, MyCustomType):
        return obj.to_dict(), True  # (encoded_data, was_handled)
    return obj, False  # Not handled, pass to next encoder

JSONEncoder.add_encoder(my_encoder)
```

### Advanced Encoder (Encdata Return)

For more control, return an `Encdata` object:

```python
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def my_encoder(obj, preview=False):
    """Advanced encoder with Encdata control."""
    if isinstance(obj, MyCustomType):
        return Encdata(
            data=obj.to_dict(),
            handeled=True,
            done=False,           # Continue encoding nested objects
            continue_preview=None # Inherit preview setting
        )
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(my_encoder)
```

### Encdata Parameters

| Parameter          | Type             | Description                                                                                                  |
| ------------------ | ---------------- | ------------------------------------------------------------------------------------------------------------ |
| `data`             | `Any`            | The encoded data                                                                                             |
| `handeled`         | `bool`           | Whether this encoder processed the object                                                                    |
| `done`             | `bool`           | If `True`, stop encoding (return data as-is). If `False`, continue encoding nested objects. Default: `False` |
| `continue_preview` | `Optional[bool]` | Override preview flag for nested encoding. `None` inherits current setting.                                  |

### Type-Specific Registration

Register encoders for specific types to improve performance:

```python
from pathlib import Path
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def path_encoder(obj, preview=False):
    if isinstance(obj, Path):
        return Encdata(data=obj.as_posix(), handeled=True)
    return Encdata(data=obj, handeled=False)

# Only called for Path objects (and subclasses)
JSONEncoder.add_encoder(path_encoder, enc_cls=[Path])
```

### Encoder Priority

Use `prepend_encoder` to add an encoder at the front of the queue (higher priority):

```python
# This encoder will be tried before others for the specified types
JSONEncoder.prepend_encoder(my_high_priority_encoder, enc_cls=[MyType])
```

______________________________________________________________________

## Real-World Encoder Examples

### NumPy Arrays

```python
import numpy as np
import funcnodes_core as fn

def numpy_encoder(obj, preview=False):
    if isinstance(obj, np.ndarray):
        if preview:
            # Simplified preview for UI
            return obj.tolist()[:10], True
        return obj.tolist(), True
    return obj, False

fn.JSONEncoder.add_encoder(numpy_encoder)
```

### Plotly Figures

```python
import plotly.graph_objects as go
import funcnodes_core as fn

def figure_encoder(figure: go.Figure, preview=False):
    if isinstance(figure, go.Figure):
        return fn.Encdata(
            data=figure.to_plotly_json(),
            handeled=True,
            done=False,              # Allow nested encoding
            continue_preview=False,  # Disable preview for nested data
        )
    return fn.Encdata(data=figure, handeled=False)

fn.JSONEncoder.add_encoder(figure_encoder, enc_cls=[go.Figure])
```

### Pydantic Models

```python
from pydantic import BaseModel
from funcnodes_core.utils.serialization import JSONEncoder, Encdata

def pydantic_encoder(obj, preview=False):
    if isinstance(obj, BaseModel):
        return Encdata(
            data=obj.model_dump(mode="json"),
            handeled=True,
            done=True,  # Already JSON-compatible
        )
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(pydantic_encoder, enc_cls=[BaseModel])
```

______________________________________________________________________

## JSONDecoder

`JSONDecoder` restores Python objects from JSON using registered decoders.

### Basic Usage

```python
import json
from funcnodes_core.utils.serialization import JSONDecoder

# Decode JSON string
data = json.loads(json_string, cls=JSONDecoder)
```

### Registering Decoders

Decoders are called for each dict/value during parsing:

```python
from funcnodes_core.utils.serialization import JSONDecoder

def my_decoder(obj):
    """Decoder returning (result, handled) tuple."""
    if isinstance(obj, dict) and obj.get("__type__") == "MyCustomType":
        return MyCustomType.from_dict(obj), True
    return obj, False

JSONDecoder.add_decoder(my_decoder)
```

### Decoder Signature

```python
def decoder(obj: Any) -> Tuple[Any, bool]:
    """
    Args:
        obj: The JSON value (dict, list, str, int, float, bool, None)

    Returns:
        Tuple of (decoded_object, was_handled)
    """
```

______________________________________________________________________

## ByteEncoder

`ByteEncoder` converts objects to binary data with MIME types for efficient transfer.

### Basic Usage

```python
from funcnodes_core.utils.serialization import ByteEncoder

result = ByteEncoder.encode(my_object, preview=False)
# result.data: bytes
# result.mime: str (e.g., "application/json", "image/png")
# result.handeled: bool
```

### Registering Byte Encoders

```python
from funcnodes_core.utils.serialization import ByteEncoder, BytesEncdata

def image_byte_encoder(obj, preview=False):
    if isinstance(obj, MyImageType):
        return BytesEncdata(
            data=obj.to_png_bytes(),
            handeled=True,
            mime="image/png"
        )
    return BytesEncdata(data=obj, handeled=False)

ByteEncoder.add_encoder(image_byte_encoder, enc_cls=[MyImageType])
```

### BytesEncdata Parameters

| Parameter  | Type            | Description                               |
| ---------- | --------------- | ----------------------------------------- |
| `data`     | `bytes \| Any`  | The encoded binary data                   |
| `handeled` | `bool`          | Whether this encoder processed the object |
| `mime`     | `Optional[str]` | MIME type of the encoded data             |

### Built-in MIME Types

| Type          | MIME                       |
| ------------- | -------------------------- |
| `str`         | `text/plain`               |
| `bytes`       | `application/octet-stream` |
| `int`         | `application/fn.struct.!q` |
| `float`       | `application/fn.struct.!d` |
| `bool`        | `application/fn.struct.?`  |
| `None`        | `application/fn.null`      |
| JSON fallback | `application/json`         |

______________________________________________________________________

## Built-in Type Handlers

### Bytes

Bytes are Base64 encoded for JSON:

```python
import base64

# Encoding: bytes ‚Üí base64 string
encoded = base64.b64encode(my_bytes).decode("utf-8")

# Built-in handler does this automatically
```

### Dataclasses

Dataclasses are automatically converted to dictionaries:

```python
from dataclasses import dataclass

@dataclass
class MyData:
    name: str
    value: int

# Automatically serializes to {"name": "...", "value": ...}
```

### Objects with `_repr_json_`

Objects implementing `_repr_json_()` method are automatically encoded:

```python
class MyType:
    def _repr_json_(self):
        """Return JSON-serializable representation."""
        return {"type": "MyType", "data": self._internal_data}
```

______________________________________________________________________

## Persistence Files

FuncNodes uses these files for persistence:

| File                 | Content                                       | Format  |
| -------------------- | --------------------------------------------- | ------- |
| `nodespace.json`     | Serialized graph state (nodes, edges, groups) | JSON    |
| `worker_<uuid>.json` | Worker configuration and metadata             | JSON    |
| `config.json`        | Global FuncNodes settings                     | JSON    |
| `io_values/`         | Large IO values stored separately             | Various |

### Nodespace Serialization

```python
# Save nodespace
nodespace.serialize()  # Returns dict
json.dumps(nodespace.serialize(), cls=JSONEncoder)

# Load nodespace
nodespace.deserialize(data)
```

### Node Serialization

```python
# Full serialization (for persistence)
node.full_serialize()

# Returns:
{
    "node_id": "my_node",
    "uuid": "abc123...",
    "io": [...],  # Serialized inputs/outputs
    "render_options": {...},
    "properties": {...}
}
```

______________________________________________________________________

## Performance Considerations

### Large Data

For large arrays or binary data:

1. **Use file references** instead of embedding data:

```python
# Instead of storing array in JSON
# Store path to file and load on demand
{"__file__": "data/large_array.npy"}
```

1. **Use ByteEncoder** for binary transfer (more efficient than Base64)
1. **Enable preview mode** for UI display to truncate large data

### Circular References

The encoder detects circular references and raises `ValueError`:

```python
# This will raise ValueError
a = {}
a["self"] = a
JSONEncoder.apply_custom_encoding(a)  # ValueError: Circular reference detected
```

### Encoder Ordering

- Register type-specific encoders with `enc_cls` for better performance
- Use `prepend_encoder` for high-priority handlers
- The encoder chain stops at the first handler that returns `handeled=True`

______________________________________________________________________

## Module Integration

### Registering Encoders in Modules

Add encoders in your module's `__init__.py`:

```python
# mymodule/__init__.py
import funcnodes_core as fn
from .types import MyCustomType

def my_encoder(obj, preview=False):
    if isinstance(obj, MyCustomType):
        return fn.Encdata(
            data={"__type__": "MyCustomType", **obj.to_dict()},
            handeled=True
        )
    return fn.Encdata(data=obj, handeled=False)

# Register when module is imported
fn.JSONEncoder.add_encoder(my_encoder, enc_cls=[MyCustomType])
```

### Render Options for Custom Types

Tell the UI how to display your type:

```python
FUNCNODES_RENDER_OPTIONS: fn.RenderOptions = {
    "typemap": {
        "mymodule.MyCustomType": "json",  # Render as JSON viewer
    },
    "inputconverter": {
        "mymodule.MyCustomType": "str_to_json",  # Parse JSON input
    },
}
```

______________________________________________________________________

## Complete Example

```python
import funcnodes_core as fn
from funcnodes_core.utils.serialization import (
    JSONEncoder, JSONDecoder, ByteEncoder,
    Encdata, BytesEncdata
)
from dataclasses import dataclass

@dataclass
class Measurement:
    timestamp: float
    values: list[float]
    unit: str

# JSON Encoder
def measurement_encoder(obj, preview=False):
    if isinstance(obj, Measurement):
        data = {
            "__type__": "Measurement",
            "timestamp": obj.timestamp,
            "values": obj.values[:10] if preview else obj.values,
            "unit": obj.unit,
        }
        return Encdata(data=data, handeled=True, done=True)
    return Encdata(data=obj, handeled=False)

JSONEncoder.add_encoder(measurement_encoder, enc_cls=[Measurement])

# JSON Decoder
def measurement_decoder(obj):
    if isinstance(obj, dict) and obj.get("__type__") == "Measurement":
        return Measurement(
            timestamp=obj["timestamp"],
            values=obj["values"],
            unit=obj["unit"]
        ), True
    return obj, False

JSONDecoder.add_decoder(measurement_decoder)

# Byte Encoder (for efficient binary transfer)
def measurement_byte_encoder(obj, preview=False):
    if isinstance(obj, Measurement):
        import json
        data = json.dumps({
            "timestamp": obj.timestamp,
            "values": obj.values,
            "unit": obj.unit,
        }).encode("utf-8")
        return BytesEncdata(data=data, handeled=True, mime="application/json")
    return BytesEncdata(data=obj, handeled=False)

ByteEncoder.add_encoder(measurement_byte_encoder, enc_cls=[Measurement])
```

______________________________________________________________________

## Best Practices

1. **Keep IO values serializable** ‚Äî Use JSON-compatible types or register encoders
1. **Use `enc_cls` for type-specific encoders** ‚Äî Improves performance by skipping irrelevant handlers
1. **Support preview mode** ‚Äî Truncate large data for UI display
1. **Use `done=True` for terminal encodings** ‚Äî When data is already JSON-compatible
1. **Avoid embedding large binary data** ‚Äî Use file references or ByteEncoder
1. **Register decoders for round-trip support** ‚Äî Ensure deserialization works correctly
1. **Handle edge cases** ‚Äî `None`, empty collections, `NaN` values

______________________________________________________________________

## See Also

- [Nodespace](https://linkdlab.github.io/FuncNodes/components/nodespace/index.md) ‚Äî Graph state and persistence
- [Inputs & Outputs](https://linkdlab.github.io/FuncNodes/components/inputs-outputs/index.md) ‚Äî IO serialization
- [Writing Modules](https://linkdlab.github.io/FuncNodes/extending/writing-modules/index.md) ‚Äî Module development

# Shelves (Node Library Groups)

Shelves are the catalog entries that tell FuncNodes which node classes are available and how they are grouped in the UI. A shelf is a small tree that contains node classes (`funcnodes_core.node.Node`) and optional subshelves.

## Structure

- **Data model:** `funcnodes_core.lib.Shelf` holds `name`, `description`, `nodes` (list of node classes), and `subshelves` (list of Shelves). Each shelf gets a generated `shelf_id` when validated.
- **Serialization:** Shelves serialize to JSON via `funcnodes_core.lib.serialize_shelf`, emitting `name`, `description`, `nodes` (serialized node classes), and nested `subshelves`.
- **Storage:** The runtime keeps a flat registry (`funcnodes_core.lib.Library`) keyed by tuple paths (`("Top", "Child", ...)`) for GC‚Äëfriendly storage. Complete shelf trees are materialized on demand.

## How shelves are discovered

FuncNodes loads shelves from installed Python packages via the `funcnodes.module` entry point group:

- If a distribution exposes `shelf = "<pkg>:<object>"` under `project.entry-points."funcnodes.module"`, that object is read and validated with `funcnodes_core.lib.check_shelf`. Dictionaries are accepted and converted to `Shelf` instances.
- If no `shelf` entry point is present, FuncNodes falls back to introspection: every non‚Äëabstract subclass of `Node` defined in the module is collected into a shelf named after the module (`funcnodes_core.lib.libparser.module_to_shelf`).
- Additional optional entry points (`render_options`, `external_worker`, `plugin_setup`) may also be exported; they are processed in `_setup.py` but do not affect shelf discovery itself.

Example (from `modules/funcnodes_files/pyproject.toml`):

```toml
[project.entry-points."funcnodes.module"]
module = "funcnodes_files"
shelf = "funcnodes_files:NODE_SHELF"
react_plugin = "funcnodes_files:REACT_PLUGIN"
```

Here `NODE_SHELF` is the authoritative shelf object; the React plugin entry point is consumed by the UI host but does not change the shelf tree.

## How shelves are mounted at runtime

- The Workermanager/Worker loads installed modules, parses their entry points, and registers shelves into a `Library` instance attached to each `NodeSpace`.
- `Library.add_shelf` merges shelves by path, keeping node IDs unique per shelf. External shelves can be mounted via weak references (`add_external_shelf`, `add_subshelf_weak`) so they disappear automatically when their owner is GC‚Äôd.
- Finding nodes is path‚Äëaware: `Library.find_nodeid` returns all shelf paths containing a node ID, and `get_node_by_id` only succeeds if the node is both registered and referenced by at least one shelf.

## Authoring guidance for module writers

- Export a `Shelf` (or dict convertible to one) through the `funcnodes.module` entry point to get precise grouping and descriptions.
- Ensure each node class has a globally unique `node_id`; shelves store only node IDs, so duplicates are skipped when the Library deduplicates.
- Organize subshelves for UI grouping‚Äîpaths are preserved (`["Vision", "Filters", ...]`) and rendered as nested menus in the editor host.

## What is a Worker?

Workers are long-lived processes that execute FuncNodes graphs. Each worker owns:

- A **NodeSpace** (graph state, groups, properties).
- An isolated **environment** (virtualenv by default) and dependency set.
- A **data directory** (`~/.funcnodes/workers/worker_<uuid>/`) containing `nodespace.json`, uploaded `files/`, optional `pyproject.toml`, and `worker.log`.
- A **WebSocket/HTTP server** that exposes RPC commands and large-payload endpoints.

Workers are started and supervised by the **Workermanager**, but you can also launch them directly via `funcnodes worker start`.

## Runtime loops & health

The worker event loop runs several recurring tasks:

- **NodeSpaceLoop** ‚Äî drains pending triggers (`NodeSpace.await_done`) on a short interval (default 5‚ÄØms).
- **SaveLoop** ‚Äî writes process/runstate files and persists the graph when `request_save()` is flagged.
- **LocalWorkerLookupLoop** ‚Äî discovers external worker classes in `data_path/local_scripts`.
- **HeartbeatLoop** ‚Äî optional; if `required_heartbeat` is set and no `heartbeat()` RPC arrives in time, the worker stops itself.

Defaults can be tuned via worker config (e.g., `nodespace_delay`, `save_delay`) for responsiveness vs. CPU/disk usage.

## RPC surface (WebSocket JSON)

Clients send `{"type":"cmd","cmd":<name>,"kwargs":{...}}`; worker replies with `result` or `error`. Common commands:

- **Identity/meta**: `uuid`, `name`, `get_meta`, `heartbeat`
- **State**: `full_state`, `get_nodes`, `get_edges`, `get_groups`, `view_state`, `get_save_state`
- **Mutations**: `update_node`, `update_group`, `group_nodes`, `remove_group`, `clear`, `save`, `load_data`, `export_worker`, `import_worker`
- **Library/modules**: `get_library`, `get_worker_dependencies`, `get_plugin_keys`, `get_plugin`, `add_package_dependency`, `remove_package_dependency`
- **External tooling**: `list_local_workers`, `start_local_worker`, `stop_local_worker`, `upload`

Ping/pong is built in (`{"type":"ping"}` ‚Üí `{"type":"pong"}`) and is how the UI detects liveness.

## Messaging & large payloads

- Standard messages travel over WebSockets as JSON.
- Messages larger than `MESSAGE_SIZE_BEFORE_REQUEST` (default 1‚ÄØMB) are staged in memory; the worker sends a `large_message` stub and exposes a temporary HTTP endpoint `/message/<msg_id>` for retrieval.
- Binary streams (e.g., image frames) are chunked with headers `chunk=<i>/<n>` to avoid blocking the socket.
- Uploads use `POST /upload/` and are forcibly rooted to `files/` inside the worker‚Äôs data dir; attempts to traverse elsewhere are rejected.

## Lifecycle & files on disk

When running, the worker writes:

- `worker_<uuid>.json` ‚Äî config (host/port, env paths, flags)
- `worker_<uuid>.p` ‚Äî PID file for liveness detection
- `worker_<uuid>.runstate` ‚Äî human-readable status (‚Äústarting‚Ä¶‚Äù, ‚Äúrunning‚Äù, etc.)

Shutting down clears PID/runstate and flushes a final save. Exports bundle `config`, `state`, optional `pyproject.toml`, and `files/` into a ZIP for backup/migration.

## Isolation & performance

- **Process/thread offload**: Nodes can set `separate_thread=True` or `separate_process=True` to avoid blocking the event loop.
- **Message size caps**: `MAX_DATA_SIZE` (default 10‚ÄØGB) protects memory; adjust via env if needed.
- **Logging**: Per-worker rotating file handler (~100‚ÄØKB √ó 5). Change location/level via config.

## Security considerations

- Workers do **not** implement authentication. In production, front them with an authenticated proxy (e.g., nginx/Traefik) and keep ports non-public. File writes are constrained to `files/`, but you should still sandbox network access and enforce upload size limits at the proxy.
- TLS termination is not provided by the worker itself; the `ssl` field in the config defaults to `False` and the WebSocket loop always starts plain HTTP. Terminate TLS in your proxy/load balancer instead.

## Environments & dependencies

- New workers create their own virtualenv unless started with `--not-in-venv`; sharing the interpreter is possible but increases the risk of version conflicts.
- The worker config carries `update_on_startup` flags (default `True` for `funcnodes`, `funcnodes-core`, `funcnodes-worker`) so core packages can be upgraded automatically when a worker starts.
- Additional packages installed via `funcnodes worker ... modules install ...` are tracked per worker in `package_dependencies`; isolated envs let different workers pin incompatible versions safely.

## Subprocess/offload options

- `@NodeDecorator(..., separate_thread=True)` runs the wrapped function in a thread; `separate_process=True` wraps it in a `ProcessPoolExecutor` (`funcnodes_core.utils.functions.make_run_in_new_process`).
- Workers expose an optional `subprocess_monitor` host/port in their config; if set, heavy external commands can be supervised by the `subprocess_monitor` service. FuncNodes itself does not enforce per-node resource limits‚Äîrely on the monitor/OS for that.

# Worker Configuration

Each worker keeps its own config file at `~/.funcnodes/workers/worker_<uuid>.json`. Key fields include:

- **uuid** / **name** ‚Äî worker identity.
- **data_path** ‚Äî worker data dir (nodespace.json, files/, logs).
- **env_path** ‚Äî virtualenv location (absent when created with `--not-in-venv`).
- **host/port/ssl** ‚Äî where the worker‚Äôs WS/HTTP server listens.
- **update_on_startup** ‚Äî flags to auto-upgrade `funcnodes`, `funcnodes-core`, and unpinned dependencies on activation.
- **nodespace_path** ‚Äî path to the current NodeSpace state file.
- **required_heartbeat** ‚Äî optional timeout for heartbeat enforcement.
- **workertype** ‚Äî worker class (defaults to WSWorker; extension point for external workers).
- **subprocess_monitor** ‚Äî optional host/port if using the subprocess monitor.

Creation and lifecycle:

- Generated when you run `funcnodes worker new ...`; updated when workers start/stop.
- The Workermanager reads this file to decide how to spawn and to report status.
- Edits can be made manually for advanced tuning (e.g., changing host/port) ‚Äî stop the worker first, edit, then restart.

Related liveness files:

- `worker_<uuid>.p` ‚Äî PID of the running process.
- `worker_<uuid>.runstate` ‚Äî human-readable startup/run status used by the UI.

## What is the Workermanager?

The Workermanager is a lightweight aiohttp service that supervises all workers on a host. It:

- Maintains worker metadata on disk (`~/.funcnodes/workers/worker_<uuid>.json/.p/.runstate`).
- Spawns, stops, restarts, deletes, and lists workers.
- Acts as a WebSocket hub so UIs can discover and control workers.
- Optionally provisions per-worker virtualenvs and upgrades packages on activation.

By default it listens on `localhost:9380` at `/` for WebSocket clients (no auth by default‚Äîsee Security).

## Message protocol (WebSocket)

Simple string commands:

- `ping` ‚Üí `pong`
- `identify` ‚Üí JSON `{ "class": "WorkerManager", "py": sys.executable }`
- `worker_status` ‚Üí lists active/inactive workers
- `stop` ‚Üí stop the manager

JSON commands (selected):

- `{ "type": "new_worker", "kwargs": {...} }` ‚Üí create worker (options: name, reference, copyLib, copyNS, in_venv toggle)
- `{ "type": "set_active", "workerid": uuid }` ‚Üí activate (start) worker
- `{ "type": "stop_worker", "workerid": uuid }`
- `{ "type": "restart_worker", "workerid": uuid }`
- `{ "type": "delete_worker", "workerid": uuid }`

Responses/broadcasts include:

- `worker_status` (active/inactive lists)
- `worker_created` / `worker_deleted`
- `set_worker` (full worker config once reachable)
- `progress` (text + progress float) to drive UI HUDs

## Files & liveness

Each worker has:

- `worker_<uuid>.json` ‚Äî config (host/port/env paths/nodespace path/flags)
- `worker_<uuid>.p` ‚Äî PID file written by the worker
- `worker_<uuid>.runstate` ‚Äî textual status during startup/running

Missing or stale files mark workers as inactive; status is refreshed every ~10‚ÄØs.

## Virtualenv & dependency management

- New workers default to their own venv unless `--not-in-venv` was set.
- On activation, optional `update_on_startup` flags can reinstall `funcnodes`, `funcnodes-core`, and unpinned dependencies.
- CLI helpers `funcnodes worker modules ‚Ä¶` run inside the worker env.

## Auto-start behavior

Clients (e.g., `funcnodes runserver`) call `assert_worker_manager_running`: it pings/identifies the manager and, if unreachable, spawns a fresh instance via `python -m funcnodes startworkermanager` (optionally through `subprocess_monitor`).

## Security

- No built-in authentication; expose only behind an authenticated reverse proxy.
- Keep the WS/HTTP ports private; block direct internet access.
- Size limits: large message/store defaults come from worker settings (`MAX_DATA_SIZE`, message expiry).
- TLS termination is not handled by the Workermanager itself; it serves plain HTTP/WebSocket. Terminate TLS at your proxy/load balancer if you need HTTPS/WSS.

## Operations cheat sheet

- Start manager: `funcnodes startworkermanager --host 0.0.0.0 --port 9380`
- List workers: `funcnodes worker list [--full]`
- New worker: `funcnodes worker new --name demo`
- Start worker: `funcnodes worker --name demo start`
- Delete worker: `funcnodes worker --name demo delete`
# Examples

# Examples

Interactive examples demonstrating FuncNodes capabilities. Each example runs directly in your browser using Pyodide (Python compiled to WebAssembly).

Browser Execution

These examples run entirely in your browser. Initial load may take a few seconds as Python compiles to WebAssembly. Performance is slower than native Python installation.

______________________________________________________________________

## CSV Processing

**Modules used:** `funcnodes-files`, `funcnodes-pandas`

A data processing pipeline that:

- Reads CSV data from a file
- Performs basic data analysis
- Exports results to Excel format

**Key concepts:** File handling, DataFrame operations, data export

[**Open Example ‚Üí**](https://linkdlab.github.io/FuncNodes/examples/csv/index.md)

______________________________________________________________________

## Image Analysis

**Modules used:** `funcnodes-files`, `funcnodes-opencv`, `funcnodes-images`

A computer vision workflow demonstrating:

- Image loading and color space conversion
- Color-based region detection
- Image filtering and masking
- Live preview at each processing stage

**Key concepts:** OpenCV integration, live image previews, slider-based parameter tuning

[**Open Example ‚Üí**](https://linkdlab.github.io/FuncNodes/examples/cat/index.md)

______________________________________________________________________

## Plotly Visualization

**Modules used:** `funcnodes-files`, `funcnodes-pandas`, `funcnodes-plotly`

An interactive data visualization workflow:

- Load the Titanic dataset
- Clean and transform data
- Create interactive Plotly charts
- Analyze survival patterns by demographics

**Key concepts:** Plotly integration, DataFrame manipulation, interactive charts

[**Open Example ‚Üí**](https://linkdlab.github.io/FuncNodes/examples/titanic/index.md)

______________________________________________________________________

## Running Examples Locally

To run these examples in the full FuncNodes environment:

1. Start the UI: `funcnodes runserver`
1. Create or select a worker
1. Install required modules via **Manage Libraries**
1. Import the `.fnw` workflow file via **Nodespace** ‚Üí **Import**

Example workflow files are bundled with the documentation.



# Titanic Survival Analysis (Plotly)

This example shows how to build an interactive survival analysis workflow using pandas + Plotly inside FuncNodes.

## What you‚Äôll see

- CSV ingest with `funcnodes-files` + `funcnodes-pandas`
- Data wrangling (select/rename columns, handle missing values)
- Plotly express nodes to visualize survival by sex/class/age
- Live previews in the UI and an exportable figure

## How to run

1. Start the UI: `funcnodes runserver`
1. Create or select a worker.
1. Install required modules if not present: `funcnodes-files`, `funcnodes-pandas`, `funcnodes-plotly`.
1. Import the workflow:
1. Open **Nodespace ‚Üí Import**, choose `titanic.fnw` (bundled with this example).
1. Drop in the sample Titanic CSV (any standard copy works) via the file upload node, or point to a local path under the worker `files/` directory.

## Tips

- Use the node previews to confirm each transformation before moving downstream.
- Plotly nodes clone the incoming figure by default; you can branch visualizations without side effects.
- To export the figure, connect `to_img` to `files.save` or use `figure.to_json` for downstream dashboards.
# Modules

## Official Modules Overview

Use this page to discover what each packaged module adds to FuncNodes. Install modules from the UI (‚ÄúManage Libraries‚Äù) or via CLI `funcnodes modules install <name>`.

### Core utilities

- **funcnodes-basic** ‚Äî typed input nodes, list/dict helpers with dynamic index/key options, logic/control utilities.
- **funcnodes-files** ‚Äî sandboxed file/folder browsing, async downloads with progress, byte/file metadata types.
- **funcnodes-images** ‚Äî unified image container (Pillow/NumPy backends), resize/crop/scale/show helpers.

### Data & numerics

- **funcnodes-numpy** ‚Äî array creation/manipulation with dtype enums and serialization/rendering for previews.
- **funcnodes-pandas** ‚Äî DataFrame/Series conversion, filtering, grouping, column/row selectors with dynamic dropdowns.

### Visualization

- **funcnodes-plotly** ‚Äî figure/trace builders (express + graph_objects), color scales, layout utilities, image export.

### Vision & capture

- **funcnodes-opencv** ‚Äî normalized float image ops: filtering, thresholding, morphology, drawing, transforms, segmentation.
- **funcnodes-webcam** ‚Äî browser webcam capture into OpenCVImageFormat; device enumeration via React plugin.
- **funcnodes-yolo** ‚Äî starter object-detection nodes (draft).

### Chemistry, spectra, optimization

- **funcnodes-rdkit** ‚Äî molecule conversions (SMILES/InChI/molblock), SVG previews via custom encoders.
- **funcnodes-span** ‚Äî spectroscopy: baseline estimation (multiple algorithms), smoothing, peak detection/fitting with Plotly plots.
- **funcnodes-lmfit** ‚Äî model builders, auto-model selection, fitting, parameter sync, Plotly result plots.
- **funcnodes-bofire** ‚Äî Bayesian optimization (create/tell/ask/predict) with separate-process options.
- **funcnodes-chromatography** ‚Äî parse Shimadzu ASCII/LCD/QGD files into tidy DataFrames.
- **funcnodes-chemprop** ‚Äî deep-learning molecular property prediction (data prep, training, async metrics).

### Tooling & testing

- **funcnodes-pytest** ‚Äî pytest plugin (`@nodetest`, `all_nodes_tested`) for coverage and isolated test contexts.
- **funcnodes-module** ‚Äî scaffolder/CLI to create/update modules with React plugin template.
- **funcnodes-repositories** ‚Äî registry metadata and helpers to refresh available module versions.

### Packaging notes

- Every module is a standalone Python package with `[project.entry-points."funcnodes.module"]` advertising at least `module` and usually `shelf`; some add `react_plugin` or `external_worker`.
- Prefer aligning module versions with the installed `funcnodes`/`funcnodes-core` to avoid API drift.
- If running offline, mirror `funcnodes_repositories` and point the UI/CLI to your mirrored list.

## Module packaging essentials

1. **Entry points drive discovery** Define the `funcnodes.module` entry points in `pyproject.toml`. Typical keys are:

- `module` ‚Üí importable module root (required).
- `shelf` ‚Üí exported `Shelf` object or dict (recommended for predictable grouping).
- `react_plugin` ‚Üí optional React bundle entry for the editor host.
- `external_worker` ‚Üí optional worker classes.

Example (from `funcnodes-files`):

```toml
[project.entry-points."funcnodes.module"]
module = "funcnodes_files"
shelf = "funcnodes_files:NODE_SHELF"
react_plugin = "funcnodes_files:REACT_PLUGIN"
```

2. **React plugin build target** Module templates build the UI add-on as a library named `FuncNodesPlugin`, bundling `src/index.tsx` and marking `react`, `react-dom`, and `@linkdlab/funcnodes_react_flow` as externals (see `vite.config.ts` in `funcnodes_files`).

1. **Testing** Use `pytest-funcnodes` decorators to isolate state and ensure shelf coverage; see the Testing section below.

## Testing FuncNodes modules

- Decorate node tests with `@pytest_funcnodes.nodetest` so registries are isolated and coverage is tracked.
- Use `pytest_funcnodes.all_nodes_tested(all_nodes, NODE_SHELF, ignore=...)` to assert every exported node is exercised.
- Run `pytest --nodetests-only` for a fast pass over node suites. The plugin also provides `@funcnodes_test` for runtime/integration checks.
# Experimental

# Experimental

Experimental features

Pages in this section describe features that are **new**, **evolving**, or **platform-dependent**. Expect rough edges and occasional breaking changes between releases.

## What "experimental" means

- CLI flags and behavior may change without a long deprecation window.
- OS integration (file associations, icons) depends on the underlying desktop/OS and may require manual steps.
- If something behaves unexpectedly, please report it with your OS, FuncNodes version, and exact command line.

______________________________________________________________________

## Available experimental features

| Feature                                                                             | Description                                                 | Status                    |
| ----------------------------------------------------------------------------------- | ----------------------------------------------------------- | ------------------------- |
| [Standalone](https://linkdlab.github.io/FuncNodes/experimental/standalone/index.md) | Open a single `.fnw` workflow with its own dedicated worker | Stable for day-to-day use |

______________________________________________________________________

## Standalone mode (quick start)

Open any `.fnw` file directly:

```bash
funcnodes standalone path/to/workflow.fnw
```

Register `.fnw` files to open with FuncNodes (OS file association):

```bash
funcnodes standalone --register
```

‚Üí See [Standalone](https://linkdlab.github.io/FuncNodes/experimental/standalone/index.md) for full documentation.

# Standalone

`funcnodes standalone` is an **experimental** way to open a single `.fnw` workflow file with a **dedicated worker**, without relying on a global Workermanager.

It is designed for the ‚Äúdouble‚Äëclick a workflow file and run it‚Äù experience, while keeping each workflow isolated.

Experimental

- The file-association integration (`--register`) is OS/desktop dependent.
- The standalone runtime is stable enough for day-to-day use, but still evolving.

______________________________________________________________________

## What it does (high level)

When you run:

```bash
funcnodes standalone path/to/workflow.fnw
```

FuncNodes will:

1. Resolve and validate the `.fnw` path.
1. Choose a **workflow-local config directory** (default: next to the file).
1. Ensure a **dedicated worker** exists (and start it if needed).
1. Import the `.fnw` content into that worker.
1. Start a small UI server (React Flow UI) connected to that worker.
1. Optionally open your browser.

This gives you a self-contained ‚Äúone workflow = one worker‚Äù runtime, without running a shared Workermanager process.

______________________________________________________________________

## Why standalone exists

The normal ‚Äúserver mode‚Äù (`funcnodes runserver`) is optimized for a multi-worker setup:

- a Workermanager supervises workers,
- the UI discovers workers via the manager,
- workers often live under a shared base directory like `~/.funcnodes`.

Standalone is optimized for a different use case:

- you have **one `.fnw` file** and want to open/run it quickly,
- you want the worker state and files to live **close to the workflow** (or in a per-project location),
- you want an easy path to ‚Äúopen with FuncNodes‚Äù via OS file associations.

______________________________________________________________________

## CLI usage

### Open a workflow

```bash
funcnodes standalone ./example.fnw
```

### Important options

| Option                               | Meaning                                                                                |
| ------------------------------------ | -------------------------------------------------------------------------------------- |
| `--config-dir <path>`                | Override the workflow-local config directory (default: `<fnw_dir>/<fnw_stem>_config`). |
| `--host <host>`                      | Host to bind the UI/worker to (default: `localhost`).                                  |
| `--worker-port <port>`               | Force a specific worker port (default: auto).                                          |
| `--ui-port <port>` / `--port <port>` | Force a specific UI port (default: auto).                                              |
| `--no-browser`                       | Don‚Äôt open a browser automatically.                                                    |
| `--debug`                            | Enable debug logging (also affects worker startup behavior).                           |

### Register ‚Äúopen .fnw with FuncNodes‚Äù (desktop integration)

```bash
funcnodes standalone --register
```

This creates a small launcher script that calls the exact Python interpreter that executed `funcnodes` at registration time, then configures your OS so `.fnw` files open with it.

______________________________________________________________________

## Workflow-local config directory

Standalone intentionally uses a **workflow-local base directory**.

By default, for a workflow file:

```text
/path/to/MyWorkflow.fnw
```

the config directory is:

```text
/path/to/MyWorkflow_config/
```

This directory behaves like a mini `~/.funcnodes` for that workflow. It stores worker metadata, PID files, logs, and (depending on your worker settings) environments and data.

Project-local isolation

For reproducible projects, consider keeping the `.fnw` and its `_config` directory in your repo, so your workflow state travels with the project.

______________________________________________________________________

## How the worker is identified (UUID)

Standalone computes a worker UUID from the **file contents**:

- it hashes the `.fnw` bytes (SHA‚Äë256),
- then uses a 32-hex-character prefix as the worker UUID.

Implications:

- Opening the same `.fnw` **content** gives the same UUID ‚Üí stable identity.
- Changing the file content changes the UUID ‚Üí you may end up with multiple `worker_<uuid>.json` files over time inside the same `<stem>_config/workers/` directory.

______________________________________________________________________

## ‚ÄúAlready running‚Äù detection and reuse

Before starting a new worker, standalone checks whether the worker is already running by looking in:

- `<config_dir>/workers/worker_<uuid>.json` (worker config)
- `<config_dir>/workers/worker_<uuid>.p` (PID)

and then verifying the port is reachable.

If a worker for that `.fnw` is already running, standalone will **reuse** it instead of spawning another instance.

______________________________________________________________________

## Importing the workflow into the worker

After ensuring the worker is reachable, standalone imports the `.fnw` into the worker:

- reads the `.fnw` bytes,
- base64‚Äëencodes them,
- sends a worker command to update its nodespace from that export.

This is what makes the opened worker reflect the content of the clicked `.fnw` file.

______________________________________________________________________

## UI server behavior

Standalone starts the React Flow UI server and connects it directly to the worker (no manager in between).

- The UI port is chosen automatically unless `--ui-port/--port` is set.
- The browser is opened by default; use `--no-browser` to disable.

______________________________________________________________________

## Shutdown behavior

- Pressing `Ctrl+C` in the terminal triggers a shutdown sequence.
- If standalone started the worker itself, it will also request the worker to stop.
- If the worker stops unexpectedly, standalone will detect that and shut down as well.

______________________________________________________________________

## Desktop integration: `--register`

`funcnodes standalone --register` performs two things:

1. **Write a launcher script** into your FuncNodes config directory:
1. Windows: `.../scripts/fnw_open.cmd`
1. Linux/macOS: `.../scripts/fnw_open.sh`
1. **Register** this launcher as the default opener for `.fnw` files (best-effort, per user).

### Where the launcher is written

The launcher is written to the FuncNodes **base config dir**:

- default: `~/.funcnodes/`
- override via env: `FUNCNODES_CONFIG_DIR=/somewhere`
- override via CLI: `funcnodes --dir /somewhere standalone --register`

This is intentionally separate from the per-workflow `--config-dir` used when actually opening a `.fnw`.

### What the launcher does

The launcher embeds:

- `PY=<sys.executable>` at registration time

and then runs:

```text
PY -m funcnodes standalone "<clicked-file.fnw>"
```

This avoids relying on PATH entrypoints and ensures the same Python environment is used.

______________________________________________________________________

## OS-specific registration details

### Windows

Standalone registration:

- writes registry keys under `HKCU\\Software\\Classes\\` (current user, no admin required),
- registers a ProgID (`FuncNodes.WorkerFile`),
- sets:
- `shell\\open\\command` ‚Üí `"path\\to\\fnw_open.cmd" "%1"`
- `DefaultIcon` ‚Üí `"path\\to\\fnw_icon.ico",0`
- copies the icon from the package into your config scripts directory as `fnw_icon.ico`.

Windows default-app behavior

Some Windows setups may still require a user confirmation in ‚ÄúDefault apps‚Äù depending on existing `UserChoice` settings.

### Linux (XDG desktops)

Standalone registration:

- writes a MIME type definition for `.fnw` (`application/x-funcnodes-fnw`),
- writes a `.desktop` launcher entry that calls your `fnw_open.sh`,
- sets the default handler using `xdg-mime` (if available),
- copies icons:
- app icon: `fnw_icon.png` under the FuncNodes config scripts directory
- MIME icon: `application-x-funcnodes-fnw.png` under `$XDG_DATA_HOME/icons/hicolor/.../mimetypes/`

It will attempt (best effort) to run:

- `update-mime-database`
- `update-desktop-database`
- `gtk-update-icon-cache`

If these tools are missing, you may need to run the equivalent commands manually or log out/in depending on your desktop environment.

### macOS

Standalone registration creates (best-effort) an app bundle:

- `~/.../FuncNodesFNW.app` in the FuncNodes base config dir
- includes `Info.plist` with `.fnw` document types and `CFBundleIconFile`
- copies `fnw_icon.icns` into `Contents/Resources/`

Because Finder delivers opened files via Apple Events (not `$1` argv), the bundle is generated as an AppleScript ‚Äúdroplet‚Äù (compiled via `osacompile` when available) which invokes:

```bash
python -m funcnodes standalone <file>
```

FuncNodes then tries to register the app with Launch Services (`lsregister`) and set defaults via `duti` if installed. If that fails, you can use Finder:

- Right click a `.fnw` ‚Üí **Get Info** ‚Üí **Open with** ‚Üí choose the app ‚Üí **Change All‚Ä¶**

______________________________________________________________________

## Security notes

- Treat `.fnw` files as potentially untrusted input: opening a workflow can trigger execution inside a worker.
- The registered launcher will execute Python code (`-m funcnodes`) when you double-click a `.fnw` file.
- If you move/remove the Python environment used at registration time, the launcher will break. Re-run `funcnodes standalone --register` to refresh it.

______________________________________________________________________

## Troubleshooting

### ‚ÄúPort already in use‚Äù

- Avoid forcing `--worker-port` / `--ui-port` unless you need fixed ports.
- Let standalone auto-pick ports when possible.

### ‚ÄúWorker already running / stale PID‚Äù

If a worker crashes and leaves stale files behind, check the workflow config directory:

- `<config_dir>/workers/worker_<uuid>.p`
- `<config_dir>/workers/worker_<uuid>.json`

If the PID is stale and no process is actually running, removing the PID file is usually safe.

### "Double-click doesn't open with FuncNodes"

- Windows: check Default apps settings for `.fnw`.
- Linux: run `xdg-mime query default application/x-funcnodes-fnw` and verify the `.desktop` entry exists.
- macOS: use Finder "Get Info ‚Üí Open with ‚Üí Change All‚Ä¶".

### "Debug logs"

To see detailed logs, run with `--debug`:

```bash
funcnodes standalone --debug ./workflow.fnw
```

______________________________________________________________________

## See also

- [CLI Reference](https://linkdlab.github.io/FuncNodes/api/cli/index.md) ‚Äî all FuncNodes commands
- [Workers](https://linkdlab.github.io/FuncNodes/components/worker/index.md) ‚Äî how workers execute workflows
- [Configuration](https://linkdlab.github.io/FuncNodes/components/config/index.md) ‚Äî global and worker configuration
- [Web UI Guide](https://linkdlab.github.io/FuncNodes/ui-guide/react_flow/web-ui/index.md) ‚Äî using the visual editor
